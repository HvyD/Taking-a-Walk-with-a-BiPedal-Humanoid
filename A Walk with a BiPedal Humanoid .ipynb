{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenAi-GYM Bipedal_Walker_v2 Deep Q Network Learning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU\n"
     ]
    }
   ],
   "source": [
    "from itertools import count\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "\n",
    "import gym\n",
    "\n",
    "\n",
    "import torch, torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Check for GPU\n",
    "use_gpu = torch.cuda.is_available()\n",
    "\n",
    "if use_gpu:\n",
    "    print(\"Using GPU\")\n",
    "    LongTensor = torch.cuda.LongTensor\n",
    "    FloatTensor = torch.cuda.FloatTensor\n",
    "\n",
    "else:\n",
    "    print(\"Using CPU\")\n",
    "    LongTensor = torch.LongTensor\n",
    "    FloatTensor = torch.FloatTensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting and Running Model with Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES = 2000\n",
    "SCREEN_WIDTH = 400\n",
    "SCREEN_LENGTH =600\n",
    "WINDOW_MAX_Y = 300\n",
    "WINDOW_MIN_Y = 200\n",
    "BUFFER_SIZE = 65536\n",
    "GAMMA = 0.999\n",
    "START_EXPLORE_RATIO = 0.7\n",
    "END_EXPLORE_RATIO = 0.05\n",
    "NUM_FEATURES = 24\n",
    "FALL_TIME = 30  \n",
    "\n",
    "\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DQN, self).__init__()\n",
    "        self.hidden1 = nn.Linear(NUM_FEATURES, 400)\n",
    "        self.hidden2 = nn.Linear(400, 300)\n",
    "        self.output = nn.Linear(300, 16)\n",
    "\n",
    "        # Weights initialization\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                n = len(m.weight.data[1])\n",
    "                # \"Xavier\" initialization\n",
    "                m.weight.data.normal_(0, np.sqrt(2. / n))\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "        self.optimizer = optim.RMSprop(self.parameters(), lr=0.0001)\n",
    "\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.tanh(self.hidden1(x))\n",
    "        x = F.tanh(self.hidden2(x))\n",
    "        return self.output(x)\n",
    "\n",
    "    def update(self,transition_buffer):\n",
    "        \n",
    "        transition_batch = transition_buffer.get_batch()\n",
    "        if transition_batch is None:\n",
    "            return\n",
    "\n",
    "        states, actions, rewards, next_states = transition_batch\n",
    "        non_final_mask = [i for i, state in enumerate(next_states) if state is not None]\n",
    "        non_final_mask = LongTensor(non_final_mask)\n",
    "     \n",
    "        non_final_next_states = Variable(torch.cat([s for s in next_states if s is not None]).view(-1, NUM_FEATURES),\n",
    "                                         volatile=True)\n",
    "\n",
    "        states = Variable(torch.cat(list(states)).view(-1, NUM_FEATURES))\n",
    "        actions = Variable(torch.cat(list(actions)).view(-1, 1).type(LongTensor))\n",
    "        rewards = Variable(torch.cat(list(rewards)))\n",
    "\n",
    "        q_values = self.forward(states).gather(1, actions)\n",
    "\n",
    "        next_state_values = Variable(torch.zeros(32).type(FloatTensor))\n",
    "\n",
    "        next_state_values[non_final_mask] = self.forward(non_final_next_states).max(1)[0]\n",
    "\n",
    "        next_state_values.volatile = False\n",
    "\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + rewards\n",
    "\n",
    "        # Compute Huber loss\n",
    "        loss = F.smooth_l1_loss(q_values, expected_state_action_values)\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in model.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "\n",
    "class TransitionBuffer:\n",
    "    def __init__(self):\n",
    "        self.buffer = []\n",
    "        self.batch_size = 32\n",
    "\n",
    "    def push(self,transition):\n",
    "        self.buffer.append(transition)\n",
    "        if len(self.buffer) > BUFFER_SIZE:\n",
    "            self.buffer.pop(0)\n",
    "\n",
    "    def get_batch(self):\n",
    "        if len(self.buffer) >= self.batch_size:\n",
    "            batch = random.sample(self.buffer, self.batch_size)\n",
    "            # Transposing list of lists\n",
    "            return list(zip(*batch))   \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_action(model,state, explore_ratio, randomization=True):\n",
    "    chance = random.random()\n",
    "    if chance < explore_ratio and randomization:\n",
    "        return LongTensor([random.randint(0, 15)])\n",
    "    else:\n",
    "        q_values = model(state)\n",
    "\n",
    "        return q_values.max(0)[1].data\n",
    "\n",
    "\n",
    "def get_action_vec(action_ind):\n",
    "    action_vec = np.array([int(bit) for bit in '{0:04b}'.format(action_ind)])\n",
    "    return action_vec*2 - 1\n",
    "\n",
    "\n",
    "def get_decay_ratio():\n",
    "    return math.pow(END_EXPLORE_RATIO/START_EXPLORE_RATIO, 1.5/NUM_EPISODES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n",
      "Episode 0 , steps =  90 , total reward: -9.671067846184602 , steps_avg: 90.0 , reward_avg: -9.671067846184602 , distance traveled: 12.897258191630248 , average speed: 0.14330286879589166 , explore ratio: 0.7\n",
      "Episode 1 , steps =  108 , total reward: -9.467656287262844 , steps_avg: 99.0 , reward_avg: -9.569362066723723 , distance traveled: 10.128399570914915 , average speed: 0.09378147750847143 , explore ratio: 0.6986158651580259\n",
      "Episode 2 , steps =  9943 , total reward: -866.7401947937425 , steps_avg: 3380.3333333333335 , reward_avg: -295.29297297573 , distance traveled: 349.5914554775514 , average speed: 0.03515955501131966 , explore ratio: 0.6972344672149957\n",
      "Episode 3 , steps =  66 , total reward: -5.711673735859495 , steps_avg: 2551.75 , reward_avg: -222.89764816576235 , distance traveled: 7.577093544602395 , average speed: 0.11480444764549083 , explore ratio: 0.6958558007591421\n",
      "Episode 4 , steps =  3678 , total reward: -290.9346151478034 , steps_avg: 2777.0 , reward_avg: -236.50504156217056 , distance traveled: 175.28707662383508 , average speed: 0.04765825900593667 , explore ratio: 0.6944798603893986\n",
      "Episode 5 , steps =  76 , total reward: -8.971062032379827 , steps_avg: 2326.8333333333335 , reward_avg: -198.5827116405388 , distance traveled: 5.417186659094877 , average speed: 0.07127877183019575 , explore ratio: 0.6931066407153782\n",
      "Episode 6 , steps =  47 , total reward: -6.247075376941517 , steps_avg: 2001.142857142857 , reward_avg: -171.1061921743106 , distance traveled: 0.7301924295304344 , average speed: 0.015536009138945412 , explore ratio: 0.6917361363573528\n",
      "Episode 7 , steps =  80 , total reward: -9.420425274794303 , steps_avg: 1761.0 , reward_avg: -150.89547131187106 , distance traveled: 6.207491680830717 , average speed: 0.07759364601038396 , explore ratio: 0.6903683419462316\n",
      "Episode 8 , steps =  98 , total reward: -18.34677077302773 , steps_avg: 1576.2222222222222 , reward_avg: -136.16783791866624 , distance traveled: -4.350242600440979 , average speed: -0.044390230616744686 , explore ratio: 0.6890032521235407\n",
      "Episode 9 , steps =  112 , total reward: -10.871471806497002 , steps_avg: 1429.8 , reward_avg: -123.63820130744932 , distance traveled: 5.999610192675972 , average speed: 0.053567948148892604 , explore ratio: 0.6876408615414012\n",
      "Episode 10 , steps =  1010 , total reward: -75.79409964391331 , steps_avg: 1391.6363636363637 , reward_avg: -119.28873751985515 , distance traveled: 54.810182293286736 , average speed: 0.054267507221075977 , explore ratio: 0.6862811648625091\n",
      "Episode 11 , steps =  110 , total reward: -11.243072797562936 , steps_avg: 1284.8333333333333 , reward_avg: -110.28493212633079 , distance traveled: 4.315008846502749 , average speed: 0.03922735315002499 , explore ratio: 0.6849241567601138\n",
      "Episode 12 , steps =  125 , total reward: -10.7411586050472 , steps_avg: 1195.6153846153845 , reward_avg: -102.62771877853976 , distance traveled: 7.408115361034871 , average speed: 0.05926492288827897 , explore ratio: 0.6835698319179975\n",
      "Episode 13 , steps =  107 , total reward: -24.167576325761765 , steps_avg: 1117.857142857143 , reward_avg: -97.02342288905561 , distance traveled: -13.048182321935894 , average speed: -0.12194562917697097 , explore ratio: 0.6822181850304545\n",
      "Episode 14 , steps =  236 , total reward: -30.179066535651643 , steps_avg: 1059.0666666666666 , reward_avg: -92.56713246549535 , distance traveled: -1.3646433379501144 , average speed: -0.0057823870252123495 , explore ratio: 0.6808692108022703\n",
      "Episode 15 , steps =  236 , total reward: -17.28705598135913 , steps_avg: 1007.625 , reward_avg: -87.86212768523683 , distance traveled: 16.056282729227107 , average speed: 0.06803509631028436 , explore ratio: 0.6795229039487005\n",
      "Episode 16 , steps =  2548 , total reward: -186.37740438725558 , steps_avg: 1098.235294117647 , reward_avg: -93.65714396182616 , distance traveled: 144.24650297608235 , average speed: 0.05661165736894912 , explore ratio: 0.6781792591954507\n",
      "Episode 17 , steps =  70 , total reward: -21.230525646482903 , steps_avg: 1041.111111111111 , reward_avg: -89.63344294430709 , distance traveled: -7.284586644913068 , average speed: -0.10406552349875811 , explore ratio: 0.6768382712786556\n",
      "Episode 18 , steps =  47 , total reward: -14.721757763688766 , steps_avg: 988.7894736842105 , reward_avg: -85.69072267164297 , distance traveled: -5.874161016941071 , average speed: -0.12498214929661852 , explore ratio: 0.675499934944858\n",
      "Episode 19 , steps =  69 , total reward: -7.279219463556383 , steps_avg: 942.8 , reward_avg: -81.77014751123865 , distance traveled: 4.341989461239428 , average speed: 0.0629273834962236 , explore ratio: 0.6741642449509889\n",
      "Episode 20 , steps =  64 , total reward: -6.26679707658974 , steps_avg: 900.952380952381 , reward_avg: -78.17474987149346 , distance traveled: 3.866311703324318 , average speed: 0.06041112036444247 , explore ratio: 0.6728311960643464\n",
      "Episode 21 , steps =  59 , total reward: -13.48350028865226 , steps_avg: 862.6818181818181 , reward_avg: -75.23423852681886 , distance traveled: -5.0869441071152695 , average speed: -0.08621939164602152 , explore ratio: 0.6715007830625753\n",
      "Episode 22 , steps =  103 , total reward: -8.284508985942855 , steps_avg: 829.6521739130435 , reward_avg: -72.32338072069382 , distance traveled: 6.304240081496536 , average speed: 0.061206214383461514 , explore ratio: 0.670173000733647\n",
      "Episode 23 , steps =  48 , total reward: -2.010578512596587 , steps_avg: 797.0833333333334 , reward_avg: -69.39368062868976 , distance traveled: 6.715950806736947 , average speed: 0.13991564180701974 , explore ratio: 0.6688478438758388\n",
      "Episode 24 , steps =  70 , total reward: -16.27338927045775 , steps_avg: 768.0 , reward_avg: -67.26886897436049 , distance traveled: -5.058821823801844 , average speed: -0.07226888319716919 , explore ratio: 0.6675253072977134\n",
      "Episode 25 , steps =  78 , total reward: -22.86180290643498 , steps_avg: 741.4615384615385 , reward_avg: -65.56090489482489 , distance traveled: -13.97617112651467 , average speed: -0.17918168110916244 , explore ratio: 0.6662053858180988\n",
      "Episode 26 , steps =  642 , total reward: -57.47822850068663 , steps_avg: 737.7777777777778 , reward_avg: -65.2615465098568 , distance traveled: 24.793995192362704 , average speed: 0.03861993020617244 , explore ratio: 0.664888074266068\n",
      "Episode 27 , steps =  75 , total reward: -6.80899782329488 , steps_avg: 714.1071428571429 , reward_avg: -63.17395548533674 , distance traveled: 8.983551474362612 , average speed: 0.11978068632483482 , explore ratio: 0.6635733674809184\n",
      "Episode 28 , steps =  67 , total reward: -13.9487411091098 , steps_avg: 691.7931034482758 , reward_avg: -61.4765342999496 , distance traveled: -3.35169577807188 , average speed: -0.05002531012047582 , explore ratio: 0.6622612603121522\n",
      "Episode 29 , steps =  286 , total reward: -25.210457070790696 , steps_avg: 678.2666666666667 , reward_avg: -60.267665058977634 , distance traveled: 18.686683864966035 , average speed: 0.06533805547190921 , explore ratio: 0.6609517476194554\n",
      "Episode 30 , steps =  61 , total reward: -15.972256327291328 , steps_avg: 658.3548387096774 , reward_avg: -58.83878090634259 , distance traveled: -5.002150075435638 , average speed: -0.08200246025304324 , explore ratio: 0.6596448242726787\n",
      "Episode 31 , steps =  63 , total reward: -2.764153526997199 , steps_avg: 639.75 , reward_avg: -57.08644880073805 , distance traveled: 9.169345369935037 , average speed: 0.14554516460214345 , explore ratio: 0.6583404851518163\n",
      "Episode 32 , steps =  69 , total reward: -18.22397774735652 , steps_avg: 622.4545454545455 , reward_avg: -55.90879816275679 , distance traveled: -7.237709503518417 , average speed: -0.10489434063070169 , explore ratio: 0.6570387251469867\n",
      "Episode 33 , steps =  1298 , total reward: -123.13876538397056 , steps_avg: 642.3235294117648 , reward_avg: -57.88615013985131 , distance traveled: 36.22127383366559 , average speed: 0.027905449794811705 , explore ratio: 0.6557395391584121\n",
      "Episode 34 , steps =  118 , total reward: -19.30423128202311 , steps_avg: 627.3428571428572 , reward_avg: -56.78380960105622 , distance traveled: -0.6610434209369122 , average speed: -0.005602062889295866 , explore ratio: 0.654442922096399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 35 , steps =  86 , total reward: -22.287586747375002 , steps_avg: 612.3055555555555 , reward_avg: -55.82558118845396 , distance traveled: -3.937477956209332 , average speed: -0.04578462739778293 , explore ratio: 0.6531488688813176\n",
      "Episode 36 , steps =  128 , total reward: -25.657160370080426 , steps_avg: 599.2162162162163 , reward_avg: -55.01021846363305 , distance traveled: -7.670378421633502 , average speed: -0.05992483141901173 , explore ratio: 0.6518573744435825\n",
      "Episode 37 , steps =  360 , total reward: -36.72592477571213 , steps_avg: 592.921052631579 , reward_avg: -54.529052840266715 , distance traveled: 11.299925496848308 , average speed: 0.03138868193568974 , explore ratio: 0.6505684337236324\n",
      "Episode 38 , steps =  839 , total reward: -69.26302309944515 , steps_avg: 599.2307692307693 , reward_avg: -54.90684694947642 , distance traveled: 40.531470759892805 , average speed: 0.048309261930742316 , explore ratio: 0.6492820416719104\n",
      "Episode 39 , steps =  181 , total reward: -33.65698069324219 , steps_avg: 588.775 , reward_avg: -54.37560029307057 , distance traveled: -10.06299806093797 , average speed: -0.05559667436982304 , explore ratio: 0.6479981932488444\n",
      "Episode 40 , steps =  77 , total reward: -11.356542528295897 , steps_avg: 576.2926829268292 , reward_avg: -53.3263549817346 , distance traveled: 7.2198893802613 , average speed: 0.09376479714625065 , explore ratio: 0.6467168834248274\n",
      "Episode 41 , steps =  48 , total reward: -26.399644863038013 , steps_avg: 563.7142857142857 , reward_avg: -52.685242836051344 , distance traveled: -5.082056315392256 , average speed: -0.10587617323733867 , explore ratio: 0.6454381071801971\n",
      "Episode 42 , steps =  75 , total reward: -19.847772299752886 , steps_avg: 552.3488372093024 , reward_avg: -51.92158073055602 , distance traveled: -8.425243884511293 , average speed: -0.11233658512681724 , explore ratio: 0.6441618595052172\n",
      "Episode 43 , steps =  448 , total reward: -39.37289743045387 , steps_avg: 549.9772727272727 , reward_avg: -51.63638338282644 , distance traveled: 24.979893932892 , average speed: 0.05575869181449107 , explore ratio: 0.6428881354000572\n",
      "Episode 44 , steps =  111 , total reward: -16.38913699746877 , steps_avg: 540.2222222222222 , reward_avg: -50.8531112409296 , distance traveled: 4.666043255659753 , average speed: 0.04203642572666444 , explore ratio: 0.6416169298747729\n",
      "Episode 45 , steps =  408 , total reward: -30.149122304457364 , steps_avg: 537.3478260869565 , reward_avg: -50.40302452491933 , distance traveled: 33.22031004664489 , average speed: 0.08142232854569827 , explore ratio: 0.6403482379492871\n",
      "Episode 46 , steps =  53 , total reward: -11.377612211065367 , steps_avg: 527.0425531914893 , reward_avg: -49.57269660334797 , distance traveled: -5.000702186822892 , average speed: -0.09435287144948852 , explore ratio: 0.6390820546533695\n",
      "Episode 47 , steps =  115 , total reward: -33.94064723785034 , steps_avg: 518.4583333333334 , reward_avg: -49.24702890823344 , distance traveled: -15.419932645484803 , average speed: -0.13408637083030264 , explore ratio: 0.637818375026618\n",
      "Episode 48 , steps =  2486 , total reward: -178.0764737312638 , steps_avg: 558.6122448979592 , reward_avg: -51.876201251560595 , distance traveled: 145.28022237383541 , average speed: 0.05843934930564578 , explore ratio: 0.6365571941184385\n",
      "Episode 49 , steps =  65 , total reward: -11.841603467371314 , steps_avg: 548.74 , reward_avg: -51.075509295876806 , distance traveled: 0.515932249976322 , average speed: 0.007937419230404955 , explore ratio: 0.6352985069880263\n",
      "Episode 50 , steps =  56 , total reward: -5.453920862961563 , steps_avg: 539.0784313725491 , reward_avg: -50.180968346211806 , distance traveled: 9.364617152810093 , average speed: 0.16722530630018023 , explore ratio: 0.6340423087043459\n",
      "Episode 51 , steps =  1105 , total reward: -106.20961789550164 , steps_avg: 549.9615384615385 , reward_avg: -51.258442376005846 , distance traveled: 30.482316687460976 , average speed: 0.027585806956978258 , explore ratio: 0.6327885943461125\n",
      "Episode 52 , steps =  66 , total reward: -14.86522125314735 , steps_avg: 540.8301886792453 , reward_avg: -50.571777826517945 , distance traveled: 5.69598332583904 , average speed: 0.08630277766422788 , explore ratio: 0.6315373590017721\n",
      "Episode 53 , steps =  144 , total reward: -17.446605181699 , steps_avg: 533.4814814814815 , reward_avg: -49.958348703465745 , distance traveled: 11.677062950675609 , average speed: 0.08109071493524728 , explore ratio: 0.6302885977694827\n",
      "Episode 54 , steps =  78 , total reward: -17.749338166205202 , steps_avg: 525.2 , reward_avg: -49.37273033006101 , distance traveled: -3.032549736276269 , average speed: -0.038878842772772676 , explore ratio: 0.6290423057570944\n",
      "Episode 55 , steps =  94 , total reward: -14.137535993216563 , steps_avg: 517.5 , reward_avg: -48.74353043118878 , distance traveled: 5.185036553945393 , average speed: 0.0551599633398446 , explore ratio: 0.6277984780821314\n",
      "Episode 56 , steps =  100 , total reward: -7.1227342913361955 , steps_avg: 510.17543859649123 , reward_avg: -48.01334102522645 , distance traveled: 13.687900806516408 , average speed: 0.1368790080651641 , explore ratio: 0.6265571098717717\n",
      "Episode 57 , steps =  323 , total reward: -49.341975264413094 , steps_avg: 506.94827586206895 , reward_avg: -48.03624851210898 , distance traveled: -13.549642635136843 , average speed: -0.041949358003519635 , explore ratio: 0.6253181962628287\n",
      "Episode 58 , steps =  1256 , total reward: -105.7523437331502 , steps_avg: 519.6440677966102 , reward_avg: -49.01448741416053 , distance traveled: 54.67738165627341 , average speed: 0.04353294717856163 , explore ratio: 0.6240817324017319\n",
      "Episode 59 , steps =  59 , total reward: -1.7181745134747337 , steps_avg: 511.96666666666664 , reward_avg: -48.226215532482435 , distance traveled: 9.706415619850159 , average speed: 0.16451551898051117 , explore ratio: 0.622847713444508\n",
      "Episode 60 , steps =  92 , total reward: -25.256207387033857 , steps_avg: 505.08196721311475 , reward_avg: -47.84965802190131 , distance traveled: -15.830619057342414 , average speed: -0.17207194627546102 , explore ratio: 0.6216161345567616\n",
      "Episode 61 , steps =  63 , total reward: -13.697978734383982 , steps_avg: 497.9516129032258 , reward_avg: -47.29882448500587 , distance traveled: -6.264876613542439 , average speed: -0.09944248592924507 , explore ratio: 0.6203869909136569\n",
      "Episode 62 , steps =  65 , total reward: -3.3975576317434544 , steps_avg: 491.07936507936506 , reward_avg: -46.60197897939853 , distance traveled: 8.784511490827425 , average speed: 0.13514633062811424 , explore ratio: 0.6191602776998982\n",
      "Episode 63 , steps =  45 , total reward: -15.261829953501003 , steps_avg: 484.109375 , reward_avg: -46.112289150868875 , distance traveled: -1.488155247531831 , average speed: -0.03307011661181847 , explore ratio: 0.6179359901097115\n",
      "Episode 64 , steps =  148 , total reward: -24.13619418809245 , steps_avg: 478.9384615384615 , reward_avg: -45.77419538221078 , distance traveled: -4.990415414362212 , average speed: -0.033719023070014946 , explore ratio: 0.6167141233468248\n",
      "Episode 65 , steps =  65 , total reward: -9.5779163730517 , steps_avg: 472.6666666666667 , reward_avg: -45.22576691237503 , distance traveled: 2.0705624055583027 , average speed: 0.031854806239358505 , explore ratio: 0.6154946726244508\n",
      "Episode 66 , steps =  376 , total reward: -33.59277468538648 , steps_avg: 471.2238805970149 , reward_avg: -45.05214016271848 , distance traveled: 15.253684595525261 , average speed: 0.04056831009448208 , explore ratio: 0.6142776331652666\n",
      "Episode 67 , steps =  57 , total reward: -10.56081914678154 , steps_avg: 465.13235294117646 , reward_avg: -44.544914853660586 , distance traveled: -0.14185048598796088 , average speed: -0.002488605017332647 , explore ratio: 0.613063000201396\n",
      "Episode 68 , steps =  54 , total reward: -5.012276420914876 , steps_avg: 459.17391304347825 , reward_avg: -43.97197806478021 , distance traveled: 4.244716019695625 , average speed: 0.07860585221658566 , explore ratio: 0.6118507689743904\n",
      "Episode 69 , steps =  41 , total reward: -15.541233500761903 , steps_avg: 453.2 , reward_avg: -43.56582457100852 , distance traveled: -1.1291344968974593 , average speed: -0.02753986577798681 , explore ratio: 0.6106409347352103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 70 , steps =  219 , total reward: -40.26434059953809 , steps_avg: 449.90140845070425 , reward_avg: -43.51932479676246 , distance traveled: -18.88696408278308 , average speed: -0.08624184512686338 , explore ratio: 0.6094334927442066\n",
      "Episode 71 , steps =  1945 , total reward: -162.35480136068625 , steps_avg: 470.6666666666667 , reward_avg: -45.16981752681696 , distance traveled: 79.52195528855368 , average speed: 0.04088532405581166 , explore ratio: 0.608228438271102\n",
      "Episode 72 , steps =  56 , total reward: -2.609441003549225 , steps_avg: 464.986301369863 , reward_avg: -44.58679867033385 , distance traveled: 7.413412904441355 , average speed: 0.13238237329359562 , explore ratio: 0.6070257665949726\n",
      "Episode 73 , steps =  70 , total reward: -15.346379991431412 , steps_avg: 459.64864864864865 , reward_avg: -44.19165787737571 , distance traveled: -7.605756487213076 , average speed: -0.10865366410304393 , explore ratio: 0.6058254730042296\n",
      "Episode 74 , steps =  2247 , total reward: -192.6009648364211 , steps_avg: 483.48 , reward_avg: -46.17044863682965 , distance traveled: 87.19870163561188 , average speed: 0.038806720799115214 , explore ratio: 0.6046275527966002\n",
      "Episode 75 , steps =  78 , total reward: -15.649814253313467 , steps_avg: 478.14473684210526 , reward_avg: -45.7688613423097 , distance traveled: -1.2817868998646746 , average speed: -0.016433165382880446 , explore ratio: 0.6034320012791098\n",
      "Episode 76 , steps =  60 , total reward: -5.159494947676236 , steps_avg: 472.7142857142857 , reward_avg: -45.24146697354822 , distance traveled: 3.6813081708457327 , average speed: 0.06135513618076221 , explore ratio: 0.6022388137680633\n",
      "Episode 77 , steps =  67 , total reward: -15.053915682965275 , steps_avg: 467.5128205128205 , reward_avg: -44.85444708520742 , distance traveled: -6.940491959676147 , average speed: -0.10358943223397235 , explore ratio: 0.6010479855890268\n",
      "Episode 78 , steps =  12134 , total reward: -994.3011775269972 , steps_avg: 615.1898734177215 , reward_avg: -56.87276012877438 , distance traveled: 509.74610963654237 , average speed: 0.04200973377588119 , explore ratio: 0.5998595120768095\n",
      "Episode 79 , steps =  5660 , total reward: -507.7248213383226 , steps_avg: 678.25 , reward_avg: -62.50841089389373 , distance traveled: 182.84071255086914 , average speed: 0.03230401281817476 , explore ratio: 0.5986733885754452\n",
      "Episode 80 , steps =  61 , total reward: -9.778381801261256 , steps_avg: 670.6296296296297 , reward_avg: -61.85742288040444 , distance traveled: 4.062575228274801 , average speed: 0.06659959390614427 , explore ratio: 0.5974896104381738\n",
      "Episode 81 , steps =  78 , total reward: -16.32294489382829 , steps_avg: 663.4024390243902 , reward_avg: -61.30212436837303 , distance traveled: 1.793184770643711 , average speed: 0.02298954834158604 , explore ratio: 0.5963081730274238\n",
      "Episode 82 , steps =  53 , total reward: -1.5647042399806286 , steps_avg: 656.0481927710844 , reward_avg: -60.5823964150189 , distance traveled: 7.991432763934134 , average speed: 0.1507817502629082 , explore ratio: 0.5951290717147936\n",
      "Episode 83 , steps =  4591 , total reward: -357.9380175926677 , steps_avg: 702.8928571428571 , reward_avg: -64.12234428618139 , distance traveled: 221.2253340241555 , average speed: 0.048186742327195706 , explore ratio: 0.5939523018810333\n",
      "Episode 84 , steps =  4916 , total reward: -341.81156774108956 , steps_avg: 752.4588235294118 , reward_avg: -67.38927632682737 , distance traveled: 298.193299726557 , average speed: 0.060657709464311836 , explore ratio: 0.5927778589160273\n",
      "Episode 85 , steps =  63 , total reward: -5.480488850943748 , steps_avg: 744.4418604651163 , reward_avg: -66.66940670501477 , distance traveled: 3.426656564846634 , average speed: 0.05439137404518466 , explore ratio: 0.5916057382187752\n",
      "Episode 86 , steps =  63 , total reward: -16.01474076610121 , steps_avg: 736.6091954022988 , reward_avg: -66.08716916548703 , distance traveled: -5.753433437570927 , average speed: -0.09132434027890361 , explore ratio: 0.5904359351973746\n",
      "Episode 87 , steps =  82 , total reward: -21.18673634603558 , steps_avg: 729.1704545454545 , reward_avg: -65.57693697435688 , distance traveled: -8.898651712336576 , average speed: -0.10852014283337288 , explore ratio: 0.5892684452690028\n",
      "Episode 88 , steps =  6964 , total reward: -444.4635000141298 , steps_avg: 799.2247191011236 , reward_avg: -69.8340893680622 , distance traveled: 475.26333194274946 , average speed: 0.06824573979648901 , explore ratio: 0.5881032638598989\n",
      "Episode 89 , steps =  106 , total reward: -9.736156256175297 , steps_avg: 791.5222222222222 , reward_avg: -69.16633455570789 , distance traveled: 11.504896701509134 , average speed: 0.10853676133499184 , explore ratio: 0.5869403864053457\n",
      "Episode 90 , steps =  1038 , total reward: -54.68680506637104 , steps_avg: 794.2307692307693 , reward_avg: -69.00721884703387 , distance traveled: 88.77497860771602 , average speed: 0.08552502756042006 , explore ratio: 0.5857798083496524\n",
      "Episode 91 , steps =  65 , total reward: -13.408808513795961 , steps_avg: 786.304347826087 , reward_avg: -68.40288829993345 , distance traveled: -4.4974594823643566 , average speed: -0.06919168434406703 , explore ratio: 0.5846215251461357\n",
      "Episode 92 , steps =  63 , total reward: -20.805023522290718 , steps_avg: 778.5268817204301 , reward_avg: -67.89108330232439 , distance traveled: -7.570281726121902 , average speed: -0.12016320200193495 , explore ratio: 0.5834655322571032\n",
      "Episode 93 , steps =  345 , total reward: -65.21441612451939 , steps_avg: 773.9148936170212 , reward_avg: -67.86260811958178 , distance traveled: -19.252146448139094 , average speed: -0.05580332303808433 , explore ratio: 0.5823118251538346\n",
      "Episode 94 , steps =  129 , total reward: -12.999580025072534 , steps_avg: 767.1263157894737 , reward_avg: -67.28510256069221 , distance traveled: 7.926864906465634 , average speed: 0.061448565166400265 , explore ratio: 0.5811603993165647\n",
      "Episode 95 , steps =  71 , total reward: -21.224998491957166 , steps_avg: 759.875 , reward_avg: -66.80530980997622 , distance traveled: -9.280265062451363 , average speed: -0.13070795862607554 , explore ratio: 0.5800112502344652\n",
      "Episode 96 , steps =  41 , total reward: -16.550144880281756 , steps_avg: 752.4639175257732 , reward_avg: -66.28721532616494 , distance traveled: -0.9654324694722891 , average speed: -0.02354713340176315 , explore ratio: 0.5788643734056274\n",
      "Episode 97 , steps =  171 , total reward: -29.923726035283266 , steps_avg: 746.530612244898 , reward_avg: -65.91615931299268 , distance traveled: -2.9857346414029586 , average speed: -0.017460436499432505 , explore ratio: 0.5777197643370442\n",
      "Episode 98 , steps =  46 , total reward: -6.498474128682168 , steps_avg: 739.4545454545455 , reward_avg: -65.31598067476732 , distance traveled: 0.6716634423192591 , average speed: 0.014601379180853458 , explore ratio: 0.5765774185445929\n",
      "Episode 99 , steps =  58 , total reward: -4.801651066225641 , steps_avg: 732.64 , reward_avg: -64.7108373786819 , distance traveled: 4.441240002661943 , average speed: 0.07657310349417143 , explore ratio: 0.5754373315530171\n",
      "Episode 100 , steps =  116 , total reward: -7.458031840691974 , steps_avg: 726.5346534653465 , reward_avg: -64.14397791790972 , distance traveled: 27.44827693068423 , average speed: 0.23662307698865714 , explore ratio: 0.5742994988959098\n",
      "Episode 101 , steps =  191 , total reward: -43.45815659471906 , steps_avg: 721.2843137254902 , reward_avg: -63.941175748074514 , distance traveled: -21.1744145987369 , average speed: -0.11086080941747067 , explore ratio: 0.5731639161156954\n",
      "Episode 102 , steps =  165 , total reward: -16.809516447633516 , steps_avg: 715.8834951456311 , reward_avg: -63.48358682282752 , distance traveled: 14.747909674867994 , average speed: 0.08938127075677572 , explore ratio: 0.5720305787636125\n",
      "Episode 103 , steps =  71 , total reward: -3.8427450991496457 , steps_avg: 709.6826923076923 , reward_avg: -62.91011719086909 , distance traveled: 7.177846250385047 , average speed: 0.10109642606176122 , explore ratio: 0.5708994823996963\n",
      "Episode 104 , steps =  71 , total reward: -3.715569701525077 , steps_avg: 703.6 , reward_avg: -62.34635959573248 , distance traveled: 9.892147579193116 , average speed: 0.13932602224215657 , explore ratio: 0.5697706225927615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 105 , steps =  43 , total reward: -22.033982840370385 , steps_avg: 697.3679245283018 , reward_avg: -61.966054154644155 , distance traveled: -3.736414952427149 , average speed: -0.08689337098667789 , explore ratio: 0.5686439949203844\n",
      "Episode 106 , steps =  59 , total reward: -13.295043768602115 , steps_avg: 691.4018691588785 , reward_avg: -61.51118489869984 , distance traveled: -4.521709041427821 , average speed: -0.0766391362953868 , explore ratio: 0.5675195949688864\n",
      "Episode 107 , steps =  67 , total reward: -14.55995205401692 , steps_avg: 685.6203703703703 , reward_avg: -61.076451261249076 , distance traveled: -3.2709414418274534 , average speed: -0.04882002151981274 , explore ratio: 0.5663974183333157\n",
      "Episode 108 , steps =  63 , total reward: -0.10174367583729278 , steps_avg: 679.9082568807339 , reward_avg: -60.51705027422695 , distance traveled: 9.916023159474133 , average speed: 0.15739719300752592 , explore ratio: 0.565277460617431\n",
      "Episode 109 , steps =  69 , total reward: -17.908930410778773 , steps_avg: 674.3545454545455 , reward_avg: -60.12970373001378 , distance traveled: -5.108302879706026 , average speed: -0.07403337506820327 , explore ratio: 0.5641597174336835\n",
      "Episode 110 , steps =  6469 , total reward: -391.9080217611959 , steps_avg: 726.5585585585585 , reward_avg: -63.11869758615056 , distance traveled: 469.0851352827007 , average speed: 0.07251277404277334 , explore ratio: 0.5630441844032004\n",
      "Episode 111 , steps =  255 , total reward: -12.402385380255696 , steps_avg: 722.3482142857143 , reward_avg: -62.66587337002649 , distance traveled: 26.787793961302373 , average speed: 0.1050501723972642 , explore ratio: 0.561930857155767\n",
      "Episode 112 , steps =  258 , total reward: -13.8623502801272 , steps_avg: 718.2389380530974 , reward_avg: -62.23398378516013 , distance traveled: 26.411217041553453 , average speed: 0.10236905830059478 , explore ratio: 0.5608197313298103\n",
      "Episode 113 , steps =  2481 , total reward: -137.71086017648335 , steps_avg: 733.7017543859649 , reward_avg: -62.896061648241904 , distance traveled: 199.68790235982829 , average speed: 0.08048686108820165 , explore ratio: 0.5597108025723816\n",
      "Episode 114 , steps =  67 , total reward: -18.477643174332876 , steps_avg: 727.9043478260869 , reward_avg: -62.50981453107748 , distance traveled: -8.16141122058034 , average speed: -0.12181210776985583 , explore ratio: 0.5586040665391392\n",
      "Episode 115 , steps =  2169 , total reward: -125.73888722877984 , steps_avg: 740.3275862068965 , reward_avg: -63.05489274398871 , distance traveled: 166.7542386597766 , average speed: 0.0768807001658721 , explore ratio: 0.5574995188943317\n",
      "Episode 116 , steps =  69 , total reward: -9.977797798274088 , steps_avg: 734.5897435897435 , reward_avg: -62.60124235983731 , distance traveled: 1.4603709610551598 , average speed: 0.0211647965370313 , explore ratio: 0.556397155310781\n",
      "Episode 117 , steps =  83 , total reward: -19.164234168703985 , steps_avg: 729.0677966101695 , reward_avg: -62.23313212092939 , distance traveled: 0.15743743476807132 , average speed: 0.0018968365634707387 , explore ratio: 0.5552969714698655\n",
      "Episode 118 , steps =  73 , total reward: -7.573930671175328 , steps_avg: 723.5546218487395 , reward_avg: -61.77381110034323 , distance traveled: 6.832209666967393 , average speed: 0.09359191324612867 , explore ratio: 0.5541989630615024\n",
      "Episode 119 , steps =  64 , total reward: -9.4381177904134 , steps_avg: 718.0583333333333 , reward_avg: -61.33768032276048 , distance traveled: 5.183430547825993 , average speed: 0.08099110230978114 , explore ratio: 0.5531031257841319\n",
      "Episode 120 , steps =  73 , total reward: -11.673282274225729 , steps_avg: 712.7272727272727 , reward_avg: -60.927230752111434 , distance traveled: 3.058518990743905 , average speed: 0.04189752042114939 , explore ratio: 0.5520094553446996\n",
      "Episode 121 , steps =  55 , total reward: -2.5748385518478885 , steps_avg: 707.3360655737705 , reward_avg: -60.44893245538797 , distance traveled: 8.195783861875533 , average speed: 0.1490142520341006 , explore ratio: 0.55091794745864\n",
      "Episode 122 , steps =  278 , total reward: -19.652649722612157 , steps_avg: 703.8455284552846 , reward_avg: -60.11725535999955 , distance traveled: 20.011489916250575 , average speed: 0.07198377667716034 , explore ratio: 0.5498285978498595\n",
      "Episode 123 , steps =  68 , total reward: -17.137317490926016 , steps_avg: 698.7177419354839 , reward_avg: -59.770642957829594 , distance traveled: -4.466793338991701 , average speed: -0.06568813733811325 , explore ratio: 0.5487414022507199\n",
      "Episode 124 , steps =  56 , total reward: -11.975261913840356 , steps_avg: 693.576 , reward_avg: -59.38827990947769 , distance traveled: -2.8995667353272436 , average speed: -0.05177797741655792 , explore ratio: 0.5476563564020214\n",
      "Episode 125 , steps =  129 , total reward: 1.558885567621008 , steps_avg: 689.0952380952381 , reward_avg: -58.90457224696103 , distance traveled: 22.901222688389243 , average speed: 0.177528858049529 , explore ratio: 0.5465734560529862\n",
      "Episode 126 , steps =  206 , total reward: 2.794789978686712 , steps_avg: 685.2913385826772 , reward_avg: -58.41875049715278 , distance traveled: 46.11757211431862 , average speed: 0.22387170929280883 , explore ratio: 0.5454926969612418\n",
      "Episode 127 , steps =  68 , total reward: -7.119647283536073 , steps_avg: 680.46875 , reward_avg: -58.01797625329639 , distance traveled: 4.440405467189847 , average speed: 0.06530008039985069 , explore ratio: 0.544414074892804\n",
      "Episode 128 , steps =  77 , total reward: -16.124964006803317 , steps_avg: 675.7906976744187 , reward_avg: -57.693224220377836 , distance traveled: -0.5117157635930922 , average speed: -0.006645659267442756 , explore ratio: 0.5433375856220608\n",
      "Episode 129 , steps =  553 , total reward: -34.32300597107676 , steps_avg: 674.8461538461538 , reward_avg: -57.51345331076782 , distance traveled: 42.810504441820065 , average speed: 0.07741501707381566 , explore ratio: 0.5422632249317557\n",
      "Episode 130 , steps =  536 , total reward: -41.06661752910147 , steps_avg: 673.7862595419847 , reward_avg: -57.38790494602228 , distance traveled: 29.767929367957112 , average speed: 0.0555371816566364 , explore ratio: 0.541190988612971\n",
      "Episode 131 , steps =  61 , total reward: -10.921191667465493 , steps_avg: 669.1439393939394 , reward_avg: -57.035884390881705 , distance traveled: 1.4994722317066045 , average speed: 0.024581511995190236 , explore ratio: 0.5401208724651115\n",
      "Episode 132 , steps =  60 , total reward: -5.354055888953935 , steps_avg: 664.5639097744361 , reward_avg: -56.647299214175476 , distance traveled: 4.8193498306162645 , average speed: 0.08032249717693775 , explore ratio: 0.539052872295888\n",
      "Episode 133 , steps =  164 , total reward: -22.469579673284013 , steps_avg: 660.8283582089553 , reward_avg: -56.39224160566136 , distance traveled: 0.23821998767321795 , average speed: 0.001452560900446451 , explore ratio: 0.537986983921301\n",
      "Episode 134 , steps =  426 , total reward: -25.75125128381671 , steps_avg: 659.0888888888888 , reward_avg: -56.165271306981026 , distance traveled: 33.831595864430994 , average speed: 0.07941689170054224 , explore ratio: 0.5369232031656238\n",
      "Episode 135 , steps =  761 , total reward: -42.468871996956445 , steps_avg: 659.8382352941177 , reward_avg: -56.06456248852497 , distance traveled: 63.279406801743825 , average speed: 0.08315296557390779 , explore ratio: 0.5358615258613868\n",
      "Episode 136 , steps =  244 , total reward: -17.145925210089068 , steps_avg: 656.8029197080292 , reward_avg: -55.78048484415683 , distance traveled: 19.06373948313295 , average speed: 0.07813007984890553 , explore ratio: 0.5348019478493609\n",
      "Episode 137 , steps =  76 , total reward: -15.312759612458454 , steps_avg: 652.5942028985507 , reward_avg: -55.48724045841988 , distance traveled: -7.7297619420290005 , average speed: -0.1017073939740658 , explore ratio: 0.533744464978541\n",
      "Episode 138 , steps =  229 , total reward: -6.262714289798112 , steps_avg: 649.5467625899281 , reward_avg: -55.13310717663124 , distance traveled: 32.33003729838878 , average speed: 0.14117920217637023 , explore ratio: 0.5326890731061301\n",
      "Episode 139 , steps =  261 , total reward: -20.277449117080593 , steps_avg: 646.7714285714286 , reward_avg: -54.88413819049159 , distance traveled: 18.638797652162616 , average speed: 0.07141301782437784 , explore ratio: 0.5316357680975229\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 140 , steps =  42 , total reward: -16.07897767654248 , steps_avg: 642.4822695035461 , reward_avg: -54.60892428613734 , distance traveled: -2.1034061729907987 , average speed: -0.05008109935692378 , explore ratio: 0.5305845458262894\n",
      "Episode 141 , steps =  89 , total reward: -16.271670243953054 , steps_avg: 638.5845070422536 , reward_avg: -54.33894362386844 , distance traveled: -6.702624813686125 , average speed: -0.07531039116501263 , explore ratio: 0.5295354021741592\n",
      "Episode 142 , steps =  39 , total reward: -14.941031650880982 , steps_avg: 634.3916083916084 , reward_avg: -54.06343374993146 , distance traveled: -0.3792657054215669 , average speed: -0.009724761677476074 , explore ratio: 0.5284883330310048\n",
      "Episode 143 , steps =  1450 , total reward: -69.60750846852278 , steps_avg: 640.0555555555555 , reward_avg: -54.17137871325501 , distance traveled: 133.76351595777535 , average speed: 0.09225070066053473 , explore ratio: 0.5274433342948263\n",
      "Episode 144 , steps =  72 , total reward: -5.914799311719224 , steps_avg: 636.1379310344828 , reward_avg: -53.83857471738235 , distance traveled: 5.913556218438317 , average speed: 0.08213272525608774 , explore ratio: 0.5264004018717342\n",
      "Episode 145 , steps =  50 , total reward: -2.258359769753493 , steps_avg: 632.1232876712329 , reward_avg: -53.485285573905436 , distance traveled: 7.237820596396922 , average speed: 0.14475641192793845 , explore ratio: 0.5253595316759344\n",
      "Episode 146 , steps =  155 , total reward: -38.77889798155363 , steps_avg: 628.8775510204082 , reward_avg: -53.38524212089624 , distance traveled: -8.59845538537949 , average speed: -0.05547390571212574 , explore ratio: 0.5243207196297117\n",
      "Episode 147 , steps =  2811 , total reward: -172.90495038454972 , steps_avg: 643.6216216216217 , reward_avg: -54.19280771727228 , distance traveled: 203.34818774327223 , average speed: 0.0723401592825586 , explore ratio: 0.523283961663414\n",
      "Episode 148 , steps =  102 , total reward: -21.445358122487242 , steps_avg: 639.9865771812081 , reward_avg: -53.97302617636768 , distance traveled: -4.376255199727602 , average speed: -0.04290446274242747 , explore ratio: 0.522249253715436\n",
      "Episode 149 , steps =  63 , total reward: -4.111737078549964 , steps_avg: 636.14 , reward_avg: -53.64061758238223 , distance traveled: 4.922403099238873 , average speed: 0.07813338252760116 , explore ratio: 0.5212165917322038\n",
      "Episode 150 , steps =  757 , total reward: 6.230417672334175 , steps_avg: 636.9403973509934 , reward_avg: -53.24412066016556 , distance traveled: 129.4622904771008 , average speed: 0.17102019878084648 , explore ratio: 0.5201859716681587\n",
      "Episode 151 , steps =  106 , total reward: -25.242254401952657 , steps_avg: 633.4473684210526 , reward_avg: -53.05989785583522 , distance traveled: -9.681955012693068 , average speed: -0.09133919823295347 , explore ratio: 0.5191573894857415\n",
      "Episode 152 , steps =  127 , total reward: -26.809761043224476 , steps_avg: 630.1372549019608 , reward_avg: -52.888328334184166 , distance traveled: -18.759914534110575 , average speed: -0.14771586247331162 , explore ratio: 0.5181308411553764\n",
      "Episode 153 , steps =  109 , total reward: -29.130658090665925 , steps_avg: 626.7532467532468 , reward_avg: -52.73405774818729 , distance traveled: -13.38408038366586 , average speed: -0.12278972829051249 , explore ratio: 0.5171063226554558\n",
      "Episode 154 , steps =  715 , total reward: -28.27486435536244 , steps_avg: 627.3225806451613 , reward_avg: -52.576256500491645 , distance traveled: 74.49329413924367 , average speed: 0.10418642536957157 , explore ratio: 0.5160838299723236\n",
      "Episode 155 , steps =  59 , total reward: -15.64219422869571 , steps_avg: 623.6794871794872 , reward_avg: -52.33949969105706 , distance traveled: -3.9646201040223232 , average speed: -0.0671969509156326 , explore ratio: 0.5150633591002606\n",
      "Episode 156 , steps =  39 , total reward: -17.890298067637403 , steps_avg: 619.9554140127389 , reward_avg: -52.12007802466585 , distance traveled: -1.9180395859479906 , average speed: -0.04918050220379463 , explore ratio: 0.5140449060414679\n",
      "Episode 157 , steps =  61 , total reward: -6.749764341840525 , steps_avg: 616.4177215189874 , reward_avg: -51.832924140597335 , distance traveled: 2.9317510847747323 , average speed: 0.048061493193028396 , explore ratio: 0.5130284668060517\n",
      "Episode 158 , steps =  85 , total reward: -13.554017301015561 , steps_avg: 613.0754716981132 , reward_avg: -51.59217629883896 , distance traveled: 2.3520127092401326 , average speed: 0.027670737755766266 , explore ratio: 0.5120140374120078\n",
      "Episode 159 , steps =  144 , total reward: -28.482435412545357 , steps_avg: 610.14375 , reward_avg: -51.44774041829963 , distance traveled: -7.940663234582171 , average speed: -0.055143494684598414 , explore ratio: 0.5110016138852053\n",
      "Episode 160 , steps =  42 , total reward: -18.41499274944826 , steps_avg: 606.6149068322982 , reward_avg: -51.242568072530375 , distance traveled: -1.623086912278086 , average speed: -0.03864492648281157 , explore ratio: 0.5099911922593717\n",
      "Episode 161 , steps =  232 , total reward: -15.086377921501136 , steps_avg: 604.3024691358024 , reward_avg: -51.019381713573395 , distance traveled: 19.66533259900286 , average speed: 0.08476436465087439 , explore ratio: 0.5089827685760773\n",
      "Episode 162 , steps =  86 , total reward: -18.273448164799568 , steps_avg: 601.1226993865031 , reward_avg: -50.81848641572816 , distance traveled: -3.5198925840854636 , average speed: -0.04092898353587748 , explore ratio: 0.5079763388847193\n",
      "Episode 163 , steps =  324 , total reward: -35.68966803774401 , steps_avg: 599.4329268292682 , reward_avg: -50.72623752317947 , distance traveled: 9.651327837836002 , average speed: 0.029788048882209883 , explore ratio: 0.5069718992425067\n",
      "Episode 164 , steps =  57 , total reward: -2.711358860941605 , steps_avg: 596.1454545454545 , reward_avg: -50.435238258559856 , distance traveled: 8.108572592586281 , average speed: 0.14225565951905755 , explore ratio: 0.5059694457144448\n",
      "Episode 165 , steps =  53 , total reward: -2.258696793231498 , steps_avg: 592.8734939759037 , reward_avg: -50.145018129250644 , distance traveled: 7.502897447347641 , average speed: 0.14156410278014417 , explore ratio: 0.5049689743733196\n",
      "Episode 166 , steps =  571 , total reward: -18.17774046853574 , steps_avg: 592.7425149700599 , reward_avg: -49.953597304934995 , distance traveled: 67.12405889427987 , average speed: 0.11755526951712762 , explore ratio: 0.5039704812996824\n",
      "Episode 167 , steps =  82 , total reward: -28.81960156610174 , steps_avg: 589.702380952381 , reward_avg: -49.82779971125146 , distance traveled: -14.301611847169697 , average speed: -0.17440990057524022 , explore ratio: 0.5029739625818347\n",
      "Episode 168 , steps =  79 , total reward: -16.717951218658435 , steps_avg: 586.6804733727811 , reward_avg: -49.63188344798167 , distance traveled: -5.115979558378457 , average speed: -0.06475923491618299 , explore ratio: 0.5019794143158128\n",
      "Episode 169 , steps =  1399 , total reward: -70.69444222137794 , steps_avg: 591.4588235294118 , reward_avg: -49.75578085253107 , distance traveled: 123.89591634524908 , average speed: 0.0885603404898135 , explore ratio: 0.5009868326053725\n",
      "Episode 170 , steps =  111 , total reward: -0.7907654412848284 , steps_avg: 588.6491228070175 , reward_avg: -49.46943573316705 , distance traveled: 19.43118172377347 , average speed: 0.1750556912051664 , explore ratio: 0.49999621356197343\n",
      "Episode 171 , steps =  307 , total reward: -31.7292570797594 , steps_avg: 587.0116279069767 , reward_avg: -49.36629515960073 , distance traveled: 7.505468828603625 , average speed: 0.024447781200663276 , explore ratio: 0.49900755330476454\n",
      "Episode 172 , steps =  69 , total reward: -20.786577627210576 , steps_avg: 584.0173410404624 , reward_avg: -49.20109448022275 , distance traveled: -6.5759785673394795 , average speed: -0.09530403720781855 , explore ratio: 0.4980208479605683\n",
      "Episode 173 , steps =  67 , total reward: -20.712271131205064 , steps_avg: 581.0459770114943 , reward_avg: -49.037365610400805 , distance traveled: -9.578547433018688 , average speed: -0.142963394522667 , explore ratio: 0.49703609366386586\n",
      "Episode 174 , steps =  102 , total reward: -12.855021524174145 , steps_avg: 578.3085714285714 , reward_avg: -48.83060935847951 , distance traveled: 2.1373749261349437 , average speed: 0.02095465613857788 , explore ratio: 0.49605328655678177\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 175 , steps =  62 , total reward: -6.898491012602425 , steps_avg: 575.375 , reward_avg: -48.59235868605976 , distance traveled: 5.398861061520873 , average speed: 0.0870784042180786 , explore ratio: 0.49507242278906893\n",
      "Episode 176 , steps =  61 , total reward: -6.342061378444852 , steps_avg: 572.4689265536723 , reward_avg: -48.35365644138396 , distance traveled: 3.622306054774671 , average speed: 0.05938206647171592 , explore ratio: 0.4940934985180934\n",
      "Episode 177 , steps =  73 , total reward: -9.470619373393564 , steps_avg: 569.6629213483146 , reward_avg: -48.13521241291211 , distance traveled: 3.5896953993290657 , average speed: 0.04917390957985021 , explore ratio: 0.4931165099088195\n",
      "Episode 178 , steps =  135 , total reward: -23.876489426841303 , steps_avg: 567.2346368715084 , reward_avg: -47.99968882081115 , distance traveled: -4.796369927627965 , average speed: -0.03552866613057752 , explore ratio: 0.49214145313379454\n",
      "Episode 179 , steps =  76 , total reward: -3.367437896649045 , steps_avg: 564.5055555555556 , reward_avg: -47.75173187123247 , distance traveled: 7.754570743739603 , average speed: 0.1020338255755211 , explore ratio: 0.4911683243731342\n",
      "Episode 180 , steps =  133 , total reward: -27.604544960807395 , steps_avg: 562.121546961326 , reward_avg: -47.640421446313 , distance traveled: -12.25826608143746 , average speed: -0.09216741414614632 , explore ratio: 0.4901971198145072\n",
      "Episode 181 , steps =  228 , total reward: -8.656964376252784 , steps_avg: 560.2857142857143 , reward_avg: -47.426226627246734 , distance traveled: 27.04120496895163 , average speed: 0.1186017761796124 , explore ratio: 0.4892278356531206\n",
      "Episode 182 , steps =  62 , total reward: -12.017034488180037 , steps_avg: 557.5628415300547 , reward_avg: -47.23273377402778 , distance traveled: -5.467597611844538 , average speed: -0.08818705825555707 , explore ratio: 0.4882604680917048\n",
      "Episode 183 , steps =  68 , total reward: -2.5018630682714345 , steps_avg: 554.9021739130435 , reward_avg: -46.989631215844334 , distance traveled: 7.566788365691899 , average speed: 0.1112762994954691 , explore ratio: 0.4872950133404987\n",
      "Episode 184 , steps =  57 , total reward: -3.3947001141489745 , steps_avg: 552.2108108108108 , reward_avg: -46.75398293961895 , distance traveled: 7.447015439271926 , average speed: 0.1306493936714373 , explore ratio: 0.48633146761723467\n",
      "Episode 185 , steps =  49 , total reward: -2.2020282523787276 , steps_avg: 549.505376344086 , reward_avg: -46.51445630151551 , distance traveled: 6.994734073877335 , average speed: 0.14274967497708846 , explore ratio: 0.48536982714712407\n",
      "Episode 186 , steps =  72 , total reward: -19.661415761764488 , steps_avg: 546.951871657754 , reward_avg: -46.370857154244106 , distance traveled: -10.260011794567106 , average speed: -0.14250016381343203 , explore ratio: 0.48441008816284226\n",
      "Episode 187 , steps =  47 , total reward: -11.300921935789287 , steps_avg: 544.2925531914893 , reward_avg: -46.18431494563531 , distance traveled: 2.780713820680976 , average speed: 0.059164123844276086 , explore ratio: 0.48345224690451377\n",
      "Episode 188 , steps =  61 , total reward: -10.439416557921096 , steps_avg: 541.7354497354497 , reward_avg: -45.99518849913947 , distance traveled: -1.9246557750552893 , average speed: -0.031551734017299826 , explore ratio: 0.48249629961969775\n",
      "Episode 189 , steps =  68 , total reward: -7.891333960400898 , steps_avg: 539.2421052631579 , reward_avg: -45.794641896304 , distance traveled: 4.358041526153683 , average speed: 0.06408884597284828 , explore ratio: 0.4815422425633732\n",
      "Episode 190 , steps =  103 , total reward: -20.973676488986868 , steps_avg: 536.958115183246 , reward_avg: -45.664689197836374 , distance traveled: -3.8339041033387167 , average speed: -0.03722236993532735 , explore ratio: 0.4805900719979242\n",
      "Episode 191 , steps =  42 , total reward: -19.21332640756792 , steps_avg: 534.3802083333334 , reward_avg: -45.526921683303726 , distance traveled: -2.3400197872705752 , average speed: -0.0557147568397756 , explore ratio: 0.4796397841931254\n",
      "Episode 192 , steps =  73 , total reward: -8.894049562874573 , steps_avg: 531.9896373056995 , reward_avg: -45.337114055736734 , distance traveled: 3.2600204676948494 , average speed: 0.04465781462595684 , explore ratio: 0.4786913754261274\n",
      "Episode 193 , steps =  205 , total reward: -17.365854551096746 , steps_avg: 530.3041237113403 , reward_avg: -45.192932305712816 , distance traveled: 16.456908369474114 , average speed: 0.08027760180231275 , explore ratio: 0.47774484198144196\n",
      "Episode 194 , steps =  620 , total reward: -26.82704460470928 , steps_avg: 530.7641025641026 , reward_avg: -45.09874826622048 , distance traveled: 67.37080042633224 , average speed: 0.10866258133279393 , explore ratio: 0.4768001801509278\n",
      "Episode 195 , steps =  145 , total reward: -20.0035044187524 , steps_avg: 528.795918367347 , reward_avg: -44.970711307815044 , distance traveled: -2.9065414982289077 , average speed: -0.02004511378088902 , explore ratio: 0.47585738623377577\n",
      "Episode 196 , steps =  63 , total reward: -8.62937379497166 , steps_avg: 526.4314720812183 , reward_avg: -44.786237513333596 , distance traveled: 2.5513092086836693 , average speed: 0.04049697156640745 , explore ratio: 0.4749164565364945\n",
      "Episode 197 , steps =  169 , total reward: -17.786951230732107 , steps_avg: 524.6262626262626 , reward_avg: -44.6498774816033 , distance traveled: 8.475341636817902 , average speed: 0.050149950513715395 , explore ratio: 0.4739773873728959\n",
      "Episode 198 , steps =  41 , total reward: -20.464898028166957 , steps_avg: 522.1959798994975 , reward_avg: -44.528344921535776 , distance traveled: -3.1924498361349105 , average speed: -0.07786463014963196 , explore ratio: 0.47304017506408064\n",
      "Episode 199 , steps =  75 , total reward: -5.164051563280323 , steps_avg: 519.96 , reward_avg: -44.33152345474449 , distance traveled: 7.139317090474071 , average speed: 0.09519089453965428 , explore ratio: 0.4721048159384239\n",
      "Episode 200 , steps =  58 , total reward: -2.018691319740069 , steps_avg: 517.6616915422885 , reward_avg: -44.12101185208279 , distance traveled: 9.169562047719953 , average speed: 0.15809589737448196 , explore ratio: 0.47117130633156085\n",
      "Episode 201 , steps =  140 , total reward: -12.977114985194065 , steps_avg: 515.7920792079208 , reward_avg: -43.96683414482096 , distance traveled: 9.179393948391079 , average speed: 0.06556709963136485 , explore ratio: 0.47023964258637235\n",
      "Episode 202 , steps =  432 , total reward: -31.293228113550878 , steps_avg: 515.3793103448276 , reward_avg: -43.904402588016666 , distance traveled: 34.58376010947861 , average speed: 0.08005500025342271 , explore ratio: 0.4693098210529706\n",
      "Episode 203 , steps =  55 , total reward: -1.391318628595526 , steps_avg: 513.1225490196078 , reward_avg: -43.69600511762735 , distance traveled: 8.312498602867127 , average speed: 0.15113633823394776 , explore ratio: 0.46838183808868483\n",
      "Episode 204 , steps =  318 , total reward: -23.558095498920636 , steps_avg: 512.170731707317 , reward_avg: -43.597771412170246 , distance traveled: 23.384163309261215 , average speed: 0.07353510474610445 , explore ratio: 0.4674556900580471\n",
      "Episode 205 , steps =  1391 , total reward: -70.07936752396017 , steps_avg: 516.4368932038835 , reward_avg: -43.72632284960611 , distance traveled: 121.98874451599819 , average speed: 0.08769859418835241 , explore ratio: 0.466531373332778\n",
      "Episode 206 , steps =  81 , total reward: -4.004334879410145 , steps_avg: 514.3333333333334 , reward_avg: -43.534429187914355 , distance traveled: 9.40067582560703 , average speed: 0.11605772624206209 , explore ratio: 0.4656088842917724\n",
      "Episode 207 , steps =  85 , total reward: -18.857715676805633 , steps_avg: 512.2692307692307 , reward_avg: -43.41579114218787 , distance traveled: -11.016079041659827 , average speed: -0.12960092990188032 , explore ratio: 0.46468821932108534\n",
      "Episode 208 , steps =  80 , total reward: -19.220486978609117 , steps_avg: 510.20095693779905 , reward_avg: -43.30002413662051 , distance traveled: -11.699118252396582 , average speed: -0.1462389781549573 , explore ratio: 0.4637693748139179\n",
      "Episode 209 , steps =  68 , total reward: -11.988475591252246 , steps_avg: 508.0952380952381 , reward_avg: -43.1509215244997 , distance traveled: -2.9017944293841715 , average speed: -0.0426734474909437 , explore ratio: 0.4628523471706029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 210 , steps =  49 , total reward: -6.062110830941553 , steps_avg: 505.9194312796209 , reward_avg: -42.975145170501804 , distance traveled: 0.9565123033791316 , average speed: 0.01952065925263534 , explore ratio: 0.46193713279859105\n",
      "Episode 211 , steps =  333 , total reward: -4.435631587071368 , steps_avg: 505.10377358490564 , reward_avg: -42.7933550120894 , distance traveled: 48.26744876861573 , average speed: 0.14494729359944664 , explore ratio: 0.4610237281124366\n",
      "Episode 212 , steps =  82 , total reward: -12.430152137070895 , steps_avg: 503.11737089201876 , reward_avg: -42.65080476384987 , distance traveled: -0.3197669030190438 , average speed: -0.003899596378281022 , explore ratio: 0.46011212953378344\n",
      "Episode 213 , steps =  233 , total reward: -14.008168265335893 , steps_avg: 501.8551401869159 , reward_avg: -42.51696066806242 , distance traveled: 19.363130719810727 , average speed: 0.08310356532107607 , explore ratio: 0.45920233349135114\n",
      "Episode 214 , steps =  364 , total reward: -8.657464533546353 , steps_avg: 501.2139534883721 , reward_avg: -42.35947463952979 , distance traveled: 44.85236514497548 , average speed: 0.12322078336531725 , explore ratio: 0.4582943364209209\n",
      "Episode 215 , steps =  44 , total reward: -25.250932432427376 , steps_avg: 499.09722222222223 , reward_avg: -42.28026842560802 , distance traveled: -5.031009615808725 , average speed: -0.11434112763201648 , explore ratio: 0.4573881347653215\n",
      "Episode 216 , steps =  53 , total reward: -9.098476406898351 , steps_avg: 497.0414746543779 , reward_avg: -42.12735694165083 , distance traveled: 1.9458753450214858 , average speed: 0.036714629151348786 , explore ratio: 0.4564837249744155\n",
      "Episode 217 , steps =  81 , total reward: -21.934381137013446 , steps_avg: 495.1330275229358 , reward_avg: -42.03472861227176 , distance traveled: -15.813649379722774 , average speed: -0.1952302392558367 , explore ratio: 0.4555811035050852\n",
      "Episode 218 , steps =  158 , total reward: -27.88093106734008 , steps_avg: 493.5936073059361 , reward_avg: -41.97009939973783 , distance traveled: -1.3252616799250259 , average speed: -0.008387732151424214 , explore ratio: 0.4546802668212189\n",
      "Episode 219 , steps =  911 , total reward: -58.256804573770665 , steps_avg: 495.4909090909091 , reward_avg: -42.044129877801616 , distance traveled: 65.7840443252027 , average speed: 0.0722108060649865 , explore ratio: 0.45378121139369704\n",
      "Episode 220 , steps =  152 , total reward: -23.981943215230473 , steps_avg: 493.9366515837104 , reward_avg: -41.96240052638727 , distance traveled: -0.34546317843720337 , average speed: -0.0022727840686658117 , explore ratio: 0.45288393370037816\n",
      "Episode 221 , steps =  59 , total reward: -10.290172478012114 , steps_avg: 491.97747747747746 , reward_avg: -41.819732832475665 , distance traveled: 0.34838180266320723 , average speed: 0.005904776316325546 , explore ratio: 0.4519884302260853\n",
      "Episode 222 , steps =  64 , total reward: 1.709151768604909 , steps_avg: 490.05829596412553 , reward_avg: -41.62453604054257 , distance traveled: 12.86963780522347 , average speed: 0.2010880907066167 , explore ratio: 0.45109469746259234\n",
      "Episode 223 , steps =  214 , total reward: -7.4408183663853915 , steps_avg: 488.82589285714283 , reward_avg: -41.471930158068645 , distance traveled: 25.41177134122699 , average speed: 0.11874659505246257 , explore ratio: 0.4502027319086099\n",
      "Episode 224 , steps =  1266 , total reward: -107.96185574868139 , steps_avg: 492.28 , reward_avg: -41.76744093847137 , distance traveled: 58.1374000658747 , average speed: 0.04592211695566722 , explore ratio: 0.44931253006977184\n",
      "Episode 225 , steps =  2721 , total reward: -194.7507104839217 , steps_avg: 502.14159292035396 , reward_avg: -42.44435806035389 , distance traveled: 158.33440304499962 , average speed: 0.05818978428702669 , explore ratio: 0.4484240884586217\n",
      "Episode 226 , steps =  49 , total reward: -22.485119903595503 , steps_avg: 500.1453744493392 , reward_avg: -42.356431901073016 , distance traveled: -3.5998591336025854 , average speed: -0.073466512930665 , explore ratio: 0.44753740359459876\n",
      "Episode 227 , steps =  112 , total reward: -14.79880183090394 , steps_avg: 498.4429824561403 , reward_avg: -42.235565102519644 , distance traveled: 2.0525881540775304 , average speed: 0.018326679947120807 , explore ratio: 0.44665247200402464\n",
      "Episode 228 , steps =  53 , total reward: -16.102842092641943 , steps_avg: 496.49781659388645 , reward_avg: -42.12144840815336 , distance traveled: -8.60185901105404 , average speed: -0.16229922662366114 , explore ratio: 0.4457692902200895\n",
      "Episode 229 , steps =  395 , total reward: -22.56162778888202 , steps_avg: 496.05652173913046 , reward_avg: -42.03640570980872 , distance traveled: 35.46346663210544 , average speed: 0.0897809281825454 , explore ratio: 0.4448878547828385\n",
      "Episode 230 , steps =  76 , total reward: -16.318285016409433 , steps_avg: 494.23809523809524 , reward_avg: -41.92507185399313 , distance traveled: -0.9122706873714925 , average speed: -0.012003561675940692 , explore ratio: 0.44400816223915845\n",
      "Episode 231 , steps =  54 , total reward: -10.697107390890523 , steps_avg: 492.3405172413793 , reward_avg: -41.79046855889355 , distance traveled: 1.4904296256601812 , average speed: 0.02760054862333669 , explore ratio: 0.443130209142764\n",
      "Episode 232 , steps =  73 , total reward: -16.498099747195226 , steps_avg: 490.54077253218884 , reward_avg: -41.68191761978755 , distance traveled: -4.061843829955905 , average speed: -0.055641696300765826 , explore ratio: 0.44225399205418436\n",
      "Episode 233 , steps =  64 , total reward: -1.713779947225631 , steps_avg: 488.71794871794873 , reward_avg: -41.511113612639846 , distance traveled: 9.031266911588608 , average speed: 0.141113545493572 , explore ratio: 0.4413795075407496\n",
      "Episode 234 , steps =  74 , total reward: -1.2311987812370093 , steps_avg: 486.9531914893617 , reward_avg: -41.33970971974026 , distance traveled: 10.589094758480789 , average speed: 0.14309587511460525 , explore ratio: 0.4405067521765775\n",
      "Episode 235 , steps =  63 , total reward: -5.802226210789764 , steps_avg: 485.15677966101697 , reward_avg: -41.18912716249895 , distance traveled: 5.0938892345130435 , average speed: 0.08085538467481021 , explore ratio: 0.4396357225425597\n",
      "Episode 236 , steps =  340 , total reward: -27.422127421144207 , steps_avg: 484.54430379746833 , reward_avg: -41.13103855599534 , distance traveled: 20.635455102687697 , average speed: 0.06069251500790499 , explore ratio: 0.43876641522634885\n",
      "Episode 237 , steps =  184 , total reward: -31.68017583635509 , steps_avg: 483.281512605042 , reward_avg: -41.09132904876996 , distance traveled: -8.907130560502415 , average speed: -0.04840831826360008 , explore ratio: 0.43789882682234477\n",
      "Episode 238 , steps =  62 , total reward: -5.917582571127146 , steps_avg: 481.5188284518828 , reward_avg: -40.944158561415804 , distance traveled: 3.5388335640728474 , average speed: 0.05707796071085238 , explore ratio: 0.43703295393168134\n",
      "Episode 239 , steps =  71 , total reward: -13.14528040352091 , steps_avg: 479.80833333333334 , reward_avg: -40.82832990242458 , distance traveled: -0.48739187669008954 , average speed: -0.006864674319578726 , explore ratio: 0.4361687931622132\n",
      "Episode 240 , steps =  67 , total reward: -0.2888581540491421 , steps_avg: 478.0954356846473 , reward_avg: -40.66011632670518 , distance traveled: 11.743454541563992 , average speed: 0.17527544091886554 , explore ratio: 0.4353063411285023\n",
      "Episode 241 , steps =  58 , total reward: -3.058876137429851 , steps_avg: 476.3595041322314 , reward_avg: -40.50473930112966 , distance traveled: 6.9097613775730125 , average speed: 0.11913381685470711 , explore ratio: 0.43444559445180486\n",
      "Episode 242 , steps =  142 , total reward: -3.9953385769973284 , steps_avg: 474.9835390946502 , reward_avg: -40.35449485370525 , distance traveled: 26.54298212438822 , average speed: 0.1869224093266776 , explore ratio: 0.4335865497600579\n",
      "Episode 243 , steps =  51 , total reward: -16.125105695356304 , steps_avg: 473.24590163934425 , reward_avg: -40.25519407846611 , distance traveled: -6.36471945092082 , average speed: -0.12479842060629058 , explore ratio: 0.43272920368786616\n",
      "Episode 244 , steps =  516 , total reward: -23.26923334665412 , steps_avg: 473.4204081632653 , reward_avg: -40.18586362649953 , distance traveled: 55.99845331639064 , average speed: 0.10852413433409039 , explore ratio: 0.43187355287648893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 245 , steps =  64 , total reward: -10.57609550990971 , steps_avg: 471.7560975609756 , reward_avg: -40.065498715456485 , distance traveled: 3.1351519225537774 , average speed: 0.04898674878990277 , explore ratio: 0.43101959397382683\n",
      "Episode 246 , steps =  40 , total reward: -17.405019578446336 , steps_avg: 470.0080971659919 , reward_avg: -39.97375588494228 , distance traveled: -2.8309115785360337 , average speed: -0.07077278946340085 , explore ratio: 0.4301673236344087\n",
      "Episode 247 , steps =  59 , total reward: -0.7462621024704187 , steps_avg: 468.3508064516129 , reward_avg: -39.81558050678715 , distance traveled: 10.007517490983009 , average speed: 0.16961894052513574 , explore ratio: 0.4293167385193785\n",
      "Episode 248 , steps =  50 , total reward: -13.772383856972056 , steps_avg: 466.6706827309237 , reward_avg: -39.71098935558307 , distance traveled: -0.4504053195565938 , average speed: -0.009008106391131875 , explore ratio: 0.4284678352964823\n",
      "Episode 249 , steps =  84 , total reward: -12.499914195353172 , steps_avg: 465.14 , reward_avg: -39.60214505494215 , distance traveled: 3.8915332242473966 , average speed: 0.04632777647913568 , explore ratio: 0.4276206106400551\n",
      "Episode 250 , steps =  3471 , total reward: -202.1494473498809 , steps_avg: 477.1155378486056 , reward_avg: -40.249743868866204 , distance traveled: 263.5817075840155 , average speed: 0.07593826205243892 , explore ratio: 0.4267750612310077\n",
      "Episode 251 , steps =  1421 , total reward: -118.21601896346903 , steps_avg: 480.8611111111111 , reward_avg: -40.55913384940035 , distance traveled: 62.78057351533323 , average speed: 0.04418055842036118 , explore ratio: 0.4259311837568142\n",
      "Episode 252 , steps =  298 , total reward: -11.85728113403298 , steps_avg: 480.1383399209486 , reward_avg: -40.445687791236836 , distance traveled: 33.690202607363474 , average speed: 0.11305437116564925 , explore ratio: 0.4250889749114984\n",
      "Episode 253 , steps =  62 , total reward: -5.581536900124203 , steps_avg: 478.49212598425197 , reward_avg: -40.30842735465765 , distance traveled: 4.31164201810956 , average speed: 0.06954261319531549 , explore ratio: 0.4242484313956212\n",
      "Episode 254 , steps =  71 , total reward: -10.149034343415872 , steps_avg: 476.8941176470588 , reward_avg: -40.190155225201806 , distance traveled: 3.2676110389083624 , average speed: 0.046022690688850176 , explore ratio: 0.42340954991626756\n",
      "Episode 255 , steps =  752 , total reward: -28.484155884542687 , steps_avg: 477.96875 , reward_avg: -40.14442866527736 , distance traveled: 81.42751907609401 , average speed: 0.1082812753671463 , explore ratio: 0.42257232718703375\n",
      "Episode 256 , steps =  41 , total reward: -15.18882390805024 , steps_avg: 476.2684824902724 , reward_avg: -40.047325144821215 , distance traveled: -0.7001728063635527 , average speed: -0.017077385521062263 , explore ratio: 0.42173675992801424\n",
      "Episode 257 , steps =  322 , total reward: -18.756007372652512 , steps_avg: 475.67054263565893 , reward_avg: -39.96480065733219 , distance traveled: 32.26954930094769 , average speed: 0.10021599161784996 , explore ratio: 0.42090284486578905\n",
      "Episode 258 , steps =  41 , total reward: -21.999648094082247 , steps_avg: 473.992277992278 , reward_avg: -39.89543713392196 , distance traveled: -3.1935938850045202 , average speed: -0.07789253378059806 , explore ratio: 0.42007057873341086\n",
      "Episode 259 , steps =  58 , total reward: -0.05676769742494375 , steps_avg: 472.39230769230767 , reward_avg: -39.74221148224313 , distance traveled: 9.698253196477891 , average speed: 0.1672112620082395 , explore ratio: 0.4192399582703921\n",
      "Episode 260 , steps =  786 , total reward: -51.79704536675939 , steps_avg: 473.5938697318008 , reward_avg: -39.78839858524894 , distance traveled: 53.17145945985046 , average speed: 0.06764816725171814 , explore ratio: 0.4184109802226924\n",
      "Episode 261 , steps =  74 , total reward: -10.509101493754734 , steps_avg: 472.0687022900763 , reward_avg: -39.67664554291499 , distance traveled: -0.24034831434488316 , average speed: -0.0032479501938497725 , explore ratio: 0.4175836413427056\n",
      "Episode 262 , steps =  63 , total reward: 0.39350992853380395 , steps_avg: 470.51330798479086 , reward_avg: -39.52428753732013 , distance traveled: 11.701864753961564 , average speed: 0.18574388498351688 , explore ratio: 0.41675793838924724\n",
      "Episode 263 , steps =  89 , total reward: -23.974515118156887 , steps_avg: 469.0681818181818 , reward_avg: -39.46538688421723 , distance traveled: -4.69325326462509 , average speed: -0.05273318274859652 , explore ratio: 0.41593386812754174\n",
      "Episode 264 , steps =  6476 , total reward: -360.9176781380587 , steps_avg: 491.7358490566038 , reward_avg: -40.67841439838267 , distance traveled: 507.6337838174496 , average speed: 0.07838693388163212 , explore ratio: 0.41511142732920975\n",
      "Episode 265 , steps =  1811 , total reward: -111.05179166180109 , steps_avg: 496.6954887218045 , reward_avg: -40.94297596704214 , distance traveled: 135.15686972645113 , average speed: 0.07463107108031537 , explore ratio: 0.41429061277225554\n",
      "Episode 266 , steps =  119 , total reward: 3.30217596869108 , steps_avg: 495.2808988764045 , reward_avg: -40.77726378750756 , distance traveled: 26.696718757152553 , average speed: 0.22434217442985338 , explore ratio: 0.4134714212410543\n",
      "Episode 267 , steps =  1811 , total reward: -117.72309772236349 , steps_avg: 500.19029850746267 , reward_avg: -41.06437510816001 , distance traveled: 128.26831970091163 , average speed: 0.07082734384368394 , explore ratio: 0.4126538495263396\n",
      "Episode 268 , steps =  171 , total reward: -11.498129917266484 , steps_avg: 498.96654275092936 , reward_avg: -40.95446341600055 , distance traveled: 15.560077168419957 , average speed: 0.09099460332409331 , explore ratio: 0.4118378944251908\n",
      "Episode 269 , steps =  784 , total reward: -28.309375207903628 , steps_avg: 500.02222222222224 , reward_avg: -40.90762975597056 , distance traveled: 90.13837637446765 , average speed: 0.11497241884498426 , explore ratio: 0.4110235527410206\n",
      "Episode 270 , steps =  70 , total reward: -6.935476040601113 , steps_avg: 498.43542435424354 , reward_avg: -40.78227125517584 , distance traveled: 9.750698660910128 , average speed: 0.13929569515585896 , explore ratio: 0.4102108212835623\n",
      "Episode 271 , steps =  59 , total reward: -13.1108893710735 , steps_avg: 496.81985294117646 , reward_avg: -40.68053823354312 , distance traveled: -3.8447583069652316 , average speed: -0.06516539503330901 , explore ratio: 0.40939969686885747\n",
      "Episode 272 , steps =  4949 , total reward: -189.107870700053 , steps_avg: 513.1282051282051 , reward_avg: -41.2242280960578 , distance traveled: 506.07066204165017 , average speed: 0.10225715539334213 , explore ratio: 0.40859017631924344\n",
      "Episode 273 , steps =  255 , total reward: -49.75629918374733 , steps_avg: 512.1861313868613 , reward_avg: -41.25536704163331 , distance traveled: -27.862915007919074 , average speed: -0.10926633336438853 , explore ratio: 0.4077822564633409\n",
      "Episode 274 , steps =  2396 , total reward: -108.67779925867632 , steps_avg: 519.0363636363636 , reward_avg: -41.50053952242256 , distance traveled: 233.93799467269312 , average speed: 0.09763689260129095 , explore ratio: 0.4069759341360413\n",
      "Episode 275 , steps =  67 , total reward: -5.70270549848304 , steps_avg: 517.3985507246376 , reward_avg: -41.37083722523437 , distance traveled: 7.177467696368692 , average speed: 0.10712638352789092 , explore ratio: 0.4061712061784946\n",
      "Episode 276 , steps =  74 , total reward: -14.300415248338762 , steps_avg: 515.797833935018 , reward_avg: -41.27311007008312 , distance traveled: 1.419678184613586 , average speed: 0.019184840332616027 , explore ratio: 0.40536806943809706\n",
      "Episode 277 , steps =  64 , total reward: -9.832768931707367 , steps_avg: 514.1726618705036 , reward_avg: -41.16001531778681 , distance traveled: 2.165764480722137 , average speed: 0.03384007001128339 , explore ratio: 0.40456652076847843\n",
      "Episode 278 , steps =  63 , total reward: -9.46461929860587 , steps_avg: 512.5555555555555 , reward_avg: -41.04641174782559 , distance traveled: 3.2031481299921873 , average speed: 0.0508436211109871 , explore ratio: 0.40376655702949005\n",
      "Episode 279 , steps =  403 , total reward: -16.022198087747423 , steps_avg: 512.1642857142857 , reward_avg: -40.95703955618245 , distance traveled: 50.165537149300825 , average speed: 0.12448024106526259 , explore ratio: 0.4029681750871923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 280 , steps =  54 , total reward: -9.160526830344772 , steps_avg: 510.5338078291815 , reward_avg: -40.84388470662431 , distance traveled: 2.1243235981464386 , average speed: 0.03933932589160071 , explore ratio: 0.40217137181384244\n",
      "Episode 281 , steps =  395 , total reward: -8.020192283007047 , steps_avg: 510.1241134751773 , reward_avg: -40.727488634200135 , distance traveled: 56.4102481484553 , average speed: 0.14281075480621597 , explore ratio: 0.40137614408788236\n",
      "Episode 282 , steps =  77 , total reward: -4.786271391255786 , steps_avg: 508.59363957597174 , reward_avg: -40.600487866557216 , distance traveled: 15.8030546683073 , average speed: 0.20523447621178312 , explore ratio: 0.4005824887939263\n",
      "Episode 283 , steps =  71 , total reward: -22.83573296022105 , steps_avg: 507.05281690140845 , reward_avg: -40.53793591266167 , distance traveled: -5.60004294913262 , average speed: -0.07887384435398057 , explore ratio: 0.3997904028227486\n",
      "Episode 284 , steps =  221 , total reward: -49.216127196862026 , steps_avg: 506.04912280701757 , reward_avg: -40.56838570664132 , distance traveled: -15.80797348514199 , average speed: -0.0715292917879728 , explore ratio: 0.3989998830712717\n",
      "Episode 285 , steps =  55 , total reward: -4.270378374901292 , steps_avg: 504.47202797202794 , reward_avg: -40.441469597089785 , distance traveled: 7.417697272114456 , average speed: 0.13486722312935373 , explore ratio: 0.3982109264425538\n",
      "Episode 286 , steps =  64 , total reward: -21.105797288432107 , steps_avg: 502.93728222996515 , reward_avg: -40.37409791657181 , distance traveled: -6.423271839022635 , average speed: -0.10036362248472867 , explore ratio: 0.3974235298457768\n",
      "Episode 287 , steps =  53 , total reward: -3.4658394385942564 , steps_avg: 501.375 , reward_avg: -40.24594424130105 , distance traveled: 7.063270293474194 , average speed: 0.13326925082026783 , explore ratio: 0.3966376901962341\n",
      "Episode 288 , steps =  361 , total reward: -18.866749684172344 , steps_avg: 500.88927335640136 , reward_avg: -40.17196778954629 , distance traveled: 35.17833751861008 , average speed: 0.09744691833409994 , explore ratio: 0.3958534044153188\n",
      "Episode 289 , steps =  93 , total reward: -12.758397729276377 , steps_avg: 499.48275862068965 , reward_avg: -40.077438237614324 , distance traveled: 7.282653256952762 , average speed: 0.07830809953712647 , explore ratio: 0.3950706694305112\n",
      "Episode 290 , steps =  66 , total reward: -17.03490797276112 , steps_avg: 497.9931271477663 , reward_avg: -39.998254284814145 , distance traveled: -3.338023999286815 , average speed: -0.050576121201315376 , explore ratio: 0.39428948217536725\n",
      "Episode 291 , steps =  3853 , total reward: -135.9030205508919 , steps_avg: 509.4828767123288 , reward_avg: -40.32669526517741 , distance traveled: 419.8942903398772 , average speed: 0.10897853369838495 , explore ratio: 0.393509839589506\n",
      "Episode 292 , steps =  61 , total reward: -9.78532300809833 , steps_avg: 507.9522184300341 , reward_avg: -40.22245849979489 , distance traveled: 2.895953848399222 , average speed: 0.047474653252446264 , explore ratio: 0.3927317386185982\n",
      "Episode 293 , steps =  560 , total reward: -21.300340011098047 , steps_avg: 508.1292517006803 , reward_avg: -40.15809755255443 , distance traveled: 62.565641026608645 , average speed: 0.11172435897608686 , explore ratio: 0.39195517621435383\n",
      "Episode 294 , steps =  3580 , total reward: -55.822798225759364 , steps_avg: 518.542372881356 , reward_avg: -40.21119823280258 , distance traveled: 484.27082391476 , average speed: 0.1352711798644581 , explore ratio: 0.39118014933451045\n",
      "Episode 295 , steps =  90 , total reward: -1.6260764520708506 , steps_avg: 517.0945945945946 , reward_avg: -40.08084309165146 , distance traveled: 18.25315769735724 , average speed: 0.2028128633039693 , explore ratio: 0.3904066549428211\n",
      "Episode 296 , steps =  492 , total reward: 8.418739225883636 , steps_avg: 517.010101010101 , reward_avg: -39.91754483469006 , distance traveled: 90.4169626073632 , average speed: 0.18377431424260815 , explore ratio: 0.38963469000904266\n",
      "Episode 297 , steps =  35 , total reward: -16.283767257599774 , steps_avg: 515.3926174496644 , reward_avg: -39.83823685624345 , distance traveled: -1.7157211822271345 , average speed: -0.049020605206489556 , explore ratio: 0.3888642515089237\n",
      "Episode 298 , steps =  85 , total reward: -19.2080098059494 , steps_avg: 513.9531772575251 , reward_avg: -39.76923944135953 , distance traveled: -1.7086531234905125 , average speed: -0.020101801452829558 , explore ratio: 0.3880953364241927\n",
      "Episode 299 , steps =  109 , total reward: -29.279737982692826 , steps_avg: 512.6033333333334 , reward_avg: -39.7342744364973 , distance traveled: -12.061043344745412 , average speed: -0.11065177380500378 , explore ratio: 0.3873279417425464\n",
      "Episode 300 , steps =  1076 , total reward: 30.930560462678798 , steps_avg: 514.4750830564784 , reward_avg: -39.49950754314456 , distance traveled: 219.80543515697127 , average speed: 0.2042801441979287 , explore ratio: 0.3865620644576379\n",
      "Episode 301 , steps =  638 , total reward: -37.23740774636842 , steps_avg: 514.884105960265 , reward_avg: -39.49201714646649 , distance traveled: 64.09575755763812 , average speed: 0.10046356983955819 , explore ratio: 0.3857977015690647\n",
      "Episode 302 , steps =  65 , total reward: -5.955749037380648 , steps_avg: 513.3993399339934 , reward_avg: -39.38133639363122 , distance traveled: 10.494623189270497 , average speed: 0.16145574137339225 , explore ratio: 0.38503485008235716\n",
      "Episode 303 , steps =  85 , total reward: -25.34289391424818 , steps_avg: 511.99013157894734 , reward_avg: -39.33515730652799 , distance traveled: -7.849971821308137 , average speed: -0.09235260966244867 , explore ratio: 0.3842735070089668\n",
      "Episode 304 , steps =  224 , total reward: -10.61819174369675 , steps_avg: 511.04590163934427 , reward_avg: -39.241003321076086 , distance traveled: 29.385224429871887 , average speed: 0.13118403763335665 , explore ratio: 0.38351366936625436\n",
      "Episode 305 , steps =  41 , total reward: -23.587517480798688 , steps_avg: 509.5098039215686 , reward_avg: -39.18984813859152 , distance traveled: -3.290019675493239 , average speed: -0.0802443823291034 , explore ratio: 0.3827553341774784\n",
      "Episode 306 , steps =  125 , total reward: -16.904234153454507 , steps_avg: 508.257328990228 , reward_avg: -39.1172565620927 , distance traveled: 5.076475051282904 , average speed: 0.04061180041026324 , explore ratio: 0.38199849847178347\n",
      "Episode 307 , steps =  59 , total reward: -2.2095045774479702 , steps_avg: 506.7987012987013 , reward_avg: -38.9974261985062 , distance traveled: 9.942074527144431 , average speed: 0.1685097377482107 , explore ratio: 0.38124315928418834\n",
      "Episode 308 , steps =  70 , total reward: -13.466289348037304 , steps_avg: 505.3851132686084 , reward_avg: -38.91480116015516 , distance traveled: 2.127279360741377 , average speed: 0.030389705153448243 , explore ratio: 0.38048931365557476\n",
      "Episode 309 , steps =  121 , total reward: -14.33796327312602 , steps_avg: 504.14516129032256 , reward_avg: -38.83552103793894 , distance traveled: 8.224403497260065 , average speed: 0.06797027683686004 , explore ratio: 0.3797369586326755\n",
      "Episode 310 , steps =  316 , total reward: -30.936722561426226 , steps_avg: 503.540192926045 , reward_avg: -38.810122972098064 , distance traveled: 16.88891864476958 , average speed: 0.053445945078384745 , explore ratio: 0.378986091268063\n",
      "Episode 311 , steps =  52 , total reward: -11.111280326352144 , steps_avg: 502.09294871794873 , reward_avg: -38.72134463028477 , distance traveled: -5.547198863625525 , average speed: -0.10667690122356778 , explore ratio: 0.3782367086201377\n",
      "Episode 312 , steps =  117 , total reward: -26.285057151245553 , steps_avg: 500.8626198083067 , reward_avg: -38.681612082428416 , distance traveled: -1.5479744779877358 , average speed: -0.013230551093912272 , explore ratio: 0.37748880775311666\n",
      "Episode 313 , steps =  911 , total reward: 5.668866776456355 , steps_avg: 502.1687898089172 , reward_avg: -38.54036851918356 , distance traveled: 151.3690720790998 , average speed: 0.1661570494830953 , explore ratio: 0.3767423857370219\n",
      "Episode 314 , steps =  475 , total reward: -3.668512276733946 , steps_avg: 502.0825396825397 , reward_avg: -38.429664213651975 , distance traveled: 76.58485691048202 , average speed: 0.16123127770627793 , explore ratio: 0.37599743964766896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 315 , steps =  211 , total reward: 2.7684231660160967 , steps_avg: 501.1613924050633 , reward_avg: -38.299290519412516 , distance traveled: 43.49752183977052 , average speed: 0.2061493926055475 , explore ratio: 0.37525396656665555\n",
      "Episode 316 , steps =  41 , total reward: -22.244672119469683 , steps_avg: 499.7097791798107 , reward_avg: -38.24864503550103 , distance traveled: -3.358398621082306 , average speed: -0.08191216148981234 , explore ratio: 0.37451196358135\n",
      "Episode 317 , steps =  711 , total reward: -35.93263330464606 , steps_avg: 500.37421383647796 , reward_avg: -38.24136197974362 , distance traveled: 72.9660227395641 , average speed: 0.10262450455634894 , explore ratio: 0.37377142778487993\n",
      "Episode 318 , steps =  96 , total reward: -24.027114465247216 , steps_avg: 499.1065830721003 , reward_avg: -38.1968032101057 , distance traveled: -2.2205740296095606 , average speed: -0.02313097947509959 , explore ratio: 0.3730323562761207\n",
      "Episode 319 , steps =  93 , total reward: -21.136537534623088 , steps_avg: 497.8375 , reward_avg: -38.14348987986982 , distance traveled: 2.4653363252570855 , average speed: 0.026508992744699842 , explore ratio: 0.37229474615968433\n",
      "Episode 320 , steps =  68 , total reward: 0.03495432372452967 , steps_avg: 496.4984423676012 , reward_avg: -38.02455391661875 , distance traveled: 14.696649457812313 , average speed: 0.21612719790900461 , explore ratio: 0.3715585945459079\n",
      "Episode 321 , steps =  58 , total reward: -1.6420510675391786 , steps_avg: 495.1366459627329 , reward_avg: -37.9115647773359 , distance traveled: 9.991749608516692 , average speed: 0.1722715449744257 , explore ratio: 0.3708238985508423\n",
      "Episode 322 , steps =  58 , total reward: -1.69674969137398 , steps_avg: 493.78328173374615 , reward_avg: -37.79944460679112 , distance traveled: 9.167992154359816 , average speed: 0.15806883024758303 , explore ratio: 0.370090655296241\n",
      "Episode 323 , steps =  1047 , total reward: 31.0504017387647 , steps_avg: 495.49074074074076 , reward_avg: -37.58694508103323 , distance traveled: 214.28862449437375 , average speed: 0.20466917334706183 , explore ratio: 0.3693588619095488\n",
      "Episode 324 , steps =  87 , total reward: -25.316475005202 , steps_avg: 494.2338461538462 , reward_avg: -37.549189788492214 , distance traveled: -7.788111542388797 , average speed: -0.0895185234757333 , explore ratio: 0.36862851552389037\n",
      "Episode 325 , steps =  663 , total reward: -16.355911841467687 , steps_avg: 494.7515337423313 , reward_avg: -37.484179733439994 , distance traveled: 90.76065732747314 , average speed: 0.13689390245471061 , explore ratio: 0.3678996132780592\n",
      "Episode 326 , steps =  72 , total reward: -12.584617326218645 , steps_avg: 493.45871559633025 , reward_avg: -37.40803428265338 , distance traveled: 3.3552557159168646 , average speed: 0.04660077383217867 , explore ratio: 0.3671721523165064\n",
      "Episode 327 , steps =  154 , total reward: -30.19580441897912 , steps_avg: 492.4237804878049 , reward_avg: -37.38604577697145 , distance traveled: -5.797263924926519 , average speed: -0.0376445709410813 , explore ratio: 0.36644612978932944\n",
      "Episode 328 , steps =  1126 , total reward: -29.00213319842477 , steps_avg: 494.34954407294833 , reward_avg: -37.36056276001538 , distance traveled: 142.09114926915143 , average speed: 0.126191073951289 , explore ratio: 0.36572154285226094\n",
      "Episode 329 , steps =  169 , total reward: -9.504834274316217 , steps_avg: 493.3636363636364 , reward_avg: -37.27615146157386 , distance traveled: 18.87407275468111 , average speed: 0.11168090387385271 , explore ratio: 0.3649983886666576\n",
      "Episode 330 , steps =  193 , total reward: -31.91626027902644 , steps_avg: 492.4561933534743 , reward_avg: -37.25995843685318 , distance traveled: -2.3404481716454044 , average speed: -0.01212667446448396 , explore ratio: 0.3642766643994892\n",
      "Episode 331 , steps =  44 , total reward: -20.161405943739553 , steps_avg: 491.105421686747 , reward_avg: -37.2084567727173 , distance traveled: -1.885161795448512 , average speed: -0.042844586260193454 , explore ratio: 0.3635563672233271\n",
      "Episode 332 , steps =  91 , total reward: -4.046324104059496 , steps_avg: 489.9039039039039 , reward_avg: -37.10887078872733 , distance traveled: 12.825355890244245 , average speed: 0.1409379768158708 , explore ratio: 0.3628374943163338\n",
      "Episode 333 , steps =  64 , total reward: -12.82911699743507 , steps_avg: 488.62874251497004 , reward_avg: -37.03617691510071 , distance traveled: -4.611719347278123 , average speed: -0.07205811480122067 , explore ratio: 0.3621200428622512\n",
      "Episode 334 , steps =  272 , total reward: 4.027556782815587 , steps_avg: 487.9820895522388 , reward_avg: -36.91359860555469 , distance traveled: 55.78263549976052 , average speed: 0.20508321874911956 , explore ratio: 0.3614040100503901\n",
      "Episode 335 , steps =  649 , total reward: -2.7293502783080523 , steps_avg: 488.4613095238095 , reward_avg: -36.811859771247406 , distance traveled: 100.9775206860155 , average speed: 0.15558940013253544 , explore ratio: 0.3606893930756188\n",
      "Episode 336 , steps =  51 , total reward: -13.173686487005403 , steps_avg: 487.1632047477745 , reward_avg: -36.741716823816425 , distance traveled: 0.4113450783491134 , average speed: 0.008065589771551243 , explore ratio: 0.35997618913835244\n",
      "Episode 337 , steps =  62 , total reward: -1.0558229466614653 , steps_avg: 485.905325443787 , reward_avg: -36.63613725613253 , distance traveled: 12.307313856482503 , average speed: 0.1985050622013307 , explore ratio: 0.3592643954445418\n",
      "Episode 338 , steps =  599 , total reward: -12.298719923876885 , steps_avg: 486.23893805309734 , reward_avg: -36.56434546459196 , distance traveled: 86.75912763336686 , average speed: 0.14483994596555402 , explore ratio: 0.35855400920566244\n",
      "Episode 339 , steps =  1252 , total reward: 6.465452753501726 , steps_avg: 488.49117647058824 , reward_avg: -36.43778723453874 , distance traveled: 211.93217401432773 , average speed: 0.16927489937246623 , explore ratio: 0.3578450276387038\n",
      "Episode 340 , steps =  585 , total reward: 7.540543829091101 , steps_avg: 488.7741935483871 , reward_avg: -36.30881852174217 , distance traveled: 114.26212038612005 , average speed: 0.19531986390789752 , explore ratio: 0.3571374479661582\n",
      "Episode 341 , steps =  68 , total reward: -8.364822829273221 , steps_avg: 487.5438596491228 , reward_avg: -36.22711093199811 , distance traveled: 7.887984507009386 , average speed: 0.11599977216190273 , explore ratio: 0.3564312674160101\n",
      "Episode 342 , steps =  92 , total reward: -17.817778417731315 , steps_avg: 486.3906705539359 , reward_avg: -36.1734394086329 , distance traveled: 3.1428148051723834 , average speed: 0.03416103049100417 , explore ratio: 0.3557264832217251\n",
      "Episode 343 , steps =  363 , total reward: -9.220458560214096 , steps_avg: 486.03197674418607 , reward_avg: -36.095087720120056 , distance traveled: 50.80751369945706 , average speed: 0.13996560247784315 , explore ratio: 0.35502309262223924\n",
      "Episode 344 , steps =  66 , total reward: -5.904662526223187 , steps_avg: 484.8144927536232 , reward_avg: -36.007579241297165 , distance traveled: 8.035442601442337 , average speed: 0.1217491303248839 , explore ratio: 0.3543210928619481\n",
      "Episode 345 , steps =  99 , total reward: -21.333240416120095 , steps_avg: 483.6994219653179 , reward_avg: -35.96516785740937 , distance traveled: -7.248294443059713 , average speed: -0.07321509538444154 , explore ratio: 0.35362048119069583\n",
      "Episode 346 , steps =  138 , total reward: -5.089163438970239 , steps_avg: 482.7031700288184 , reward_avg: -35.87618801758678 , distance traveled: 17.506051140830397 , average speed: 0.12685544304949564 , explore ratio: 0.35292125486376485\n",
      "Episode 347 , steps =  68 , total reward: -4.2737681958551255 , steps_avg: 481.51149425287355 , reward_avg: -35.785376466374906 , distance traveled: 8.96189127445221 , average speed: 0.13179251874194425 , explore ratio: 0.3522234111418646\n",
      "Episode 348 , steps =  125 , total reward: -15.510341563358288 , steps_avg: 480.48997134670486 , reward_avg: -35.727281810492336 , distance traveled: 7.206568216234448 , average speed: 0.05765254572987558 , explore ratio: 0.35152694729112116\n",
      "Episode 349 , steps =  54 , total reward: -8.17264402876794 , steps_avg: 479.27142857142854 , reward_avg: -35.64855427397312 , distance traveled: 4.8116259098332375 , average speed: 0.08910418351543033 , explore ratio: 0.35083186058306626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 350 , steps =  790 , total reward: 2.188421097298418 , steps_avg: 480.15669515669515 , reward_avg: -35.54075662334272 , distance traveled: 130.6654379166638 , average speed: 0.16539928850210606 , explore ratio: 0.3501381482946268\n",
      "Episode 351 , steps =  46 , total reward: -28.230464639935022 , steps_avg: 478.92329545454544 , reward_avg: -35.519988748389856 , distance traveled: -5.592352543249726 , average speed: -0.12157288137499404 , explore ratio: 0.3494458077081141\n",
      "Episode 352 , steps =  90 , total reward: -25.683565785198795 , steps_avg: 477.8215297450425 , reward_avg: -35.49212352753096 , distance traveled: -3.2652476106776147 , average speed: -0.03628052900752905 , explore ratio: 0.3487548361112133\n",
      "Episode 353 , steps =  231 , total reward: -35.667331214306195 , steps_avg: 477.1242937853107 , reward_avg: -35.49261846449925 , distance traveled: -2.927023176155632 , average speed: -0.012671096000673732 , explore ratio: 0.34806523079697255\n",
      "Episode 354 , steps =  65 , total reward: -8.156007185078538 , steps_avg: 475.96338028169015 , reward_avg: -35.41561392568398 , distance traveled: 3.9826868238206945 , average speed: 0.06127210498185684 , explore ratio: 0.3473769890637928\n",
      "Episode 355 , steps =  58 , total reward: -6.235089818981787 , steps_avg: 474.78932584269666 , reward_avg: -35.33364616133931 , distance traveled: 4.212434118166567 , average speed: 0.0726281744511477 , explore ratio: 0.3466901082154167\n",
      "Episode 356 , steps =  168 , total reward: -4.328902897161752 , steps_avg: 473.9299719887955 , reward_avg: -35.24679814099147 , distance traveled: 25.87396464600228 , average speed: 0.15401169432144213 , explore ratio: 0.3460045855609185\n",
      "Episode 357 , steps =  71 , total reward: -1.776704894687366 , steps_avg: 472.804469273743 , reward_avg: -35.15330626041521 , distance traveled: 11.793731769919393 , average speed: 0.16610889816787877 , explore ratio: 0.34532041841469324\n",
      "Episode 358 , steps =  140 , total reward: -3.871502996940796 , steps_avg: 471.8774373259053 , reward_avg: -35.066170318177114 , distance traveled: 19.503988455981023 , average speed: 0.1393142032570073 , explore ratio: 0.34463760409644634\n",
      "Episode 359 , steps =  233 , total reward: -12.044268344532714 , steps_avg: 471.2138888888889 , reward_avg: -35.00222059047255 , distance traveled: 24.974552912232454 , average speed: 0.10718692237009637 , explore ratio: 0.34395613993118296\n",
      "Episode 360 , steps =  60 , total reward: -4.381268647086498 , steps_avg: 470.0747922437673 , reward_avg: -34.917398008911924 , distance traveled: 6.48417280241847 , average speed: 0.10806954670697451 , explore ratio: 0.3432760232491977\n",
      "Episode 361 , steps =  181 , total reward: -15.041294063719002 , steps_avg: 469.27624309392263 , reward_avg: -34.86249164442244 , distance traveled: 8.476024632453916 , average speed: 0.04682886537267357 , explore ratio: 0.3425972513860641\n",
      "Episode 362 , steps =  221 , total reward: -8.61796622525406 , steps_avg: 468.59228650137743 , reward_avg: -34.79019267632555 , distance traveled: 23.015264102630315 , average speed: 0.10414146652773898 , explore ratio: 0.34191982168262414\n",
      "Episode 363 , steps =  137 , total reward: -8.66335895438928 , steps_avg: 467.68131868131866 , reward_avg: -34.71841566060595 , distance traveled: 10.346262602582573 , average speed: 0.07552016498235455 , explore ratio: 0.3412437314849777\n",
      "Episode 364 , steps =  718 , total reward: -22.230951745336814 , steps_avg: 468.36712328767123 , reward_avg: -34.6842034307011 , distance traveled: 85.10590518694026 , average speed: 0.11853190137456861 , explore ratio: 0.34056897814447257\n",
      "Episode 365 , steps =  274 , total reward: -26.512039993276588 , steps_avg: 467.8360655737705 , reward_avg: -34.6618751152983 , distance traveled: 10.35056421088055 , average speed: 0.03777578179153486 , explore ratio: 0.3398955590176936\n",
      "Episode 366 , steps =  102 , total reward: -26.17160663375256 , steps_avg: 466.8392370572207 , reward_avg: -34.63874086875459 , distance traveled: -14.061730675846338 , average speed: -0.1378601046651602 , explore ratio: 0.33922347146645265\n",
      "Episode 367 , steps =  396 , total reward: -9.312067623241836 , steps_avg: 466.6467391304348 , reward_avg: -34.56991838710917 , distance traveled: 49.78252058051527 , average speed: 0.125713435809382 , explore ratio: 0.3385527128577782\n",
      "Episode 368 , steps =  51 , total reward: -3.749552424632014 , steps_avg: 465.520325203252 , reward_avg: -34.48639436011059 , distance traveled: 4.8071871185302735 , average speed: 0.09425857095157399 , explore ratio: 0.33788328056390493\n",
      "Episode 369 , steps =  715 , total reward: -24.198713919839538 , steps_avg: 466.1945945945946 , reward_avg: -34.45858981838012 , distance traveled: 80.93219870792245 , average speed: 0.11319188630478665 , explore ratio: 0.33721517196226347\n",
      "Episode 370 , steps =  112 , total reward: -2.0739706776347004 , steps_avg: 465.2398921832884 , reward_avg: -34.37129973983364 , distance traveled: 20.264385927245023 , average speed: 0.18093201720754484 , explore ratio: 0.33654838443547025\n",
      "Episode 371 , steps =  154 , total reward: -8.380778101526213 , steps_avg: 464.4032258064516 , reward_avg: -34.30143274618227 , distance traveled: 16.516082627931613 , average speed: 0.10724728979176372 , explore ratio: 0.3358829153713171\n",
      "Episode 372 , steps =  155 , total reward: -0.9246187321903857 , steps_avg: 463.57372654155495 , reward_avg: -34.21195067107774 , distance traveled: 24.575312310755233 , average speed: 0.15855040200487247 , explore ratio: 0.335218762162761\n",
      "Episode 373 , steps =  114 , total reward: -6.322557887893172 , steps_avg: 462.63903743315507 , reward_avg: -34.13738010213874 , distance traveled: 13.031262989044192 , average speed: 0.11430932446529993 , explore ratio: 0.33455592220791397\n",
      "Episode 374 , steps =  56 , total reward: -1.961936449499805 , steps_avg: 461.55466666666666 , reward_avg: -34.05157891906504 , distance traveled: 7.7264396888762725 , average speed: 0.137972137301362 , explore ratio: 0.3338943929100329\n",
      "Episode 375 , steps =  97 , total reward: -11.161160624684776 , steps_avg: 460.5851063829787 , reward_avg: -33.99070014700552 , distance traveled: 4.019825280234217 , average speed: 0.041441497734373375 , explore ratio: 0.33323417167750924\n",
      "Episode 376 , steps =  64 , total reward: -10.555654443345972 , steps_avg: 459.53315649867375 , reward_avg: -33.92853822206212 , distance traveled: -3.2394855397939692 , average speed: -0.05061696155928077 , explore ratio: 0.33257525592385895\n",
      "Episode 377 , steps =  135 , total reward: -5.942651603380227 , steps_avg: 458.6746031746032 , reward_avg: -33.854501484975664 , distance traveled: 14.979470682665704 , average speed: 0.11095904209382003 , explore ratio: 0.33191764306771226\n",
      "Episode 378 , steps =  79 , total reward: -13.250109952286508 , steps_avg: 457.67282321899734 , reward_avg: -33.800136335812894 , distance traveled: 1.143747683800757 , average speed: 0.014477818782288062 , explore ratio: 0.33126133053280377\n",
      "Episode 379 , steps =  100 , total reward: -11.221152046329042 , steps_avg: 456.7315789473684 , reward_avg: -33.74071795610372 , distance traveled: 6.576124047171323 , average speed: 0.06576124047171322 , explore ratio: 0.3306063157479621\n",
      "Episode 380 , steps =  4890 , total reward: -255.85417612372717 , steps_avg: 468.36745406824144 , reward_avg: -34.32369291192426 , distance traveled: 410.35079433280964 , average speed: 0.08391631785947028 , explore ratio: 0.32995259614710004\n",
      "Episode 381 , steps =  105 , total reward: -2.953068197673817 , steps_avg: 467.41623036649213 , reward_avg: -34.24157085769848 , distance traveled: 16.509060780582953 , average speed: 0.15722915029126622 , explore ratio: 0.3293001691692043\n",
      "Episode 382 , steps =  91 , total reward: -5.666383951940891 , steps_avg: 466.43342036553526 , reward_avg: -34.1669620146025 , distance traveled: 11.570441135913134 , average speed: 0.12714770479025422 , explore ratio: 0.32864903225832565\n",
      "Episode 383 , steps =  295 , total reward: -9.1244482968127 , steps_avg: 465.9869791666667 , reward_avg: -34.10174713512909 , distance traveled: 36.18029779963199 , average speed: 0.12264507728688809 , explore ratio: 0.3279991828635688\n",
      "Episode 384 , steps =  47 , total reward: -8.444249605529635 , steps_avg: 464.8987012987013 , reward_avg: -34.035104284402856 , distance traveled: 3.6419366906583304 , average speed: 0.0774880146948581 , explore ratio: 0.32735061843908236\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 385 , steps =  61 , total reward: -0.6365658427414776 , steps_avg: 463.8523316062176 , reward_avg: -33.948579573414094 , distance traveled: 9.992934878468512 , average speed: 0.16381860456505756 , explore ratio: 0.3267033364440491\n",
      "Episode 386 , steps =  1351 , total reward: -66.77472280364958 , steps_avg: 466.1447028423773 , reward_avg: -34.03340164894442 , distance traveled: 122.18195591602486 , average speed: 0.09043816129979634 , explore ratio: 0.3260573343426757\n",
      "Episode 387 , steps =  3046 , total reward: -73.44118870205243 , steps_avg: 472.7938144329897 , reward_avg: -34.134968110421504 , distance traveled: 375.94260320892596 , average speed: 0.12342173447436834 , explore ratio: 0.325412609604183\n",
      "Episode 388 , steps =  57 , total reward: -8.1088049729007 , steps_avg: 471.7249357326478 , reward_avg: -34.068062806726076 , distance traveled: 3.9973395834211263 , average speed: 0.07012876462142327 , explore ratio: 0.3247691597027961\n",
      "Episode 389 , steps =  798 , total reward: -31.733351934502792 , steps_avg: 472.5615384615385 , reward_avg: -34.06207636859217 , distance traveled: 98.24890618219963 , average speed: 0.12311893005288174 , explore ratio: 0.3241269821177342\n",
      "Episode 390 , steps =  143 , total reward: -12.254258554898215 , steps_avg: 471.71867007672637 , reward_avg: -34.00630189848042 , distance traveled: 13.258900177566684 , average speed: 0.09271958166130548 , explore ratio: 0.32348607433320126\n",
      "Episode 391 , steps =  712 , total reward: -16.437487183957202 , steps_avg: 472.3316326530612 , reward_avg: -33.96148349359643 , distance traveled: 91.69050441113289 , average speed: 0.12877879833024283 , explore ratio: 0.3228464338383755\n",
      "Episode 392 , steps =  95 , total reward: -18.676681413128957 , steps_avg: 471.37150127226465 , reward_avg: -33.922590867437485 , distance traveled: -1.4980833606608215 , average speed: -0.015769298533271806 , explore ratio: 0.3222080581274001\n",
      "Episode 393 , steps =  55 , total reward: -6.35565740754518 , steps_avg: 470.3147208121827 , reward_avg: -33.852624031244865 , distance traveled: 4.769754935279489 , average speed: 0.08672281700508162 , explore ratio: 0.32157094469937303\n",
      "Episode 394 , steps =  458 , total reward: -14.318118594137353 , steps_avg: 470.28354430379744 , reward_avg: -33.803169587100285 , distance traveled: 61.439155246764436 , average speed: 0.13414662717634157 , explore ratio: 0.32093509105833745\n",
      "Episode 395 , steps =  245 , total reward: 1.137725749267245 , steps_avg: 469.7146464646465 , reward_avg: -33.71493500291754 , distance traveled: 47.02578788459303 , average speed: 0.19194199136568582 , explore ratio: 0.32030049471327177\n",
      "Episode 396 , steps =  49 , total reward: -16.081085279241208 , steps_avg: 468.65491183879095 , reward_avg: -33.67051724542717 , distance traveled: -5.50685534119606 , average speed: -0.11238480288155224 , explore ratio: 0.3196671531780801\n",
      "Episode 397 , steps =  295 , total reward: 1.153837924357477 , steps_avg: 468.2185929648241 , reward_avg: -33.58301886560359 , distance traveled: 52.567280975868925 , average speed: 0.17819417279955568 , explore ratio: 0.3190350639715823\n",
      "Episode 398 , steps =  87 , total reward: -0.930527927462016 , steps_avg: 467.2631578947368 , reward_avg: -33.50118304871602 , distance traveled: 15.06741845972836 , average speed: 0.17318871792791218 , explore ratio: 0.31840422461750445\n",
      "Episode 399 , steps =  511 , total reward: 7.387317644576827 , steps_avg: 467.3725 , reward_avg: -33.39896179698278 , distance traveled: 91.81977841760965 , average speed: 0.1796864548289817 , explore ratio: 0.317774632644469\n",
      "Episode 400 , steps =  177 , total reward: 12.885843090701213 , steps_avg: 466.6483790523691 , reward_avg: -33.28353834339754 , distance traveled: 50.033583531975765 , average speed: 0.28267561317500434 , explore ratio: 0.31714628558598507\n",
      "Episode 401 , steps =  85 , total reward: -26.843522154654686 , steps_avg: 465.69900497512435 , reward_avg: -33.26751840262953 , distance traveled: -7.860214528413491 , average speed: -0.09247311209898225 , explore ratio: 0.316519180980439\n",
      "Episode 402 , steps =  461 , total reward: 0.8971805147472419 , steps_avg: 465.6873449131514 , reward_avg: -33.18274247479484 , distance traveled: 76.1499164815619 , average speed: 0.16518420061076336 , explore ratio: 0.31589331637108453\n",
      "Episode 403 , steps =  72 , total reward: -13.261127794486782 , steps_avg: 464.71287128712873 , reward_avg: -33.13343154736833 , distance traveled: 3.29618326837197 , average speed: 0.04578032317183292 , explore ratio: 0.31526868930603313\n",
      "Episode 404 , steps =  477 , total reward: 10.630208812784979 , steps_avg: 464.74320987654323 , reward_avg: -33.025373176108694 , distance traveled: 92.78659716568876 , average speed: 0.1945211680622406 , explore ratio: 0.3146452973382446\n",
      "Episode 405 , steps =  104 , total reward: -7.263971079797803 , steps_avg: 463.8546798029557 , reward_avg: -32.96192144680744 , distance traveled: 10.519029520154 , average speed: 0.10114451461686538 , explore ratio: 0.31402313802551723\n",
      "Episode 406 , steps =  251 , total reward: 1.1533267462054795 , steps_avg: 463.33169533169536 , reward_avg: -32.87810019817596 , distance traveled: 45.588572272360324 , average speed: 0.18162777797753116 , explore ratio: 0.31340220893047843\n",
      "Episode 407 , steps =  47 , total reward: -24.132635558765386 , steps_avg: 462.3112745098039 , reward_avg: -32.85666523582446 , distance traveled: -5.862204477068521 , average speed: -0.12472775483124512 , explore ratio: 0.31278250762057513\n",
      "Episode 408 , steps =  71 , total reward: -7.001449230584627 , steps_avg: 461.3545232273839 , reward_avg: -32.793449548770084 , distance traveled: 5.03947698289063 , average speed: 0.0709785490547976 , explore ratio: 0.31216403166806417\n",
      "Episode 409 , steps =  104 , total reward: -5.972407149435337 , steps_avg: 460.4829268292683 , reward_avg: -32.72803237218634 , distance traveled: 14.877781120687727 , average speed: 0.14305558769892046 , explore ratio: 0.3115467786500029\n",
      "Episode 410 , steps =  145 , total reward: 4.2154039687042335 , steps_avg: 459.7153284671533 , reward_avg: -32.63814566576082 , distance traveled: 28.25238914284855 , average speed: 0.19484406305412794 , explore ratio: 0.3109307461482397\n",
      "Episode 411 , steps =  40 , total reward: -14.583693283312021 , steps_avg: 458.6966019417476 , reward_avg: -32.59432417939565 , distance traveled: -0.12358681865036492 , average speed: -0.003089670466259123 , explore ratio: 0.3103159317494043\n",
      "Episode 412 , steps =  193 , total reward: -5.981946565903742 , steps_avg: 458.05326876513317 , reward_avg: -32.52988742972618 , distance traveled: 27.77014945143834 , average speed: 0.14388678472247843 , explore ratio: 0.3097023330448986\n",
      "Episode 413 , steps =  138 , total reward: 5.7575206439966875 , steps_avg: 457.280193236715 , reward_avg: -32.43740576771235 , distance traveled: 33.4295013374579 , average speed: 0.24224276331491232 , explore ratio: 0.309089947630887\n",
      "Episode 414 , steps =  79 , total reward: -28.87951009671081 , steps_avg: 456.3686746987952 , reward_avg: -32.428832525131625 , distance traveled: -6.6934087189380085 , average speed: -0.08472669264478491 , explore ratio: 0.3084787731082872\n",
      "Episode 415 , steps =  75 , total reward: -25.653553998110212 , steps_avg: 455.4519230769231 , reward_avg: -32.41254579790321 , distance traveled: -5.357786482125519 , average speed: -0.07143715309500692 , explore ratio: 0.30786880708276065\n",
      "Episode 416 , steps =  124 , total reward: -13.628242457725118 , steps_avg: 454.6570743405276 , reward_avg: -32.36749950691957 , distance traveled: 4.700238998411223 , average speed: 0.03790515321299373 , explore ratio: 0.3072600471647032\n",
      "Episode 417 , steps =  118 , total reward: -23.27374853837054 , steps_avg: 453.85167464114835 , reward_avg: -32.34574412182735 , distance traveled: -1.349968671938405 , average speed: -0.011440412474054279 , explore ratio: 0.30665249096923564\n",
      "Episode 418 , steps =  53 , total reward: -22.303241436615586 , steps_avg: 452.89498806682576 , reward_avg: -32.32177633498914 , distance traveled: -6.980034457147121 , average speed: -0.1316987633423985 , explore ratio: 0.3060461361161947\n",
      "Episode 419 , steps =  105 , total reward: -4.102907188435398 , steps_avg: 452.06666666666666 , reward_avg: -32.25458855130686 , distance traveled: 14.440655130296953 , average speed: 0.13753004885997097 , explore ratio: 0.3054409802301233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 420 , steps =  66 , total reward: -7.7466858130923155 , steps_avg: 451.1496437054632 , reward_avg: -32.19637500561039 , distance traveled: 6.663623852245509 , average speed: 0.1009639977612956 , explore ratio: 0.30483702094026155\n",
      "Episode 421 , steps =  50 , total reward: -6.530918836817148 , steps_avg: 450.1990521327014 , reward_avg: -32.135556389096664 , distance traveled: 1.4272776667436118 , average speed: 0.028545553334872235 , explore ratio: 0.30423425588053726\n",
      "Episode 422 , steps =  32 , total reward: -7.524319341421128 , steps_avg: 449.21040189125296 , reward_avg: -32.07737379560334 , distance traveled: -1.5489582699537277 , average speed: -0.04840494593605399 , explore ratio: 0.30363268268955684\n",
      "Episode 423 , steps =  80 , total reward: -7.169986174410834 , steps_avg: 448.33962264150944 , reward_avg: -32.018629956874115 , distance traveled: 8.785843499600885 , average speed: 0.10982304374501106 , explore ratio: 0.30303229901059586\n",
      "Episode 424 , steps =  410 , total reward: -1.8142683599020355 , steps_avg: 448.2494117647059 , reward_avg: -31.947560870763592 , distance traveled: 63.26056055498308 , average speed: 0.15429405013410508 , explore ratio: 0.30243310249159006\n",
      "Episode 425 , steps =  207 , total reward: -24.758019711427373 , steps_avg: 447.6830985915493 , reward_avg: -31.930684013582052 , distance traveled: 13.968378371181899 , average speed: 0.06748008874967101 , explore ratio: 0.3018350907851259\n",
      "Episode 426 , steps =  71 , total reward: 1.2966211180097118 , steps_avg: 446.8009367681499 , reward_avg: -31.85286831069776 , distance traveled: 13.30381838053465 , average speed: 0.18737772366950212 , explore ratio: 0.3012382615484315\n",
      "Episode 427 , steps =  64 , total reward: 0.15337352633289947 , steps_avg: 445.9065420560748 , reward_avg: -31.778087371826196 , distance traveled: 11.389029656052589 , average speed: 0.1779535883758217 , explore ratio: 0.3006426124433674\n",
      "Episode 428 , steps =  48 , total reward: -1.6608469878267496 , steps_avg: 444.97902097902096 , reward_avg: -31.707884014287735 , distance traveled: 7.434038947820662 , average speed: 0.15487581141293047 , explore ratio: 0.3000481411364174\n",
      "Episode 429 , steps =  48 , total reward: -5.716630309004338 , steps_avg: 444.0558139534884 , reward_avg: -31.647439238228937 , distance traveled: 1.1118609146028755 , average speed: 0.023163769054226572 , explore ratio: 0.2994548452986796\n",
      "Episode 430 , steps =  55 , total reward: -7.476915283336622 , steps_avg: 443.15313225058003 , reward_avg: -31.59135913624543 , distance traveled: 2.076439857780934 , average speed: 0.03775345195965334 , explore ratio: 0.29886272260585695\n",
      "Episode 431 , steps =  116 , total reward: -38.578231748312724 , steps_avg: 442.3958333333333 , reward_avg: -31.607532452477066 , distance traveled: -18.635129373650994 , average speed: -0.1606476670142327 , explore ratio: 0.2982717707382484\n",
      "Episode 432 , steps =  571 , total reward: 19.314785686543956 , steps_avg: 442.6928406466513 , reward_avg: -31.48992894638233 , distance traveled: 118.78672682153068 , average speed: 0.20803279653508 , explore ratio: 0.29768198738073964\n",
      "Episode 433 , steps =  59 , total reward: -7.934720700322963 , steps_avg: 441.8087557603687 , reward_avg: -31.435654273004314 , distance traveled: 1.9949211227428159 , average speed: 0.03381222241936976 , explore ratio: 0.29709337022279425\n",
      "Episode 434 , steps =  154 , total reward: -10.16710563074674 , steps_avg: 441.1471264367816 , reward_avg: -31.386761057734756 , distance traveled: 18.333705906271923 , average speed: 0.1190500383524151 , explore ratio: 0.2965059169584444\n",
      "Episode 435 , steps =  113 , total reward: -15.870071015600747 , steps_avg: 440.39449541284404 , reward_avg: -31.35117231910601 , distance traveled: 2.0565901329740885 , average speed: 0.018199912681186623 , explore ratio: 0.2959196252862821\n",
      "Episode 436 , steps =  49 , total reward: -24.53502663464782 , steps_avg: 439.49885583524025 , reward_avg: -31.335574731727387 , distance traveled: -3.936475204154849 , average speed: -0.0803362286562214 , explore ratio: 0.2953344929094497\n",
      "Episode 437 , steps =  271 , total reward: -0.24293963320679413 , steps_avg: 439.11415525114154 , reward_avg: -31.2645869803609 , distance traveled: 45.050945048891 , average speed: 0.16623964962690407 , explore ratio: 0.29475051753563153\n",
      "Episode 438 , steps =  111 , total reward: -33.802032027397935 , steps_avg: 438.3667425968109 , reward_avg: -31.270367037415653 , distance traveled: -17.579389231726527 , average speed: -0.15837287596150024 , explore ratio: 0.2941676968770444\n",
      "Episode 439 , steps =  66 , total reward: -10.605437453728792 , steps_avg: 437.5204545454545 , reward_avg: -31.22340128836182 , distance traveled: 1.5774306235089897 , average speed: 0.02390046399256045 , explore ratio: 0.293586028650429\n",
      "Episode 440 , steps =  54 , total reward: -1.5134810056090369 , steps_avg: 436.6507936507937 , reward_avg: -31.15603185461408 , distance traveled: 7.43058750718832 , average speed: 0.13760347235533926 , explore ratio: 0.2930055105770406\n",
      "Episode 441 , steps =  181 , total reward: 5.844168203844363 , steps_avg: 436.07239819004525 , reward_avg: -31.072320994753316 , distance traveled: 40.79583040416239 , average speed: 0.22539132819979218 , explore ratio: 0.2924261403826405\n",
      "Episode 442 , steps =  84 , total reward: -25.990104495083923 , steps_avg: 435.27765237020316 , reward_avg: -31.060848722745032 , distance traveled: -12.363509986996652 , average speed: -0.1471846427023411 , explore ratio: 0.29184791579748676\n",
      "Episode 443 , steps =  60 , total reward: -1.1692395435615173 , steps_avg: 434.43243243243245 , reward_avg: -30.99352527864777 , distance traveled: 10.220491498410702 , average speed: 0.1703415249735117 , explore ratio: 0.2912708345563256\n",
      "Episode 444 , steps =  46 , total reward: -3.658714173530541 , steps_avg: 433.5595505617978 , reward_avg: -30.932098736838523 , distance traveled: 4.041648387014866 , average speed: 0.0878619214568449 , explore ratio: 0.2906948943983823\n",
      "Episode 445 , steps =  35 , total reward: -9.05918384405164 , steps_avg: 432.6659192825112 , reward_avg: -30.883056326765004 , distance traveled: -3.020196526050568 , average speed: -0.08629132931573051 , explore ratio: 0.29012009306735265\n",
      "Episode 446 , steps =  95 , total reward: -33.96985563184135 , steps_avg: 431.91051454138704 , reward_avg: -30.88996191805153 , distance traveled: -18.800715003954245 , average speed: -0.19790226319951837 , explore ratio: 0.28954642831139366\n",
      "Episode 447 , steps =  82 , total reward: -22.239026106663673 , steps_avg: 431.1294642857143 , reward_avg: -30.87065179347254 , distance traveled: -15.821910248994826 , average speed: -0.19295012498774178 , explore ratio: 0.28897389788311517\n",
      "Episode 448 , steps =  64 , total reward: -23.512063305398456 , steps_avg: 430.31180400890867 , reward_avg: -30.85426295496903 , distance traveled: -2.7695725489058534 , average speed: -0.04327457107665396 , explore ratio: 0.28840249953957076\n",
      "Episode 449 , steps =  37 , total reward: -8.320442444563536 , steps_avg: 429.4377777777778 , reward_avg: -30.804187798279244 , distance traveled: -2.6301330864429477 , average speed: -0.07108467801197156 , explore ratio: 0.28783223104224914\n",
      "Episode 450 , steps =  87 , total reward: -25.239959932956218 , steps_avg: 428.67849223946786 , reward_avg: -30.79185026420979 , distance traveled: -6.397281535472722 , average speed: -0.07353197167210025 , explore ratio: 0.28726309015706525\n",
      "Episode 451 , steps =  69 , total reward: 0.0666025268547226 , steps_avg: 427.88274336283183 , reward_avg: -30.72357935095522 , distance traveled: 12.432602634653447 , average speed: 0.18018264687903546 , explore ratio: 0.2866950746543516\n",
      "Episode 452 , steps =  139 , total reward: -14.202958095873404 , steps_avg: 427.2450331125828 , reward_avg: -30.68710998836122 , distance traveled: 16.750197393894204 , average speed: 0.12050501722226047 , explore ratio: 0.28612818230884957\n",
      "Episode 453 , steps =  476 , total reward: 27.964333917556512 , steps_avg: 427.352422907489 , reward_avg: -30.557921785925277 , distance traveled: 117.32814442813398 , average speed: 0.24648769837843273 , explore ratio: 0.2855624108997004\n",
      "Episode 454 , steps =  136 , total reward: -11.746860694902024 , steps_avg: 426.7120879120879 , reward_avg: -30.516578794516438 , distance traveled: 9.670454110577705 , average speed: 0.07110628022483606 , explore ratio: 0.284997758210437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 455 , steps =  107 , total reward: -1.6664587633957537 , steps_avg: 426.0109649122807 , reward_avg: -30.453310987430644 , distance traveled: 16.84670917599433 , average speed: 0.15744588014947972 , explore ratio: 0.2844342220289747\n",
      "Episode 456 , steps =  53 , total reward: -6.761182886822148 , steps_avg: 425.19474835886217 , reward_avg: -30.401468256357106 , distance traveled: 3.914694188833237 , average speed: 0.07386215450628748 , explore ratio: 0.28387180014760316\n",
      "Episode 457 , steps =  47 , total reward: -14.591492128415032 , steps_avg: 424.36899563318775 , reward_avg: -30.36694865782448 , distance traveled: 0.861413399130106 , average speed: 0.01832794466234268 , explore ratio: 0.2833104903629772\n",
      "Episode 458 , steps =  255 , total reward: 10.779138149740152 , steps_avg: 424.0 , reward_avg: -30.277305767176188 , distance traveled: 58.0280838536471 , average speed: 0.22756111315155725 , explore ratio: 0.2827502904761084\n",
      "Episode 459 , steps =  73 , total reward: -17.343246485461176 , steps_avg: 423.2369565217391 , reward_avg: -30.249188246998553 , distance traveled: -10.194945502951743 , average speed: -0.1396567877116677 , explore ratio: 0.28219119829235656\n",
      "Episode 460 , steps =  75 , total reward: -5.450089630087227 , steps_avg: 422.4815618221258 , reward_avg: -30.195394106831714 , distance traveled: 6.753682845532894 , average speed: 0.09004910460710525 , explore ratio: 0.281633211621421\n",
      "Episode 461 , steps =  182 , total reward: -2.768693280961377 , steps_avg: 421.961038961039 , reward_avg: -30.136028953528964 , distance traveled: 27.65456879206001 , average speed: 0.1519481801761539 , explore ratio: 0.2810763282773321\n",
      "Episode 462 , steps =  183 , total reward: -7.0776794745531095 , steps_avg: 421.4449244060475 , reward_avg: -30.08622690281843 , distance traveled: 31.28856896013022 , average speed: 0.17097578666737825 , explore ratio: 0.28052054607844235\n",
      "Episode 463 , steps =  113 , total reward: -2.778205184468388 , steps_avg: 420.7801724137931 , reward_avg: -30.02737340773578 , distance traveled: 16.127847610730676 , average speed: 0.14272431513920952 , explore ratio: 0.27996586284741837\n",
      "Episode 464 , steps =  179 , total reward: 5.0320143612579695 , steps_avg: 420.26021505376343 , reward_avg: -29.951976874899238 , distance traveled: 39.00088810108601 , average speed: 0.21788205643064812 , explore ratio: 0.279412276411232\n",
      "Episode 465 , steps =  642 , total reward: -19.58245608702168 , steps_avg: 420.7360515021459 , reward_avg: -29.92972468436731 , distance traveled: 74.25050852690818 , average speed: 0.11565499770546445 , explore ratio: 0.2788597846011519\n",
      "Episode 466 , steps =  89 , total reward: -0.26286820629798147 , steps_avg: 420.0256959314775 , reward_avg: -29.866198225099495 , distance traveled: 16.335876540541648 , average speed: 0.1835491746128275 , explore ratio: 0.278308385252735\n",
      "Episode 467 , steps =  58 , total reward: -13.710582043793053 , steps_avg: 419.2521367521368 , reward_avg: -29.831677677703542 , distance traveled: -7.684282221794127 , average speed: -0.13248762451369184 , explore ratio: 0.27775807620581805\n",
      "Episode 468 , steps =  211 , total reward: 3.093225582141417 , steps_avg: 418.80810234541576 , reward_avg: -29.761475325337134 , distance traveled: 40.4241407492012 , average speed: 0.19158360544645117 , explore ratio: 0.2772088553045092\n",
      "Episode 469 , steps =  382 , total reward: 3.6791350789808623 , steps_avg: 418.72978723404253 , reward_avg: -29.69032509043433 , distance traveled: 65.77856613948941 , average speed: 0.17219519931803512 , explore ratio: 0.27666072039717965\n",
      "Episode 470 , steps =  296 , total reward: -3.0028280615663405 , steps_avg: 418.4692144373673 , reward_avg: -29.63366373793143 , distance traveled: 45.994539893791064 , average speed: 0.15538695910064548 , explore ratio: 0.2761136693364548\n",
      "Episode 471 , steps =  77 , total reward: -1.2667111763196797 , steps_avg: 417.7457627118644 , reward_avg: -29.5735642621653 , distance traveled: 12.332614652984779 , average speed: 0.16016382666214 , explore ratio: 0.2755676999792064\n",
      "Episode 472 , steps =  435 , total reward: 27.617970719129485 , steps_avg: 417.7822410147991 , reward_avg: -29.452651926052624 , distance traveled: 107.66406580638956 , average speed: 0.24750359955491852 , explore ratio: 0.2750228101865437\n",
      "Episode 473 , steps =  316 , total reward: 7.972642181623076 , steps_avg: 417.5675105485232 , reward_avg: -29.373695609369765 , distance traveled: 61.8411756978929 , average speed: 0.1956999230945978 , explore ratio: 0.27447899782380536\n",
      "Episode 474 , steps =  635 , total reward: -30.12396476200771 , steps_avg: 418.02526315789476 , reward_avg: -29.37527512337532 , distance traveled: 60.95074164988472 , average speed: 0.0959854199210783 , explore ratio: 0.273936260760551\n",
      "Episode 475 , steps =  55 , total reward: -9.792723417983707 , steps_avg: 417.2626050420168 , reward_avg: -29.334135308868195 , distance traveled: -0.6846889907866713 , average speed: -0.012448890741575843 , explore ratio: 0.27339459687055273\n",
      "Episode 476 , steps =  70 , total reward: -5.586378130633388 , steps_avg: 416.5345911949685 , reward_avg: -29.284349654406487 , distance traveled: 4.317125694304706 , average speed: 0.06167322420435294 , explore ratio: 0.27285400403178706\n",
      "Episode 477 , steps =  245 , total reward: -1.2784780381589105 , steps_avg: 416.1757322175732 , reward_avg: -29.225759964832747 , distance traveled: 40.596673927120854 , average speed: 0.16570070990661573 , explore ratio: 0.2723144801264263\n",
      "Episode 478 , steps =  62 , total reward: -4.728305157763887 , steps_avg: 415.43632567849687 , reward_avg: -29.174617052918197 , distance traveled: 4.349409501263871 , average speed: 0.07015176614941727 , explore ratio: 0.2717760230408305\n",
      "Episode 479 , steps =  74 , total reward: -6.081670067097996 , steps_avg: 414.725 , reward_avg: -29.12650674669774 , distance traveled: 3.9882139425119383 , average speed: 0.053894783006918086 , explore ratio: 0.2712386306655391\n",
      "Episode 480 , steps =  64 , total reward: -2.6463310014413066 , steps_avg: 413.995841995842 , reward_avg: -29.071454406271016 , distance traveled: 10.18948416173458 , average speed: 0.1592106900271028 , explore ratio: 0.27070230089526265\n",
      "Episode 481 , steps =  304 , total reward: 2.027460530575335 , steps_avg: 413.76763485477176 , reward_avg: -29.00693383586262 , distance traveled: 54.43209059860557 , average speed: 0.1790529296006762 , explore ratio: 0.2701670316288745\n",
      "Episode 482 , steps =  117 , total reward: -12.051495941482491 , steps_avg: 413.1532091097308 , reward_avg: -28.97182940958026 , distance traveled: 6.023169318884611 , average speed: 0.05148007964858642 , explore ratio: 0.26963282076940276\n",
      "Episode 483 , steps =  57 , total reward: -0.043385733663419135 , steps_avg: 412.41735537190084 , reward_avg: -28.912059897853155 , distance traveled: 9.983117070794107 , average speed: 0.1751424047507738 , explore ratio: 0.26909966622402176\n",
      "Episode 484 , steps =  382 , total reward: 1.0647713401888603 , steps_avg: 412.3546391752577 , reward_avg: -28.850251998393276 , distance traveled: 66.42252676069734 , average speed: 0.17388096010653753 , explore ratio: 0.26856756590404424\n",
      "Episode 485 , steps =  58 , total reward: -11.731651845096922 , steps_avg: 411.6255144032922 , reward_avg: -28.815028541287727 , distance traveled: -0.8596442910656334 , average speed: -0.01482145329423506 , explore ratio: 0.2680365177249129\n",
      "Episode 486 , steps =  291 , total reward: -6.26829398448706 , steps_avg: 411.37782340862424 , reward_avg: -28.76873134507253 , distance traveled: 54.95481263335791 , average speed: 0.1888481533792368 , explore ratio: 0.2675065196061922\n",
      "Episode 487 , steps =  67 , total reward: -9.47843949217909 , steps_avg: 410.672131147541 , reward_avg: -28.729202058488735 , distance traveled: 2.66794689450413 , average speed: 0.03982010290304672 , explore ratio: 0.26697756947156054\n",
      "Episode 488 , steps =  74 , total reward: -4.295719206186017 , steps_avg: 409.9836400817996 , reward_avg: -28.67923583588689 , distance traveled: 9.465649865269663 , average speed: 0.12791418736850896 , explore ratio: 0.26644966524880176\n",
      "Episode 489 , steps =  92 , total reward: -13.02345970686464 , steps_avg: 409.33469387755105 , reward_avg: -28.64728527235827 , distance traveled: 5.9353906740155065 , average speed: 0.06451511602190768 , explore ratio: 0.2659228048697972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 490 , steps =  119 , total reward: -4.998626306052634 , steps_avg: 408.74338085539716 , reward_avg: -28.59912099747781 , distance traveled: 22.651829813104133 , average speed: 0.1903515110344885 , explore ratio: 0.26539698627051755\n",
      "Episode 491 , steps =  81 , total reward: -13.262405633344006 , steps_avg: 408.0772357723577 , reward_avg: -28.567948811778354 , distance traveled: -0.6849921905994413 , average speed: -0.008456693711104213 , explore ratio: 0.2648722073910148\n",
      "Episode 492 , steps =  77 , total reward: -22.797549255079915 , steps_avg: 407.40567951318457 , reward_avg: -28.55624414736314 , distance traveled: -14.325239401969595 , average speed: -0.1860420701554493 , explore ratio: 0.2643484661754141\n",
      "Episode 493 , steps =  99 , total reward: -11.27078564114435 , steps_avg: 406.7813765182186 , reward_avg: -28.52125334067039 , distance traveled: 8.656871114373203 , average speed: 0.0874431425694263 , explore ratio: 0.2638257605719058\n",
      "Episode 494 , steps =  284 , total reward: 17.394739879020186 , steps_avg: 406.53333333333336 , reward_avg: -28.42849375840839 , distance traveled: 75.1072267600894 , average speed: 0.26446206605665284 , explore ratio: 0.2633040885327374\n",
      "Episode 495 , steps =  133 , total reward: -9.441403494269904 , steps_avg: 405.9818548387097 , reward_avg: -28.390213334488756 , distance traveled: 16.31097807680955 , average speed: 0.12263893290834249 , explore ratio: 0.2627834480142054\n",
      "Episode 496 , steps =  135 , total reward: -8.974046467294302 , steps_avg: 405.4366197183099 , reward_avg: -28.35114660034953 , distance traveled: 10.540974201243372 , average speed: 0.07808129037958053 , explore ratio: 0.26226383697664746\n",
      "Episode 497 , steps =  514 , total reward: -20.094156066696264 , steps_avg: 405.6546184738956 , reward_avg: -28.33456629807312 , distance traveled: 60.22149153538046 , average speed: 0.1171624348937363 , explore ratio: 0.26174525338443433\n",
      "Episode 498 , steps =  81 , total reward: -3.6440784503438923 , steps_avg: 405.00400801603206 , reward_avg: -28.28508636250653 , distance traveled: 10.587486042380329 , average speed: 0.13070970422691763 , explore ratio: 0.26122769520596184\n",
      "Episode 499 , steps =  83 , total reward: -20.769562265476225 , steps_avg: 404.36 , reward_avg: -28.27005531431247 , distance traveled: -15.458211813010276 , average speed: -0.1862435158194009 , explore ratio: 0.26071116041364306\n",
      "Episode 500 , steps =  90 , total reward: -25.461272815757745 , steps_avg: 403.7325349301397 , reward_avg: -28.26444896201994 , distance traveled: -19.371840902902193 , average speed: -0.21524267669891325 , explore ratio: 0.2601956469839002\n",
      "Episode 501 , steps =  76 , total reward: -20.325482539302985 , steps_avg: 403.0796812749004 , reward_avg: -28.248634287871106 , distance traveled: -13.827828643396495 , average speed: -0.18194511372890126 , explore ratio: 0.25968115289715676\n",
      "Episode 502 , steps =  55 , total reward: -5.912438888785747 , steps_avg: 402.3876739562624 , reward_avg: -28.204228332803343 , distance traveled: 1.5318578981235624 , average speed: 0.027851961784064773 , explore ratio: 0.2591676761378297\n",
      "Episode 503 , steps =  61 , total reward: -5.287381114380432 , steps_avg: 401.71031746031747 , reward_avg: -28.158758397846153 , distance traveled: 6.717706185579299 , average speed: 0.11012633091113605 , explore ratio: 0.2586552146943214\n",
      "Episode 504 , steps =  73 , total reward: -10.68015539924366 , steps_avg: 401.05940594059405 , reward_avg: -28.124147302799415 , distance traveled: 1.5687397531606255 , average speed: 0.021489585659734595 , explore ratio: 0.25814376655901183\n",
      "Episode 505 , steps =  398 , total reward: 2.3110780028681788 , steps_avg: 401.05335968379444 , reward_avg: -28.063998636187424 , distance traveled: 68.37800898715852 , average speed: 0.1718040426813028 , explore ratio: 0.25763332972825076\n",
      "Episode 506 , steps =  172 , total reward: -3.847509634320325 , steps_avg: 400.6015779092702 , reward_avg: -28.01623435807723 , distance traveled: 26.32555939804763 , average speed: 0.15305557789562577 , explore ratio: 0.2571239022023498\n",
      "Episode 507 , steps =  119 , total reward: -5.189072916525118 , steps_avg: 400.0472440944882 , reward_avg: -27.971299000908825 , distance traveled: 15.710140060713751 , average speed: 0.1320179837034769 , explore ratio: 0.25661548198557466\n",
      "Episode 508 , steps =  51 , total reward: -23.271330010920146 , steps_avg: 399.3614931237721 , reward_avg: -27.9620652700837 , distance traveled: -5.740239090621471 , average speed: -0.11255370765924454 , explore ratio: 0.2561080670861372\n",
      "Episode 509 , steps =  35 , total reward: -8.147763086122769 , steps_avg: 398.6470588235294 , reward_avg: -27.92321369717397 , distance traveled: -2.620753251314163 , average speed: -0.0748786643232618 , explore ratio: 0.25560165551618785\n",
      "Episode 510 , steps =  77 , total reward: -11.801286749783285 , steps_avg: 398.01761252446187 , reward_avg: -27.891663937981427 , distance traveled: -4.2212834537029265 , average speed: -0.05482186303510294 , explore ratio: 0.2550962452918076\n",
      "Episode 511 , steps =  412 , total reward: 19.059631931226736 , steps_avg: 398.044921875 , reward_avg: -27.79996218823688 , distance traveled: 95.9395933603495 , average speed: 0.23286309068045996 , explore ratio: 0.2545918344330002\n",
      "Episode 512 , steps =  119 , total reward: -30.64830123370388 , steps_avg: 397.5009746588694 , reward_avg: -27.8055145060643 , distance traveled: -19.31979369501583 , average speed: -0.1623512075211414 , explore ratio: 0.2540884209636848\n",
      "Episode 513 , steps =  81 , total reward: -16.950083019057917 , steps_avg: 396.8852140077821 , reward_avg: -27.784394989552617 , distance traveled: -9.569229637223764 , average speed: -0.11813863749658968 , explore ratio: 0.2535860029116876\n",
      "Episode 514 , steps =  273 , total reward: 8.470100937326734 , steps_avg: 396.6446601941748 , reward_avg: -27.713997910082945 , distance traveled: 59.754820297658455 , average speed: 0.21888212563244855 , explore ratio: 0.2530845783087347\n",
      "Episode 515 , steps =  126 , total reward: 4.399754523124536 , steps_avg: 396.12015503875966 , reward_avg: -27.651761955755024 , distance traveled: 33.0313481982029 , average speed: 0.26215355712859445 , explore ratio: 0.2525841451904441\n",
      "Episode 516 , steps =  149 , total reward: -9.148962107737253 , steps_avg: 395.642166344294 , reward_avg: -27.615973174617658 , distance traveled: 14.718503776397554 , average speed: 0.0987819045395809 , explore ratio: 0.2520847015963179\n",
      "Episode 517 , steps =  76 , total reward: -18.797518265288943 , steps_avg: 395.0250965250965 , reward_avg: -27.598949130391155 , distance traveled: -9.993308366127314 , average speed: -0.13149089955430676 , explore ratio: 0.2515862455697349\n",
      "Episode 518 , steps =  121 , total reward: -17.57785853756403 , steps_avg: 394.4971098265896 , reward_avg: -27.579640670674724 , distance traveled: -3.4694495044089866 , average speed: -0.02867313640007427 , explore ratio: 0.25108877515794276\n",
      "Episode 519 , steps =  149 , total reward: 1.7824505784157525 , steps_avg: 394.025 , reward_avg: -27.523175110580322 , distance traveled: 33.2355720694363 , average speed: 0.22305753066735773 , explore ratio: 0.25059228841205033\n",
      "Episode 520 , steps =  134 , total reward: -5.9688527884756635 , steps_avg: 393.5259117082534 , reward_avg: -27.48180405046112 , distance traveled: 17.45927099268884 , average speed: 0.13029306710961822 , explore ratio: 0.2500967833870201\n",
      "Episode 521 , steps =  148 , total reward: -1.1904614809223797 , steps_avg: 393.05555555555554 , reward_avg: -27.431437493814492 , distance traveled: 27.135201608687634 , average speed: 0.18334595681545698 , explore ratio: 0.24960225814166068\n",
      "Episode 522 , steps =  190 , total reward: -8.18189883607131 , steps_avg: 392.6673040152964 , reward_avg: -27.394631492556858 , distance traveled: 22.26692577391862 , average speed: 0.11719434617851905 , explore ratio: 0.24910871073861884\n",
      "Episode 523 , steps =  59 , total reward: -2.2713949846339747 , steps_avg: 392.03053435114504 , reward_avg: -27.34668638471731 , distance traveled: 9.598426254987714 , average speed: 0.16268519076250362 , explore ratio: 0.24861613924437231\n",
      "Episode 524 , steps =  147 , total reward: 8.151824398848538 , steps_avg: 391.56380952380954 , reward_avg: -27.279070173700994 , distance traveled: 38.8462489720434 , average speed: 0.2642601970887306 , explore ratio: 0.248124541729222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 525 , steps =  669 , total reward: -22.352994433180612 , steps_avg: 392.09125475285174 , reward_avg: -27.269705010696203 , distance traveled: 79.47589759348097 , average speed: 0.11879805320400742 , explore ratio: 0.24763391626728445\n",
      "Episode 526 , steps =  72 , total reward: -19.76393484772433 , steps_avg: 391.48387096774195 , reward_avg: -27.255462562569118 , distance traveled: -1.395555437654257 , average speed: -0.01938271441186468 , explore ratio: 0.2471442609364844\n",
      "Episode 527 , steps =  58 , total reward: -5.864824630156158 , steps_avg: 390.85227272727275 , reward_avg: -27.214949990727426 , distance traveled: 3.904212734922767 , average speed: 0.06731401267108218 , explore ratio: 0.24665557381854708\n",
      "Episode 528 , steps =  132 , total reward: -1.115870477683845 , steps_avg: 390.36294896030245 , reward_avg: -27.16561335648727 , distance traveled: 23.666213545314964 , average speed: 0.1792894965554164 , explore ratio: 0.24616785299899085\n",
      "Episode 529 , steps =  54 , total reward: -8.22643394973626 , steps_avg: 389.72830188679245 , reward_avg: -27.12987905571981 , distance traveled: 0.8984528922289607 , average speed: 0.016638016522758533 , explore ratio: 0.24568109656711962\n",
      "Episode 530 , steps =  97 , total reward: -20.22778443229631 , steps_avg: 389.17702448210923 , reward_avg: -27.11688076076045 , distance traveled: -10.113701292425393 , average speed: -0.10426496177758138 , explore ratio: 0.2451953026160154\n",
      "Episode 531 , steps =  372 , total reward: 19.993805342447644 , steps_avg: 389.14473684210526 , reward_avg: -27.028326839513813 , distance traveled: 90.58357600048183 , average speed: 0.24350423656043502 , explore ratio: 0.24471046924253084\n",
      "Episode 532 , steps =  221 , total reward: 10.149222391252707 , steps_avg: 388.8292682926829 , reward_avg: -26.958575340018943 , distance traveled: 56.55859233828264 , average speed: 0.2559212322999214 , explore ratio: 0.24422659454728168\n",
      "Episode 533 , steps =  92 , total reward: -7.517955569869534 , steps_avg: 388.27340823970036 , reward_avg: -26.922169685018662 , distance traveled: 9.39020587426261 , average speed: 0.10206745515502838 , explore ratio: 0.24374367663463944\n",
      "Episode 534 , steps =  81 , total reward: -22.92484106979147 , steps_avg: 387.69906542056077 , reward_avg: -26.91469804274721 , distance traveled: -15.542633052729071 , average speed: -0.19188435867566755 , explore ratio: 0.24326171361272392\n",
      "Episode 535 , steps =  828 , total reward: 51.04935254730526 , steps_avg: 388.5205223880597 , reward_avg: -26.769242724482186 , distance traveled: 203.31770963623188 , average speed: 0.245552789415739 , explore ratio: 0.2427807035933958\n",
      "Episode 536 , steps =  35 , total reward: -7.650965441549199 , steps_avg: 387.86219739292363 , reward_avg: -26.73364071836872 , distance traveled: -2.34942232131958 , average speed: -0.06712635203770229 , explore ratio: 0.2423006446922492\n",
      "Episode 537 , steps =  538 , total reward: 10.943178304535607 , steps_avg: 388.14126394052045 , reward_avg: -26.663609456244362 , distance traveled: 103.63886020455094 , average speed: 0.19263728662555937 , explore ratio: 0.24182153502860446\n",
      "Episode 538 , steps =  67 , total reward: -2.2886942113960744 , steps_avg: 387.54545454545456 , reward_avg: -26.618386978981192 , distance traveled: 12.602356628179553 , average speed: 0.188094875047456 , explore ratio: 0.24134337272550052\n",
      "Episode 539 , steps =  162 , total reward: -2.4847457689071817 , steps_avg: 387.1277777777778 , reward_avg: -26.57369505081439 , distance traveled: 22.991654589716354 , average speed: 0.1419237937636812 , explore ratio: 0.2408661559096878\n",
      "Episode 540 , steps =  109 , total reward: -6.615792663763597 , steps_avg: 386.61367837338264 , reward_avg: -26.536804288546275 , distance traveled: 9.669386586695909 , average speed: 0.08870996868528357 , explore ratio: 0.2403898827116207\n",
      "Episode 541 , steps =  40 , total reward: -16.076231261671836 , steps_avg: 385.97416974169744 , reward_avg: -26.517504338312186 , distance traveled: -2.2983804874867206 , average speed: -0.057459512187168015 , explore ratio: 0.2399145512654504\n",
      "Episode 542 , steps =  114 , total reward: -15.278248941658074 , steps_avg: 385.4732965009208 , reward_avg: -26.496805893751127 , distance traveled: -0.3317609919235076 , average speed: -0.0029101841396798915 , explore ratio: 0.2394401597090174\n",
      "Episode 543 , steps =  495 , total reward: 28.326796727429006 , steps_avg: 385.67463235294116 , reward_avg: -26.3960272124622 , distance traveled: 119.10169097989802 , average speed: 0.2406094767270667 , explore ratio: 0.23896670618384444\n",
      "Episode 544 , steps =  42 , total reward: -16.86583493241668 , steps_avg: 385.0440366972477 , reward_avg: -26.378540621122664 , distance traveled: -2.8064189940691 , average speed: -0.06681949985878809 , explore ratio: 0.23849418883512896\n",
      "Episode 545 , steps =  70 , total reward: -17.324060809221123 , steps_avg: 384.467032967033 , reward_avg: -26.36195732476387 , distance traveled: -8.195621223896742 , average speed: -0.11708030319852489 , explore ratio: 0.23802260581173604\n",
      "Episode 546 , steps =  58 , total reward: -14.772104544748867 , steps_avg: 383.8702010968921 , reward_avg: -26.340769294087426 , distance traveled: -7.938426201939585 , average speed: -0.13686941727482044 , explore ratio: 0.23755195526619105\n",
      "Episode 547 , steps =  198 , total reward: 0.4097754918094555 , steps_avg: 383.5310218978102 , reward_avg: -26.291954431339438 , distance traveled: 33.83523969903588 , average speed: 0.1708850489850297 , explore ratio: 0.23708223535467246\n",
      "Episode 548 , steps =  36 , total reward: -14.849283899821334 , steps_avg: 382.89799635701274 , reward_avg: -26.27111167991591 , distance traveled: -1.2199198718369004 , average speed: -0.03388666310658057 , explore ratio: 0.2366134442370046\n",
      "Episode 549 , steps =  74 , total reward: -0.19240466381609528 , steps_avg: 382.3363636363636 , reward_avg: -26.223695848977545 , distance traveled: 16.612850573658942 , average speed: 0.22449798072512084 , explore ratio: 0.2361455800766504\n",
      "Episode 550 , steps =  420 , total reward: 9.386418301304769 , steps_avg: 382.40471869328496 , reward_avg: -26.159067692624944 , distance traveled: 83.38617757782339 , average speed: 0.19853851804243663 , explore ratio: 0.2356786410407043\n",
      "Episode 551 , steps =  399 , total reward: 37.91991864483301 , steps_avg: 382.4347826086956 , reward_avg: -26.04298257244839 , distance traveled: 118.67907624945045 , average speed: 0.2974412938582718 , explore ratio: 0.23521262529988496\n",
      "Episode 552 , steps =  39 , total reward: -10.18014112166936 , steps_avg: 381.8137432188065 , reward_avg: -26.014297506533783 , distance traveled: -4.02091846704483 , average speed: -0.10310047351397 , explore ratio: 0.23474753102852816\n",
      "Episode 553 , steps =  40 , total reward: -10.137519693830983 , steps_avg: 381.19675090252707 , reward_avg: -25.985639062828543 , distance traveled: -4.52793083935976 , average speed: -0.113198270983994 , explore ratio: 0.23428335640457962\n",
      "Episode 554 , steps =  58 , total reward: -7.37593181375787 , steps_avg: 380.6144144144144 , reward_avg: -25.95210805877616 , distance traveled: 2.533858268335461 , average speed: 0.04368721152302519 , explore ratio: 0.23382009960958788\n",
      "Episode 555 , steps =  127 , total reward: -14.731579775700975 , steps_avg: 380.158273381295 , reward_avg: -25.931927252511638 , distance traveled: 8.295281375013289 , average speed: 0.065317176181207 , explore ratio: 0.2333577588286972\n",
      "Episode 556 , steps =  37 , total reward: -12.871545379375423 , steps_avg: 379.5421903052065 , reward_avg: -25.908479529220553 , distance traveled: 1.423724021092057 , average speed: 0.03847902759708262 , explore ratio: 0.23289633225064035\n",
      "Episode 557 , steps =  42 , total reward: -19.893002009993417 , steps_avg: 378.93727598566306 , reward_avg: -25.897699103558853 , distance traveled: -2.9212082708626985 , average speed: -0.06955257787768329 , explore ratio: 0.23243581806773167\n",
      "Episode 558 , steps =  73 , total reward: -1.7887423568007872 , steps_avg: 378.38998211091234 , reward_avg: -25.85457037950383 , distance traveled: 12.655130908191206 , average speed: 0.17335795764645487 , explore ratio: 0.2319762144758598\n",
      "Episode 559 , steps =  65 , total reward: -7.915078189975273 , steps_avg: 377.83035714285717 , reward_avg: -25.822535572022527 , distance traveled: 3.0675707566738124 , average speed: 0.04719339625652019 , explore ratio: 0.23151751967448084\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 560 , steps =  122 , total reward: -18.085532369814796 , steps_avg: 377.37433155080214 , reward_avg: -25.808744122464226 , distance traveled: 2.8502804304728304 , average speed: 0.023362954348137954 , explore ratio: 0.23105973186661102\n",
      "Episode 561 , steps =  98 , total reward: -8.245930194399019 , steps_avg: 376.87722419928826 , reward_avg: -25.777493563873364 , distance traveled: 9.492260673525742 , average speed: 0.096859802791079 , explore ratio: 0.23060284925881994\n",
      "Episode 562 , steps =  280 , total reward: 8.94247565872344 , steps_avg: 376.7051509769094 , reward_avg: -25.715823991541928 , distance traveled: 60.685031197434306 , average speed: 0.2167322542765511 , explore ratio: 0.23014687006122334\n",
      "Episode 563 , steps =  195 , total reward: -2.4126361586526137 , steps_avg: 376.3829787234043 , reward_avg: -25.674506282618367 , distance traveled: 29.484719259431575 , average speed: 0.1512036885099055 , explore ratio: 0.22969179248747615\n",
      "Episode 564 , steps =  217 , total reward: -3.0187840592048003 , steps_avg: 376.10088495575224 , reward_avg: -25.634407659214094 , distance traveled: 34.750678187403814 , average speed: 0.16014137413550145 , explore ratio: 0.2292376147547656\n",
      "Episode 565 , steps =  62 , total reward: -18.498983461077017 , steps_avg: 375.5459363957597 , reward_avg: -25.621800902680285 , distance traveled: -8.157614593505858 , average speed: -0.13157442892751384 , explore ratio: 0.22878433508380402\n",
      "Episode 566 , steps =  67 , total reward: -2.615612869019932 , steps_avg: 375.0017636684303 , reward_avg: -25.581225615142966 , distance traveled: 10.855684289038184 , average speed: 0.16202513864236096 , explore ratio: 0.22833195169882206\n",
      "Episode 567 , steps =  203 , total reward: -19.23201891643675 , steps_avg: 374.69894366197184 , reward_avg: -25.57004743433538 , distance traveled: 10.657801169604063 , average speed: 0.05250148359410869 , explore ratio: 0.22788046282756166\n",
      "Episode 568 , steps =  709 , total reward: -73.0384426283915 , steps_avg: 375.286467486819 , reward_avg: -25.653471678964657 , distance traveled: 13.581369982991593 , average speed: 0.01915566993369759 , explore ratio: 0.22742986670126908\n",
      "Episode 569 , steps =  51 , total reward: -8.93867941641374 , steps_avg: 374.71754385964914 , reward_avg: -25.62414748201281 , distance traveled: 1.869352873982862 , average speed: 0.03665397792123259 , explore ratio: 0.226980161554688\n",
      "Episode 570 , steps =  113 , total reward: -3.214849987775716 , steps_avg: 374.25919439579684 , reward_avg: -25.584901777119228 , distance traveled: 15.209443162679676 , average speed: 0.13459684214760775 , explore ratio: 0.22653134562605265\n",
      "Episode 571 , steps =  64 , total reward: -8.125206400676323 , steps_avg: 373.7167832167832 , reward_avg: -25.554377834153417 , distance traveled: 3.0587451320886614 , average speed: 0.047792892688885334 , explore ratio: 0.2260834171570808\n",
      "Episode 572 , steps =  132 , total reward: 8.449647471321745 , steps_avg: 373.29493891797557 , reward_avg: -25.49503398545276 , distance traveled: 37.24353477537632 , average speed: 0.28214799072254787 , explore ratio: 0.22563637439296697\n",
      "Episode 573 , steps =  55 , total reward: -0.8635101360858729 , steps_avg: 372.7404181184669 , reward_avg: -25.452121922997417 , distance traveled: 8.863556048870088 , average speed: 0.16115556452491067 , explore ratio: 0.2251902155823755\n",
      "Episode 574 , steps =  118 , total reward: -3.156001425826929 , steps_avg: 372.2973913043478 , reward_avg: -25.41334606126321 , distance traveled: 20.43786464609206 , average speed: 0.17320224276349203 , explore ratio: 0.22474493897743375\n",
      "Episode 575 , steps =  76 , total reward: -0.2977334845823637 , steps_avg: 371.7829861111111 , reward_avg: -25.369742567206472 , distance traveled: 14.209324427247049 , average speed: 0.1869647950953559 , explore ratio: 0.22430054283372516\n",
      "Episode 576 , steps =  127 , total reward: -6.807188178843521 , steps_avg: 371.3587521663778 , reward_avg: -25.337571762373955 , distance traveled: 13.374661827151426 , average speed: 0.10531229785158604 , explore ratio: 0.22385702541028252\n",
      "Episode 577 , steps =  559 , total reward: 18.327948879808776 , steps_avg: 371.6833910034602 , reward_avg: -25.26202587890997 , distance traveled: 116.46920680023732 , average speed: 0.20835278497359092 , explore ratio: 0.22341438496958102\n",
      "Episode 578 , steps =  309 , total reward: -13.01921653875338 , steps_avg: 371.57512953367876 , reward_avg: -25.240881130481373 , distance traveled: 33.20514140973798 , average speed: 0.10746000456225885 , explore ratio: 0.22297261977753158\n",
      "Episode 579 , steps =  352 , total reward: -3.6053572344029003 , steps_avg: 371.54137931034484 , reward_avg: -25.20357850307434 , distance traveled: 52.987720116600386 , average speed: 0.15053329578579655 , explore ratio: 0.22253172810347396\n",
      "Episode 580 , steps =  40 , total reward: -15.404304458334432 , steps_avg: 370.9707401032702 , reward_avg: -25.186712282687523 , distance traveled: -2.3340787500143048 , average speed: -0.05835196875035762 , explore ratio: 0.22209170822017008\n",
      "Episode 581 , steps =  55 , total reward: -13.473134474974747 , steps_avg: 370.42783505154637 , reward_avg: -25.166585860337506 , distance traveled: -2.0145907076261937 , average speed: -0.03662892195683989 , explore ratio: 0.2216525584037971\n",
      "Episode 582 , steps =  78 , total reward: -19.6416408701092 , steps_avg: 369.926243567753 , reward_avg: -25.157109110783082 , distance traveled: -7.47296958250925 , average speed: -0.09580730233986218 , explore ratio: 0.22121427693394083\n",
      "Episode 583 , steps =  241 , total reward: 10.394241433269638 , steps_avg: 369.7054794520548 , reward_avg: -25.096233510536415 , distance traveled: 58.18978695346045 , average speed: 0.24145139814713878 , explore ratio: 0.22077686209358888\n",
      "Episode 584 , steps =  73 , total reward: -19.00421236562294 , steps_avg: 369.1982905982906 , reward_avg: -25.085819799177592 , distance traveled: -3.9681299794837828 , average speed: -0.05435794492443538 , explore ratio: 0.22034031216912395\n",
      "Episode 585 , steps =  91 , total reward: -8.379573485023663 , steps_avg: 368.72354948805463 , reward_avg: -25.05731084642306 , distance traveled: 7.5181875014863895 , average speed: 0.08261744507127901 , explore ratio: 0.2199046254503172\n",
      "Episode 586 , steps =  42 , total reward: -15.674345579357816 , steps_avg: 368.16695059625215 , reward_avg: -25.04132623779092 , distance traveled: -1.5125036881864071 , average speed: -0.03601199257586683 , explore ratio: 0.21946980023032142\n",
      "Episode 587 , steps =  62 , total reward: -5.970293450221419 , steps_avg: 367.6462585034014 , reward_avg: -25.00889250856036 , distance traveled: 4.042759107565506 , average speed: 0.06520579205750816 , explore ratio: 0.21903583480566446\n",
      "Episode 588 , steps =  189 , total reward: -21.412497918203997 , steps_avg: 367.3429541595925 , reward_avg: -25.00278657546977 , distance traveled: 1.425377990070557 , average speed: 0.007541682487145804 , explore ratio: 0.21860272747624246\n",
      "Episode 589 , steps =  40 , total reward: -17.661982227060953 , steps_avg: 366.7881355932203 , reward_avg: -24.990344534201284 , distance traveled: -2.5389015355333684 , average speed: -0.06347253838833421 , explore ratio: 0.21817047654531327\n",
      "Episode 590 , steps =  49 , total reward: -2.095545651703454 , steps_avg: 366.2504230118443 , reward_avg: -24.951605449797736 , distance traveled: 4.829872342944145 , average speed: 0.09856882332539071 , explore ratio: 0.21773908031948977\n",
      "Episode 591 , steps =  463 , total reward: 24.880317891171153 , steps_avg: 366.41385135135135 , reward_avg: -24.867429903613665 , distance traveled: 111.61558970354491 , average speed: 0.24107038812860673 , explore ratio: 0.2173085371087332\n",
      "Episode 592 , steps =  67 , total reward: -4.161741675401732 , steps_avg: 365.9089376053963 , reward_avg: -24.832513060058503 , distance traveled: 7.418495416939258 , average speed: 0.11072381219312326 , explore ratio: 0.21687884522634662\n",
      "Episode 593 , steps =  64 , total reward: 0.14430704073173356 , steps_avg: 365.4006734006734 , reward_avg: -24.790464541370305 , distance traveled: 12.72342734634876 , average speed: 0.19880355228669938 , explore ratio: 0.21645000298896822\n",
      "Episode 594 , steps =  78 , total reward: -12.826492999814457 , steps_avg: 364.91764705882355 , reward_avg: -24.770357026174413 , distance traveled: 2.399163914769887 , average speed: 0.030758511727819064 , explore ratio: 0.21602200871656474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 595 , steps =  222 , total reward: -16.88990361909933 , steps_avg: 364.67785234899327 , reward_avg: -24.75713478891422 , distance traveled: 14.893281856477257 , average speed: 0.06708685520935702 , explore ratio: 0.21559486073242498\n",
      "Episode 596 , steps =  102 , total reward: -5.871849368810042 , steps_avg: 364.23785594639867 , reward_avg: -24.725501144994446 , distance traveled: 14.06881980777718 , average speed: 0.1379296059585998 , explore ratio: 0.21516855736315313\n",
      "Episode 597 , steps =  107 , total reward: -13.804586198571453 , steps_avg: 363.8076923076923 , reward_avg: -24.707238745418486 , distance traveled: 6.808626273237169 , average speed: 0.06363202124520718 , explore ratio: 0.21474309693866223\n",
      "Episode 598 , steps =  76 , total reward: -23.556612594485905 , steps_avg: 363.3272120200334 , reward_avg: -24.705317833647314 , distance traveled: -4.032468474861235 , average speed: -0.053058795721858364 , explore ratio: 0.21431847779216762\n",
      "Episode 599 , steps =  217 , total reward: 14.675465255551027 , steps_avg: 363.0833333333333 , reward_avg: -24.63968319516532 , distance traveled: 59.86458555467427 , average speed: 0.2758736661505727 , explore ratio: 0.21389469826018048\n",
      "Episode 600 , steps =  49 , total reward: -24.37010563272238 , steps_avg: 362.56073211314475 , reward_avg: -24.63923464680851 , distance traveled: -6.270131414048373 , average speed: -0.12796186559282394 , explore ratio: 0.21347175668250126\n",
      "Episode 601 , steps =  68 , total reward: -10.048938283464564 , steps_avg: 362.07142857142856 , reward_avg: -24.614998274111926 , distance traveled: 1.5138161102682353 , average speed: 0.022262001621591695 , explore ratio: 0.21304965140221316\n",
      "Episode 602 , steps =  63 , total reward: -5.599245089044798 , steps_avg: 361.57545605306797 , reward_avg: -24.583463028365543 , distance traveled: 5.984981557577848 , average speed: 0.09499970726314044 , explore ratio: 0.21262838076567567\n",
      "Episode 603 , steps =  452 , total reward: -20.309423010578126 , steps_avg: 361.7251655629139 , reward_avg: -24.576386803170532 , distance traveled: 50.70957029906859 , average speed: 0.1121893148209482 , explore ratio: 0.2122079431225181\n",
      "Episode 604 , steps =  60 , total reward: -7.986497568379464 , steps_avg: 361.22644628099175 , reward_avg: -24.548965498650215 , distance traveled: 1.2218305044248705 , average speed: 0.020363841740414508 , explore ratio: 0.21178833682563306\n",
      "Episode 605 , steps =  61 , total reward: 0.032157097057127416 , steps_avg: 360.73102310231025 , reward_avg: -24.50840259007644 , distance traveled: 11.759145091921093 , average speed: 0.1927728703593622 , explore ratio: 0.21136956023117007\n",
      "Episode 606 , steps =  56 , total reward: -0.45188094488158953 , steps_avg: 360.22899505766065 , reward_avg: -24.4687707587005 , distance traveled: 10.309137609601018 , average speed: 0.1840917430285896 , explore ratio: 0.21095161169852905\n",
      "Episode 607 , steps =  196 , total reward: 10.819491045663113 , steps_avg: 359.95888157894734 , reward_avg: -24.41073085441701 , distance traveled: 55.07995789457111 , average speed: 0.2810201933396485 , explore ratio: 0.210534489590354\n",
      "Episode 608 , steps =  317 , total reward: -55.2347718953551 , steps_avg: 359.88834154351395 , reward_avg: -24.461345043318385 , distance traveled: -27.273180186571544 , average speed: -0.08603526872735502 , explore ratio: 0.2101181922725265\n",
      "Episode 609 , steps =  69 , total reward: 2.290341054351378 , steps_avg: 359.41147540983604 , reward_avg: -24.41748982020745 , distance traveled: 14.666985046863557 , average speed: 0.212565000679182 , explore ratio: 0.20970271811415936\n",
      "Episode 610 , steps =  492 , total reward: -6.56441220699751 , steps_avg: 359.6284779050736 , reward_avg: -24.38827038057863 , distance traveled: 70.83565007396048 , average speed: 0.14397489852430992 , explore ratio: 0.2092880654875901\n",
      "Episode 611 , steps =  124 , total reward: -5.645834709680958 , steps_avg: 359.2434640522876 , reward_avg: -24.357645485691542 , distance traveled: 14.574330662246798 , average speed: 0.1175349246955387 , explore ratio: 0.20887423276837477\n",
      "Episode 612 , steps =  83 , total reward: -29.870128123518704 , steps_avg: 358.79282218597064 , reward_avg: -24.36663811642209 , distance traveled: -14.80473769381642 , average speed: -0.1783703336604388 , explore ratio: 0.20846121833528147\n",
      "Episode 613 , steps =  163 , total reward: -6.476999621789297 , steps_avg: 358.47394136807816 , reward_avg: -24.337501897375457 , distance traveled: 24.15075670240446 , average speed: 0.14816415154849363 , explore ratio: 0.20804902057028402\n",
      "Episode 614 , steps =  521 , total reward: -12.645656467720906 , steps_avg: 358.73821138211383 , reward_avg: -24.31849076659553 , distance traveled: 67.73927036728712 , average speed: 0.13001779341129965 , explore ratio: 0.20763763785855557\n",
      "Episode 615 , steps =  53 , total reward: -1.9233987961218983 , steps_avg: 358.2418831168831 , reward_avg: -24.282135097812294 , distance traveled: 6.4649006080627425 , average speed: 0.1219792567559008 , explore ratio: 0.2072270685884624\n",
      "Episode 616 , steps =  106 , total reward: -8.532071378344058 , steps_avg: 357.83306320907616 , reward_avg: -24.256608252237793 , distance traveled: 9.920585142150522 , average speed: 0.09359042586934455 , explore ratio: 0.2068173111515575\n",
      "Episode 617 , steps =  405 , total reward: 19.814646479024848 , steps_avg: 357.9093851132686 , reward_avg: -24.185295542316656 , distance traveled: 96.80164175570006 , average speed: 0.23901639939679029 , explore ratio: 0.20640836394257425\n",
      "Episode 618 , steps =  217 , total reward: 12.654423566386704 , steps_avg: 357.68174474959613 , reward_avg: -24.12578064876463 , distance traveled: 54.13166955817492 , average speed: 0.24945469842476922 , explore ratio: 0.20600022535942028\n",
      "Episode 619 , steps =  106 , total reward: -23.717853487408384 , steps_avg: 357.2758064516129 , reward_avg: -24.125122701730184 , distance traveled: -3.6466338202357296 , average speed: -0.03440220585128047 , explore ratio: 0.205592893803171\n",
      "Episode 620 , steps =  334 , total reward: -0.4130829006421326 , steps_avg: 357.23832528180355 , reward_avg: -24.08693906275903 , distance traveled: 56.278108654338915 , average speed: 0.16849733130041591 , explore ratio: 0.2051863676780635\n",
      "Episode 621 , steps =  462 , total reward: 35.15460743620755 , steps_avg: 357.40675241157555 , reward_avg: -23.991695418870016 , distance traveled: 124.39867962880987 , average speed: 0.2692612113177703 , explore ratio: 0.2047806453914902\n",
      "Episode 622 , steps =  493 , total reward: -4.775142399588635 , steps_avg: 357.6243980738363 , reward_avg: -23.960850229432967 , distance traveled: 71.14737271861173 , average speed: 0.14431515764424288 , explore ratio: 0.20437572535399265\n",
      "Episode 623 , steps =  79 , total reward: -24.841962778930245 , steps_avg: 357.17788461538464 , reward_avg: -23.96226226877511 , distance traveled: -4.548891977034507 , average speed: -0.05758091110170262 , explore ratio: 0.20397160597925523\n",
      "Episode 624 , steps =  133 , total reward: 4.464004361101107 , steps_avg: 356.8192 , reward_avg: -23.91678024216731 , distance traveled: 30.35563974877818 , average speed: 0.22823789284795626 , explore ratio: 0.2035682856840991\n",
      "Episode 625 , steps =  64 , total reward: -17.532376742693913 , steps_avg: 356.3514376996805 , reward_avg: -23.906581514532366 , distance traveled: -6.056527199149132 , average speed: -0.09463323748670519 , explore ratio: 0.20316576288847582\n",
      "Episode 626 , steps =  201 , total reward: -12.736221639831783 , steps_avg: 356.103668261563 , reward_avg: -23.88876594854401 , distance traveled: 18.622863622941072 , average speed: 0.09265106280070184 , explore ratio: 0.20276403601546128\n",
      "Episode 627 , steps =  346 , total reward: -17.40964427956791 , steps_avg: 356.0875796178344 , reward_avg: -23.878448875822706 , distance traveled: 34.87589707670732 , average speed: 0.10079739039510785 , explore ratio: 0.20236310349124945\n",
      "Episode 628 , steps =  688 , total reward: 7.288433952396066 , steps_avg: 356.61526232114466 , reward_avg: -23.828898982614092 , distance traveled: 122.08383845645018 , average speed: 0.1774474396169334 , explore ratio: 0.20196296374514625\n",
      "Episode 629 , steps =  204 , total reward: -13.022198656617675 , steps_avg: 356.37301587301585 , reward_avg: -23.811745490033147 , distance traveled: 19.423580226176423 , average speed: 0.09521362855968835 , explore ratio: 0.20156361520956337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 630 , steps =  50 , total reward: -24.872659747954454 , steps_avg: 355.8874801901743 , reward_avg: -23.813426812153466 , distance traveled: -6.258206955492496 , average speed: -0.12516413910984991 , explore ratio: 0.2011650563200122\n",
      "Episode 631 , steps =  126 , total reward: -5.9054826122907365 , steps_avg: 355.5237341772152 , reward_avg: -23.78509145740685 , distance traveled: 18.313671027347446 , average speed: 0.14534659545513845 , explore ratio: 0.20076728551509762\n",
      "Episode 632 , steps =  281 , total reward: -9.998072921911271 , steps_avg: 355.40600315955766 , reward_avg: -23.763311017382367 , distance traveled: 47.50457311794163 , average speed: 0.16905542034854673 , explore ratio: 0.2003703012365119\n",
      "Episode 633 , steps =  121 , total reward: -4.4760005478294085 , steps_avg: 355.0362776025237 , reward_avg: -23.73288939203607 , distance traveled: 16.237170530632138 , average speed: 0.13419149198869534 , explore ratio: 0.19997410192902862\n",
      "Episode 634 , steps =  71 , total reward: -20.173544881512733 , steps_avg: 354.58897637795275 , reward_avg: -23.727284125090364 , distance traveled: -7.308655604347586 , average speed: -0.10293881132883924 , explore ratio: 0.19957868604049656\n",
      "Episode 635 , steps =  241 , total reward: 1.4928208223469372 , steps_avg: 354.41037735849056 , reward_avg: -23.687629872028353 , distance traveled: 45.30359650030733 , average speed: 0.18798172821704287 , explore ratio: 0.19918405202183362\n",
      "Episode 636 , steps =  140 , total reward: -1.905448188595484 , steps_avg: 354.07378335949767 , reward_avg: -23.653434924330657 , distance traveled: 24.237459588674827 , average speed: 0.17312471134767735 , explore ratio: 0.19879019832702077\n",
      "Episode 637 , steps =  348 , total reward: -6.279700683337353 , steps_avg: 354.064263322884 , reward_avg: -23.626203365959196 , distance traveled: 52.537837054207905 , average speed: 0.15097079613278133 , explore ratio: 0.19839712341309595\n",
      "Episode 638 , steps =  225 , total reward: -3.8040749578737003 , steps_avg: 353.8622848200313 , reward_avg: -23.595182820719625 , distance traveled: 32.95538646474482 , average speed: 0.14646838428775474 , explore ratio: 0.1980048257401481\n",
      "Episode 639 , steps =  206 , total reward: -6.4463860247731395 , steps_avg: 353.63125 , reward_avg: -23.56838782572596 , distance traveled: 29.09539724741132 , average speed: 0.14123979246316173 , explore ratio: 0.19761330377131103\n",
      "Episode 640 , steps =  242 , total reward: 16.536904195755707 , steps_avg: 353.4570982839314 , reward_avg: -23.50582106750212 , distance traveled: 69.29633573725819 , average speed: 0.28634849478205865 , explore ratio: 0.19722255597275748\n",
      "Episode 641 , steps =  64 , total reward: -0.467958400701485 , steps_avg: 353.00623052959503 , reward_avg: -23.46993654621427 , distance traveled: 10.972533995267005 , average speed: 0.17144584367604696 , explore ratio: 0.1968325808136931\n",
      "Episode 642 , steps =  73 , total reward: -0.08330655274664658 , steps_avg: 352.5707620528771 , reward_avg: -23.433565426473265 , distance traveled: 15.747554588913918 , average speed: 0.21571992587553313 , explore ratio: 0.19644337676635035\n",
      "Episode 643 , steps =  62 , total reward: -16.594019886475053 , steps_avg: 352.1195652173913 , reward_avg: -23.422945014144073 , distance traveled: -5.761198718100785 , average speed: -0.0929225599693675 , explore ratio: 0.19605494230598272\n",
      "Episode 644 , steps =  135 , total reward: 8.522505330874889 , steps_avg: 351.7829457364341 , reward_avg: -23.373417184151794 , distance traveled: 38.8718839904666 , average speed: 0.2879398814108637 , explore ratio: 0.19566727591085853\n",
      "Episode 645 , steps =  297 , total reward: 10.888978875764316 , steps_avg: 351.6981424148607 , reward_avg: -23.320379419353163 , distance traveled: 68.17556235507134 , average speed: 0.22954734799687318 , explore ratio: 0.19528037606225512\n",
      "Episode 646 , steps =  64 , total reward: -1.5463061640026696 , steps_avg: 351.2534775888717 , reward_avg: -23.286725519422173 , distance traveled: 12.55403090894222 , average speed: 0.1961567329522222 , explore ratio: 0.19489424124445287\n",
      "Episode 647 , steps =  60 , total reward: -0.6595611357657896 , steps_avg: 350.804012345679 , reward_avg: -23.251807055867147 , distance traveled: 9.809776428043842 , average speed: 0.1634962738007307 , explore ratio: 0.19450886994472924\n",
      "Episode 648 , steps =  46 , total reward: -2.857967071379227 , steps_avg: 350.3343605546995 , reward_avg: -23.22038357361062 , distance traveled: 4.639551393985748 , average speed: 0.10085981291273365 , explore ratio: 0.1941242606533528\n",
      "Episode 649 , steps =  86 , total reward: -7.410712130499392 , steps_avg: 349.9276923076923 , reward_avg: -23.196061002159677 , distance traveled: 9.945213711624964 , average speed: 0.11564201990261586 , explore ratio: 0.19374041186357743\n",
      "Episode 650 , steps =  58 , total reward: -24.48354495571678 , steps_avg: 349.47926267281105 , reward_avg: -23.198038704085263 , distance traveled: -6.571982832401991 , average speed: -0.11331004883451709 , explore ratio: 0.1933573220716363\n",
      "Episode 651 , steps =  134 , total reward: -1.0405812903543388 , steps_avg: 349.14877300613495 , reward_avg: -23.164054873696106 , distance traveled: 23.082262790529054 , average speed: 0.17225569246663472 , explore ratio: 0.19297498977673608\n",
      "Episode 652 , steps =  81 , total reward: -11.157881509343172 , steps_avg: 348.73813169984686 , reward_avg: -23.14566869702788 , distance traveled: 0.10649240193888579 , average speed: 0.0013147210115911825 , explore ratio: 0.19259341348105097\n",
      "Episode 653 , steps =  81 , total reward: -25.650082625676568 , steps_avg: 348.32874617737 , reward_avg: -23.149498076123674 , distance traveled: -12.366518096476787 , average speed: -0.1526730629194665 , explore ratio: 0.1922125916897169\n",
      "Episode 654 , steps =  294 , total reward: -2.805057619470505 , steps_avg: 348.24580152671757 , reward_avg: -23.118437861686033 , distance traveled: 44.09399095267988 , average speed: 0.14997956106353702 , explore ratio: 0.19183252291082567\n",
      "Episode 655 , steps =  215 , total reward: -0.09386029247195554 , steps_avg: 348.0426829268293 , reward_avg: -23.08333942026955 , distance traveled: 36.05187224775552 , average speed: 0.1676831267337466 , explore ratio: 0.191453205655419\n",
      "Episode 656 , steps =  113 , total reward: 0.546369432880842 , steps_avg: 347.6849315068493 , reward_avg: -23.047373348955773 , distance traveled: 22.9247973501496 , average speed: 0.2028743128331823 , explore ratio: 0.19107463843748287\n",
      "Episode 657 , steps =  190 , total reward: -3.493180474011858 , steps_avg: 347.4452887537994 , reward_avg: -23.017655730604794 , distance traveled: 30.322758134286858 , average speed: 0.15959346386466766 , explore ratio: 0.19069681977394157\n",
      "Episode 658 , steps =  85 , total reward: -10.448103350050134 , steps_avg: 347.0470409711684 , reward_avg: -22.998582054761766 , distance traveled: 2.0614508736133574 , average speed: 0.024252363218980676 , explore ratio: 0.19031974818465192\n",
      "Episode 659 , steps =  90 , total reward: -16.376346266844003 , steps_avg: 346.6575757575758 , reward_avg: -22.988548364174015 , distance traveled: -8.325009458586576 , average speed: -0.0925001050954064 , explore ratio: 0.18994342219239746\n",
      "Episode 660 , steps =  160 , total reward: 2.2156996910801734 , steps_avg: 346.375189107413 , reward_avg: -22.950417883001162 , distance traveled: 33.713291673213234 , average speed: 0.2107080729575827 , explore ratio: 0.18956784032288276\n",
      "Episode 661 , steps =  66 , total reward: -18.987451757333556 , steps_avg: 345.95166163141994 , reward_avg: -22.944431529337013 , distance traveled: -8.29255789205432 , average speed: -0.12564481654627757 , explore ratio: 0.1891930011047275\n",
      "Episode 662 , steps =  73 , total reward: -31.02626537594076 , steps_avg: 345.53996983408746 , reward_avg: -22.95662132397744 , distance traveled: -9.047788925170899 , average speed: -0.12394231404343697 , explore ratio: 0.1888189030694608\n",
      "Episode 663 , steps =  157 , total reward: -5.216485872218399 , steps_avg: 345.25602409638554 , reward_avg: -22.92990425251395 , distance traveled: 24.424414249635298 , average speed: 0.15556951751360062 , explore ratio: 0.18844554475151543\n",
      "Episode 664 , steps =  217 , total reward: -10.797048393102378 , steps_avg: 345.06315789473683 , reward_avg: -22.91165935648476 , distance traveled: 23.50588365020464 , average speed: 0.10832204447098913 , explore ratio: 0.18807292468822207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 665 , steps =  280 , total reward: 31.26700292049289 , steps_avg: 344.96546546546546 , reward_avg: -22.830310013726535 , distance traveled: 91.95529461354015 , average speed: 0.3284117664769291 , explore ratio: 0.1877010414198036\n",
      "Episode 666 , steps =  155 , total reward: 0.6274096553058561 , steps_avg: 344.6806596701649 , reward_avg: -22.79514101872049 , distance traveled: 31.535215716809034 , average speed: 0.2034530046245744 , explore ratio: 0.18732989348936935\n",
      "Episode 667 , steps =  149 , total reward: 6.862140154352403 , steps_avg: 344.3877245508982 , reward_avg: -22.75074389121589 , distance traveled: 38.06777511499822 , average speed: 0.2554884235905921 , explore ratio: 0.18695947944290944\n",
      "Episode 668 , steps =  198 , total reward: -25.64400194189254 , steps_avg: 344.16890881913304 , reward_avg: -22.75506864166533 , distance traveled: 0.7342833390086891 , average speed: 0.0037085017121650968 , explore ratio: 0.18658979782928906\n",
      "Episode 669 , steps =  100 , total reward: -6.494060156273969 , steps_avg: 343.8044776119403 , reward_avg: -22.730798479746834 , distance traveled: 10.4481214132905 , average speed: 0.104481214132905 , explore ratio: 0.18622084720024273\n",
      "Episode 670 , steps =  98 , total reward: -3.403372137187058 , steps_avg: 343.4381520119225 , reward_avg: -22.701994565674465 , distance traveled: 15.60486738748849 , average speed: 0.15923334068865805 , explore ratio: 0.18585262611036876\n",
      "Episode 671 , steps =  255 , total reward: -13.268097087318687 , steps_avg: 343.3065476190476 , reward_avg: -22.687956027760247 , distance traveled: 27.316150508522984 , average speed: 0.10712215885695288 , explore ratio: 0.18548513311712342\n",
      "Episode 672 , steps =  174 , total reward: 6.8465617768323535 , steps_avg: 343.0549777117385 , reward_avg: -22.644071157322514 , distance traveled: 45.83365393074227 , average speed: 0.26341180419966825 , explore ratio: 0.1851183667808154\n",
      "Episode 673 , steps =  91 , total reward: -3.1073250689587324 , steps_avg: 342.68100890207717 , reward_avg: -22.61508488716174 , distance traveled: 16.709254544377323 , average speed: 0.1836181818063442 , explore ratio: 0.18475232566460015\n",
      "Episode 674 , steps =  834 , total reward: 63.298299164776424 , steps_avg: 343.4088888888889 , reward_avg: -22.487805799677385 , distance traveled: 225.5382823010813 , average speed: 0.27042959508522935 , explore ratio: 0.18438700833447427\n",
      "Episode 675 , steps =  168 , total reward: -0.33365372148716144 , steps_avg: 343.14940828402365 , reward_avg: -22.455033385360537 , distance traveled: 30.352895583109927 , average speed: 0.18067199751851146 , explore ratio: 0.18402241335926983\n",
      "Episode 676 , steps =  101 , total reward: -7.843638980565284 , steps_avg: 342.7917282127031 , reward_avg: -22.43345082346276 , distance traveled: 9.10035760112107 , average speed: 0.09010255050614921 , explore ratio: 0.1836585393106488\n",
      "Episode 677 , steps =  213 , total reward: 10.18779066823359 , steps_avg: 342.60029498525074 , reward_avg: -22.38533689795878 , distance traveled: 50.63008126527074 , average speed: 0.23769991204352459 , explore ratio: 0.18329538476309745\n",
      "Episode 678 , steps =  71 , total reward: -5.601706120121602 , steps_avg: 342.20029455081004 , reward_avg: -22.360618737755786 , distance traveled: 6.69421073678881 , average speed: 0.09428465826463113 , explore ratio: 0.18293294829392082\n",
      "Episode 679 , steps =  385 , total reward: 16.801767646511994 , steps_avg: 342.26323529411764 , reward_avg: -22.303026993073036 , distance traveled: 88.09322010844949 , average speed: 0.2288135587232454 , explore ratio: 0.182571228483237\n",
      "Episode 680 , steps =  334 , total reward: 24.175067442774797 , steps_avg: 342.2511013215859 , reward_avg: -22.234777221507915 , distance traveled: 89.33378234094013 , average speed: 0.2674664141944315 , explore ratio: 0.1822102239139718\n",
      "Episode 681 , steps =  59 , total reward: -5.814491729235278 , steps_avg: 341.8357771260997 , reward_avg: -22.210700556563232 , distance traveled: 6.668256076276302 , average speed: 0.1130212894284119 , explore ratio: 0.18184993317185288\n",
      "Episode 682 , steps =  232 , total reward: 0.27902605606923747 , steps_avg: 341.67496339677894 , reward_avg: -22.177772699150886 , distance traveled: 40.98010071802767 , average speed: 0.17663836516391238 , explore ratio: 0.18149035484540457\n",
      "Episode 683 , steps =  62 , total reward: -15.600286165540425 , steps_avg: 341.266081871345 , reward_avg: -22.168156490768414 , distance traveled: -2.9815969425792934 , average speed: -0.04809027326740796 , explore ratio: 0.18113148752594205\n",
      "Episode 684 , steps =  75 , total reward: 2.712069408235447 , steps_avg: 340.87737226277375 , reward_avg: -22.131834993105638 , distance traveled: 15.829473693966865 , average speed: 0.21105964925289153 , explore ratio: 0.18077332980756597\n",
      "Episode 685 , steps =  207 , total reward: 7.066856139548103 , steps_avg: 340.6822157434402 , reward_avg: -22.08927130340789 , distance traveled: 50.38197454690932 , average speed: 0.24339118138603535 , explore ratio: 0.18041588028715694\n",
      "Episode 686 , steps =  121 , total reward: -8.471869788022097 , steps_avg: 340.3624454148472 , reward_avg: -22.06944975826177 , distance traveled: 14.175107371956114 , average speed: 0.11714964770211665 , explore ratio: 0.18005913756436998\n",
      "Episode 687 , steps =  60 , total reward: -4.221115108141677 , steps_avg: 339.9549418604651 , reward_avg: -22.043507411386596 , distance traveled: 8.822854344248771 , average speed: 0.14704757240414618 , explore ratio: 0.17970310024162905\n",
      "Episode 688 , steps =  168 , total reward: -10.491039186269681 , steps_avg: 339.70537010159654 , reward_avg: -22.026740403802968 , distance traveled: 18.43729099452495 , average speed: 0.10974577972931518 , explore ratio: 0.17934776692412163\n",
      "Episode 689 , steps =  239 , total reward: 1.479050195895116 , steps_avg: 339.5594202898551 , reward_avg: -21.992674040615 , distance traveled: 46.07498671301177 , average speed: 0.19278237118414965 , explore ratio: 0.17899313621979318\n",
      "Episode 690 , steps =  284 , total reward: 17.83368674978745 , steps_avg: 339.47901591895805 , reward_avg: -21.935038207343798 , distance traveled: 72.36829036027196 , average speed: 0.2548179238037745 , explore ratio: 0.17863920673934172\n",
      "Episode 691 , steps =  38 , total reward: -10.908111973511053 , steps_avg: 339.0433526011561 , reward_avg: -21.919103342844036 , distance traveled: 2.760956183290109 , average speed: 0.07265674166552918 , explore ratio: 0.17828597709621238\n",
      "Episode 692 , steps =  295 , total reward: 8.076788414427986 , steps_avg: 338.979797979798 , reward_avg: -21.87581922775418 , distance traveled: 61.95068629547955 , average speed: 0.2100023264253544 , explore ratio: 0.17793344590659202\n",
      "Episode 693 , steps =  65 , total reward: -6.762566050179311 , steps_avg: 338.5850144092219 , reward_avg: -21.854042205884475 , distance traveled: 3.562010115925223 , average speed: 0.05480015562961882 , explore ratio: 0.1775816117894037\n",
      "Episode 694 , steps =  234 , total reward: -2.949993154141451 , steps_avg: 338.43453237410074 , reward_avg: -21.826842135306425 , distance traveled: 35.182050101626665 , average speed: 0.150350641459943 , explore ratio: 0.17723047336630138\n",
      "Episode 695 , steps =  166 , total reward: 1.0804000981077402 , steps_avg: 338.1867816091954 , reward_avg: -21.793929430948072 , distance traveled: 31.04443861481732 , average speed: 0.18701469045070676 , explore ratio: 0.17688002926166443\n",
      "Episode 696 , steps =  398 , total reward: -3.9493505348085503 , steps_avg: 338.2725968436155 , reward_avg: -21.76832745261789 , distance traveled: 63.26512439209967 , average speed: 0.1589575989751248 , explore ratio: 0.17653027810259234\n",
      "Episode 697 , steps =  191 , total reward: 1.0219088484116963 , steps_avg: 338.06160458452723 , reward_avg: -21.735676684278303 , distance traveled: 39.961175470724704 , average speed: 0.20922081398285186 , explore ratio: 0.17618121851889923\n",
      "Episode 698 , steps =  102 , total reward: -30.010864308395114 , steps_avg: 337.7238912732475 , reward_avg: -21.747515293182623 , distance traveled: -7.347326456420124 , average speed: -0.07203261231784434 , explore ratio: 0.17583284914310857\n",
      "Episode 699 , steps =  228 , total reward: -0.03533489859726424 , steps_avg: 337.56714285714287 , reward_avg: -21.716497892618925 , distance traveled: 41.18630719229577 , average speed: 0.18064169821182355 , explore ratio: 0.17548516861044777\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 700 , steps =  61 , total reward: -7.144361775180325 , steps_avg: 337.17261055634805 , reward_avg: -21.695710251937843 , distance traveled: 5.675005856556818 , average speed: 0.09303288289437407 , explore ratio: 0.1751381755588429\n",
      "Episode 701 , steps =  229 , total reward: -3.579181794774426 , steps_avg: 337.01851851851853 , reward_avg: -21.669903231343593 , distance traveled: 36.52098340151366 , average speed: 0.15948027686250507 , explore ratio: 0.17479186862891322\n",
      "Episode 702 , steps =  47 , total reward: -6.015615634616464 , steps_avg: 336.6059743954481 , reward_avg: -21.64763539692435 , distance traveled: -0.27644256502389913 , average speed: -0.005881756702636152 , explore ratio: 0.17444624646396603\n",
      "Episode 703 , steps =  71 , total reward: -21.246001092916977 , steps_avg: 336.2286931818182 , reward_avg: -21.647064893651613 , distance traveled: -9.831298425793648 , average speed: -0.13846899191258658 , explore ratio: 0.17410130770999122\n",
      "Episode 704 , steps =  300 , total reward: 12.893016987483298 , steps_avg: 336.177304964539 , reward_avg: -21.598071869706743 , distance traveled: 69.81506860138849 , average speed: 0.23271689533796164 , explore ratio: 0.173757051015656\n",
      "Episode 705 , steps =  44 , total reward: -11.398352683116988 , steps_avg: 335.7634560906516 , reward_avg: -21.58362467539146 , distance traveled: 1.1401427706889806 , average speed: 0.02591233569747683 , explore ratio: 0.17341347503229967\n",
      "Episode 706 , steps =  85 , total reward: -25.44237348855473 , steps_avg: 335.4087694483734 , reward_avg: -21.58908259450484 , distance traveled: -8.419901379514487 , average speed: -0.09905766328840573 , explore ratio: 0.17307057841392823\n",
      "Episode 707 , steps =  224 , total reward: -0.627642025704199 , steps_avg: 335.25141242937855 , reward_avg: -21.559476040029136 , distance traveled: 39.49374303212157 , average speed: 0.1763113528219713 , explore ratio: 0.1727283598172092\n",
      "Episode 708 , steps =  92 , total reward: -16.870677291660265 , steps_avg: 334.9083215796897 , reward_avg: -21.552862783684468 , distance traveled: -3.2015295461984348 , average speed: -0.03479923419780907 , explore ratio: 0.1723868179014663\n",
      "Episode 709 , steps =  108 , total reward: -18.557343695428212 , steps_avg: 334.5887323943662 , reward_avg: -21.548643742715097 , distance traveled: -6.171962478104979 , average speed: -0.05714780072319425 , explore ratio: 0.1720459513286742\n",
      "Episode 710 , steps =  124 , total reward: 0.18253766089179735 , steps_avg: 334.29254571026723 , reward_avg: -21.518079493202286 , distance traveled: 28.1833721256908 , average speed: 0.2272852590781516 , explore ratio: 0.17170575876345334\n",
      "Episode 711 , steps =  83 , total reward: -5.318666167663415 , steps_avg: 333.939606741573 , reward_avg: -21.495327508194507 , distance traveled: 10.760018661268987 , average speed: 0.1296387790514336 , explore ratio: 0.17136623887306465\n",
      "Episode 712 , steps =  67 , total reward: -18.70645823989623 , steps_avg: 333.5652173913044 , reward_avg: -21.49141605059521 , distance traveled: -4.615854992195964 , average speed: -0.06889335809247708 , explore ratio: 0.17102739032740427\n",
      "Episode 713 , steps =  68 , total reward: -5.958824413462854 , steps_avg: 333.1932773109244 , reward_avg: -21.469661720571214 , distance traveled: 2.5471028695441778 , average speed: 0.03745739514035556 , explore ratio: 0.17068921179899846\n",
      "Episode 714 , steps =  54 , total reward: -9.770441950142377 , steps_avg: 332.8027972027972 , reward_avg: -21.45329917543775 , distance traveled: 2.519772093594074 , average speed: 0.046662446177668036 , explore ratio: 0.17035170196299834\n",
      "Episode 715 , steps =  60 , total reward: -3.97136850294657 , steps_avg: 332.4217877094972 , reward_avg: -21.428883071146558 , distance traveled: 7.460124094784259 , average speed: 0.12433540157973764 , explore ratio: 0.17001485949717468\n",
      "Episode 716 , steps =  293 , total reward: 7.961723191340125 , steps_avg: 332.3668061366806 , reward_avg: -21.38789198849316 , distance traveled: 58.5254738449305 , average speed: 0.1997456445219471 , explore ratio: 0.16967868308191272\n",
      "Episode 717 , steps =  94 , total reward: -20.048945386256413 , steps_avg: 332.03481894150417 , reward_avg: -21.386027160356342 , distance traveled: -8.328724131435155 , average speed: -0.08860344820675697 , explore ratio: 0.16934317140020708\n",
      "Episode 718 , steps =  210 , total reward: 29.440441011851615 , steps_avg: 331.86509040333794 , reward_avg: -21.315336662203062 , distance traveled: 80.07150320118295 , average speed: 0.3812928723865855 , explore ratio: 0.16900832313765649\n",
      "Episode 719 , steps =  172 , total reward: -5.859500371068108 , steps_avg: 331.6430555555556 , reward_avg: -21.29387022290982 , distance traveled: 26.087258673417377 , average speed: 0.1516701085663801 , explore ratio: 0.1686741369824587\n",
      "Episode 720 , steps =  285 , total reward: 8.54647020271046 , steps_avg: 331.5783633841886 , reward_avg: -21.252482788200222 , distance traveled: 59.20404850747439 , average speed: 0.20773350353499787 , explore ratio: 0.16834061162540537\n",
      "Episode 721 , steps =  45 , total reward: -21.050129271298637 , steps_avg: 331.1814404432133 , reward_avg: -21.25220252017127 , distance traveled: -4.296082627661526 , average speed: -0.09546850283692279 , explore ratio: 0.16800774575987687\n",
      "Episode 722 , steps =  67 , total reward: -20.54029773017951 , steps_avg: 330.81604426002764 , reward_avg: -21.251217866243206 , distance traveled: -3.1668205107003446 , average speed: -0.047265977771646935 , explore ratio: 0.1676755380818372\n",
      "Episode 723 , steps =  102 , total reward: -10.048649872326608 , steps_avg: 330.5 , reward_avg: -21.235744706030612 , distance traveled: 8.844554811269045 , average speed: 0.08671132167910829 , explore ratio: 0.16734398728982888\n",
      "Episode 724 , steps =  153 , total reward: -9.34469670502222 , steps_avg: 330.2551724137931 , reward_avg: -21.21934326051198 , distance traveled: 15.957014352120455 , average speed: 0.10429421145176768 , explore ratio: 0.16701309208496784\n",
      "Episode 725 , steps =  274 , total reward: 8.572057884141163 , steps_avg: 330.1776859504132 , reward_avg: -21.178308272709426 , distance traveled: 61.33295994115991 , average speed: 0.22384291949328436 , explore ratio: 0.16668285117093837\n",
      "Episode 726 , steps =  80 , total reward: -27.967548772233226 , steps_avg: 329.83356258596973 , reward_avg: -21.187646980411664 , distance traveled: -13.262114329487089 , average speed: -0.16577642911858861 , explore ratio: 0.16635326325398797\n",
      "Episode 727 , steps =  68 , total reward: -8.94351260625199 , steps_avg: 329.4739010989011 , reward_avg: -21.17082811451309 , distance traveled: 4.593234445117413 , average speed: 0.06754756536937372 , explore ratio: 0.16602432704292236\n",
      "Episode 728 , steps =  249 , total reward: -17.969327221337537 , steps_avg: 329.36351165980795 , reward_avg: -21.16643648091477 , distance traveled: 27.43453294630161 , average speed: 0.11017884717390204 , explore ratio: 0.16569604124910034\n",
      "Episode 729 , steps =  381 , total reward: -33.416484435413004 , steps_avg: 329.43424657534246 , reward_avg: -21.18321736852367 , distance traveled: 20.33884039040654 , average speed: 0.05338278317692005 , explore ratio: 0.16536840458642885\n",
      "Episode 730 , steps =  43 , total reward: -22.816952829498184 , steps_avg: 329.0424076607387 , reward_avg: -21.18545230075483 , distance traveled: -3.4575724677275863 , average speed: -0.08040866204017642 , explore ratio: 0.16504141577135778\n",
      "Episode 731 , steps =  68 , total reward: -20.758689602132893 , steps_avg: 328.6857923497268 , reward_avg: -21.184869291603704 , distance traveled: -11.170972902774814 , average speed: -0.1642790132761002 , explore ratio: 0.16471507352287512\n",
      "Episode 732 , steps =  82 , total reward: 0.014968103791899223 , steps_avg: 328.3492496589359 , reward_avg: -21.15594727605746 , distance traveled: 14.904458925426002 , average speed: 0.18176169421251223 , explore ratio: 0.1643893765625018\n",
      "Episode 733 , steps =  132 , total reward: -8.91715527861318 , steps_avg: 328.0817438692098 , reward_avg: -21.13927317251871 , distance traveled: 15.54912056479545 , average speed: 0.11779636791511705 , explore ratio: 0.16406432361428672\n",
      "Episode 734 , steps =  547 , total reward: -13.56988999415398 , steps_avg: 328.3795918367347 , reward_avg: -21.128974692003926 , distance traveled: 71.03687098022547 , average speed: 0.1298663089218016 , explore ratio: 0.1637399134048018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 735 , steps =  317 , total reward: 14.086211569697877 , steps_avg: 328.3641304347826 , reward_avg: -21.08112797153966 , distance traveled: 78.07551862615165 , average speed: 0.24629501143896418 , explore ratio: 0.16341614466313692\n",
      "Episode 736 , steps =  241 , total reward: -1.7106227970291137 , steps_avg: 328.24559023066485 , reward_avg: -21.054845060855115 , distance traveled: 39.22329572781458 , average speed: 0.1627522644307659 , explore ratio: 0.16309301612089502\n",
      "Episode 737 , steps =  262 , total reward: 8.738288551836568 , steps_avg: 328.1558265582656 , reward_avg: -21.01447496110892 , distance traveled: 59.507268683407446 , average speed: 0.22712697970766202 , explore ratio: 0.16277052651218707\n",
      "Episode 738 , steps =  67 , total reward: -4.1932075100696355 , steps_avg: 327.8024357239513 , reward_avg: -20.991712758874765 , distance traveled: 9.47892012476921 , average speed: 0.14147641977267478 , explore ratio: 0.1624486745736271\n",
      "Episode 739 , steps =  89 , total reward: -27.311098257876303 , steps_avg: 327.47972972972974 , reward_avg: -21.000252469008554 , distance traveled: -3.624801987810061 , average speed: -0.040728112222584954 , explore ratio: 0.1621274590443273\n",
      "Episode 740 , steps =  213 , total reward: 1.791055392855144 , steps_avg: 327.3252361673414 , reward_avg: -20.969494968520205 , distance traveled: 38.44463669780644 , average speed: 0.18049125210237765 , explore ratio: 0.16180687866589305\n",
      "Episode 741 , steps =  173 , total reward: 10.158752394516629 , steps_avg: 327.11725067385447 , reward_avg: -20.927543152667056 , distance traveled: 46.00344065565615 , average speed: 0.26591584194020895 , explore ratio: 0.161486932182418\n",
      "Episode 742 , steps =  79 , total reward: 0.2614175201747476 , steps_avg: 326.78331090174964 , reward_avg: -20.89902503601451 , distance traveled: 16.706705554425714 , average speed: 0.21147728549905967 , explore ratio: 0.16116761834047916\n",
      "Episode 743 , steps =  60 , total reward: -6.980169324570642 , steps_avg: 326.4247311827957 , reward_avg: -20.88031689661741 , distance traveled: 1.3572200945019726 , average speed: 0.02262033490836621 , explore ratio: 0.16084893588913196\n",
      "Episode 744 , steps =  408 , total reward: 21.198007771514977 , steps_avg: 326.53422818791944 , reward_avg: -20.823835923908508 , distance traveled: 95.62969477144067 , average speed: 0.23438650679274672 , explore ratio: 0.1605308835799054\n",
      "Episode 745 , steps =  54 , total reward: -14.139438983169697 , steps_avg: 326.16890080428954 , reward_avg: -20.814875606293576 , distance traveled: 0.27267637073993684 , average speed: 0.005049562421109942 , explore ratio: 0.16021346016679705\n",
      "Episode 746 , steps =  49 , total reward: -0.3803416408927483 , steps_avg: 325.7978580990629 , reward_avg: -20.78752013913775 , distance traveled: 8.210216682851316 , average speed: 0.16755544250716972 , explore ratio: 0.15989666440626835\n",
      "Episode 747 , steps =  215 , total reward: 9.505405982928332 , steps_avg: 325.64973262032083 , reward_avg: -20.747021574803437 , distance traveled: 51.52393157785758 , average speed: 0.2396461933853841 , explore ratio: 0.15958049505723956\n",
      "Episode 748 , steps =  297 , total reward: 22.65416360819153 , steps_avg: 325.61148197596793 , reward_avg: -20.689076067215993 , distance traveled: 83.22321349248286 , average speed: 0.28021284004202984 , explore ratio: 0.159264950881085\n",
      "Episode 749 , steps =  439 , total reward: -9.305437741815165 , steps_avg: 325.7626666666667 , reward_avg: -20.673897882782125 , distance traveled: 58.05175465982873 , average speed: 0.13223634318867591 , explore ratio: 0.15895003064162813\n",
      "Episode 750 , steps =  147 , total reward: -23.49124888232849 , steps_avg: 325.52463382157123 , reward_avg: -20.677649348826794 , distance traveled: 1.2746025506872698 , average speed: 0.008670765650933809 , explore ratio: 0.15863573310513682\n",
      "Episode 751 , steps =  86 , total reward: -28.12516303646192 , steps_avg: 325.2061170212766 , reward_avg: -20.687552957453967 , distance traveled: -7.6880755241587755 , average speed: -0.08939622702510204 , explore ratio: 0.15832205704031835\n",
      "Episode 752 , steps =  218 , total reward: 21.407253660304477 , steps_avg: 325.0637450199203 , reward_avg: -20.631650159820822 , distance traveled: 70.55045847505333 , average speed: 0.3236259563075841 , explore ratio: 0.15800900121831477\n",
      "Episode 753 , steps =  61 , total reward: -8.018830182410783 , steps_avg: 324.7135278514589 , reward_avg: -20.6149222818667 , distance traveled: -0.7832460307376461 , average speed: -0.012840098864551576 , explore ratio: 0.15769656441269791\n",
      "Episode 754 , steps =  153 , total reward: 14.702846825140828 , steps_avg: 324.4860927152318 , reward_avg: -20.56814377973821 , distance traveled: 46.25703028097748 , average speed: 0.3023335312482188 , explore ratio: 0.15738474539946473\n",
      "Episode 755 , steps =  485 , total reward: -17.006947062871824 , steps_avg: 324.6984126984127 , reward_avg: -20.5634332020704 , distance traveled: 56.178590974621436 , average speed: 0.11583214633942564 , explore ratio: 0.1570735429570324\n",
      "Episode 756 , steps =  46 , total reward: -27.70026783296342 , steps_avg: 324.330250990753 , reward_avg: -20.57286098890117 , distance traveled: -5.491299212984741 , average speed: -0.11937606984749437 , explore ratio: 0.15676295586623362\n",
      "Episode 757 , steps =  123 , total reward: -1.5677096086902105 , steps_avg: 324.0646437994723 , reward_avg: -20.547788229824373 , distance traveled: 20.218654513210055 , average speed: 0.1643793049854476 , explore ratio: 0.15645298291031176\n",
      "Episode 758 , steps =  69 , total reward: -1.1283615260031084 , steps_avg: 323.7285902503294 , reward_avg: -20.522202687395094 , distance traveled: 12.87349016368389 , average speed: 0.18657232121281 , explore ratio: 0.15614362287491612\n",
      "Episode 759 , steps =  251 , total reward: 17.75361485390802 , steps_avg: 323.6328947368421 , reward_avg: -20.471839769577592 , distance traveled: 73.53705566927792 , average speed: 0.29297631740748176 , explore ratio: 0.15583487454809722\n",
      "Episode 760 , steps =  83 , total reward: -28.021987261449915 , steps_avg: 323.31668856767413 , reward_avg: -20.48176111976402 , distance traveled: -4.862523254667799 , average speed: -0.058584617526118064 , explore ratio: 0.15552673672030196\n",
      "Episode 761 , steps =  69 , total reward: -0.15569827781555667 , steps_avg: 322.98293963254594 , reward_avg: -20.45508649661186 , distance traveled: 11.040857160687445 , average speed: 0.1600124226186586 , explore ratio: 0.15521920818436896\n",
      "Episode 762 , steps =  129 , total reward: -5.466553273951022 , steps_avg: 322.7287024901704 , reward_avg: -20.43544228531086 , distance traveled: 17.801815704256295 , average speed: 0.137998571350824 , explore ratio: 0.1549122877355238\n",
      "Episode 763 , steps =  52 , total reward: -6.112168205550559 , steps_avg: 322.3743455497382 , reward_avg: -20.416694544368767 , distance traveled: 3.0633191802911464 , average speed: 0.0589099842363682 , explore ratio: 0.15460597417137428\n",
      "Episode 764 , steps =  52 , total reward: -8.372225986473264 , steps_avg: 322.02091503267974 , reward_avg: -20.400950141025113 , distance traveled: 1.7469325455464424 , average speed: 0.03359485664512389 , explore ratio: 0.1543002662919058\n",
      "Episode 765 , steps =  153 , total reward: 20.157804538846023 , steps_avg: 321.80026109660577 , reward_avg: -20.348001375124497 , distance traveled: 56.42742334887386 , average speed: 0.3688066885547311 , explore ratio: 0.1539951628994765\n",
      "Episode 766 , steps =  54 , total reward: -15.992415335639693 , steps_avg: 321.4511082138201 , reward_avg: -20.342322644955676 , distance traveled: -5.651069675087931 , average speed: -0.10464943842755428 , explore ratio: 0.15369066279881274\n",
      "Episode 767 , steps =  152 , total reward: -36.65952528530044 , steps_avg: 321.23046875 , reward_avg: -20.363569002560293 , distance traveled: -27.929144256273283 , average speed: -0.18374437010706107 , explore ratio: 0.15338676479700428\n",
      "Episode 768 , steps =  226 , total reward: 1.4454478123399 , steps_avg: 321.1066319895969 , reward_avg: -20.335208772631944 , distance traveled: 43.505119772404406 , average speed: 0.19250052996639117 , explore ratio: 0.15308346770349968\n",
      "Episode 769 , steps =  77 , total reward: 1.5633949182437044 , steps_avg: 320.7896103896104 , reward_avg: -20.30676902757886 , distance traveled: 16.689969447255134 , average speed: 0.2167528499643524 , explore ratio: 0.15278077033010162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 770 , steps =  71 , total reward: -23.274599066440032 , steps_avg: 320.4656290531777 , reward_avg: -20.31061835318049 , distance traveled: -1.985718086063862 , average speed: -0.027967860367096645 , explore ratio: 0.15247867149096228\n",
      "Episode 771 , steps =  68 , total reward: -0.7327475561673485 , steps_avg: 320.13860103626945 , reward_avg: -20.28525841691493 , distance traveled: 10.72791311681271 , average speed: 0.1577634281884222 , explore ratio: 0.15217717000257863\n",
      "Episode 772 , steps =  52 , total reward: -8.922812326866525 , steps_avg: 319.7917205692109 , reward_avg: -20.270559262852775 , distance traveled: 0.570477427840233 , average speed: 0.010970719766158328 , explore ratio: 0.1518762646837878\n",
      "Episode 773 , steps =  402 , total reward: 2.8750214802759704 , steps_avg: 319.8979328165375 , reward_avg: -20.240655411763463 , distance traveled: 72.65906267987563 , average speed: 0.180743937014616 , explore ratio: 0.1515759543557625\n",
      "Episode 774 , steps =  424 , total reward: -10.681565595159086 , steps_avg: 320.03225806451616 , reward_avg: -20.22832110232268 , distance traveled: 52.99198077527807 , average speed: 0.1249810867341464 , explore ratio: 0.15127623784200636\n",
      "Episode 775 , steps =  62 , total reward: 0.014468618672342282 , steps_avg: 319.69974226804123 , reward_avg: -20.202235033094595 , distance traveled: 11.086933586597448 , average speed: 0.17882150946124917 , explore ratio: 0.1509771139683494\n",
      "Episode 776 , steps =  165 , total reward: -5.066603346945108 , steps_avg: 319.5006435006435 , reward_avg: -20.182755455634943 , distance traveled: 19.372213912457227 , average speed: 0.11740735704519531 , explore ratio: 0.15067858156294328\n",
      "Episode 777 , steps =  958 , total reward: 4.494599273210319 , steps_avg: 320.3213367609255 , reward_avg: -20.15103649068784 , distance traveled: 161.94213642144575 , average speed: 0.1690418960557889 , explore ratio: 0.15038063945625685\n",
      "Episode 778 , steps =  54 , total reward: -0.34003970002010436 , steps_avg: 319.97946084724003 , reward_avg: -20.12560517259969 , distance traveled: 8.718238484859466 , average speed: 0.16144886083073084 , explore ratio: 0.1500832864810715\n",
      "Episode 779 , steps =  224 , total reward: -0.6680636581611044 , steps_avg: 319.85641025641024 , reward_avg: -20.100659606555542 , distance traveled: 40.59973713867369 , average speed: 0.1812488265119361 , explore ratio: 0.1497865214724766\n",
      "Episode 780 , steps =  204 , total reward: 0.773976707413159 , steps_avg: 319.708066581306 , reward_avg: -20.073931519085672 , distance traveled: 38.49556922882793 , average speed: 0.1887037707295487 , explore ratio: 0.14949034326786495\n",
      "Episode 781 , steps =  98 , total reward: -12.429416261393584 , steps_avg: 319.42455242966753 , reward_avg: -20.064155924126982 , distance traveled: -0.96122959006112 , average speed: -0.009808465204705305 , explore ratio: 0.1491947507069282\n",
      "Episode 782 , steps =  67 , total reward: -6.033425042116402 , steps_avg: 319.1021711366539 , reward_avg: -20.046236727598234 , distance traveled: 3.5719142904505135 , average speed: 0.05331215358881363 , explore ratio: 0.14889974263165234\n",
      "Episode 783 , steps =  167 , total reward: -9.581645995194725 , steps_avg: 318.90816326530614 , reward_avg: -20.032889035337515 , distance traveled: 15.278729723040016 , average speed: 0.09148939953916177 , explore ratio: 0.14860531788631315\n",
      "Episode 784 , steps =  179 , total reward: -5.996968770010415 , steps_avg: 318.7299363057325 , reward_avg: -20.015008882133277 , distance traveled: 23.356870027296242 , average speed: 0.1304853074150628 , explore ratio: 0.1483114753174716\n",
      "Episode 785 , steps =  54 , total reward: -0.9911891270789013 , steps_avg: 318.39312977099235 , reward_avg: -19.990805549111577 , distance traveled: 8.831763278245926 , average speed: 0.163551171819369 , explore ratio: 0.14801821377396948\n",
      "Episode 786 , steps =  173 , total reward: -13.054195244617157 , steps_avg: 318.2083862770013 , reward_avg: -19.98199155888986 , distance traveled: 14.257712246552108 , average speed: 0.08241452165637057 , explore ratio: 0.14772553210692474\n",
      "Episode 787 , steps =  471 , total reward: -25.39820843909971 , steps_avg: 318.4022842639594 , reward_avg: -19.988864930565253 , distance traveled: 41.07661589529365 , average speed: 0.0872114987161224 , explore ratio: 0.1474334291697271\n",
      "Episode 788 , steps =  75 , total reward: 4.47673686024732 , steps_avg: 318.0937896070976 , reward_avg: -19.957856563276515 , distance traveled: 18.43036692023278 , average speed: 0.2457382256031037 , explore ratio: 0.14714190381803346\n",
      "Episode 789 , steps =  287 , total reward: -9.623394310495483 , steps_avg: 318.05443037974686 , reward_avg: -19.944774965488186 , distance traveled: 33.43090170986834 , average speed: 0.11648397808316494 , explore ratio: 0.14685095490976355\n",
      "Episode 790 , steps =  179 , total reward: -15.077630703448019 , steps_avg: 317.8786346396966 , reward_avg: -19.938621812185986 , distance traveled: 9.560922012403609 , average speed: 0.05341297213633301 , explore ratio: 0.1465605813050953\n",
      "Episode 791 , steps =  317 , total reward: -14.680408834373539 , steps_avg: 317.87752525252523 , reward_avg: -19.931982654385717 , distance traveled: 30.389087223038093 , average speed: 0.09586462846384257 , explore ratio: 0.1462707818664605\n",
      "Episode 792 , steps =  370 , total reward: 10.925818612507202 , steps_avg: 317.94325346784365 , reward_avg: -19.89306991634424 , distance traveled: 76.37370134141297 , average speed: 0.20641540903084585 , explore ratio: 0.14598155545854027\n",
      "Episode 793 , steps =  173 , total reward: -1.3909252421378007 , steps_avg: 317.76070528967256 , reward_avg: -19.86976746713239 , distance traveled: 25.32267200142144 , average speed: 0.1463738265978118 , explore ratio: 0.14569290094826065\n",
      "Episode 794 , steps =  61 , total reward: -2.5448151213657155 , steps_avg: 317.4377358490566 , reward_avg: -19.847975074244637 , distance traveled: 6.48960397258401 , average speed: 0.10638695037022966 , explore ratio: 0.14540481720478812\n",
      "Episode 795 , steps =  296 , total reward: 33.33553586093266 , steps_avg: 317.4108040201005 , reward_avg: -19.78116161829592 , distance traveled: 96.75577577445658 , average speed: 0.3268776208596506 , explore ratio: 0.14511730309952522\n",
      "Episode 796 , steps =  212 , total reward: -3.1152439162191143 , steps_avg: 317.27854454203265 , reward_avg: -19.760250805620792 , distance traveled: 31.988643141388895 , average speed: 0.15088982613862686 , explore ratio: 0.14483035750610612\n",
      "Episode 797 , steps =  66 , total reward: -4.961542015800261 , steps_avg: 316.9636591478697 , reward_avg: -19.741706057763874 , distance traveled: 5.981810815818608 , average speed: 0.09063349720937285 , explore ratio: 0.14454397930039217\n",
      "Episode 798 , steps =  136 , total reward: -6.933552681494505 , steps_avg: 316.7371714643304 , reward_avg: -19.725675828256655 , distance traveled: 16.712267270833248 , average speed: 0.12288431816789153 , explore ratio: 0.14425816736046754\n",
      "Episode 799 , steps =  82 , total reward: -28.942352643887823 , steps_avg: 316.44375 , reward_avg: -19.73719667427619 , distance traveled: -8.40164010643959 , average speed: -0.10245902568828769 , explore ratio: 0.14397292056663474\n",
      "Episode 800 , steps =  343 , total reward: -7.7035194554991175 , steps_avg: 316.4769038701623 , reward_avg: -19.722173356899443 , distance traveled: 50.02341277778149 , average speed: 0.14584085357953785 , explore ratio: 0.14368823780141038\n",
      "Episode 801 , steps =  52 , total reward: -1.2057535473344227 , steps_avg: 316.1471321695761 , reward_avg: -19.699085551650604 , distance traveled: 7.72856948554516 , average speed: 0.14862633626048385 , explore ratio: 0.14340411794952068\n",
      "Episode 802 , steps =  141 , total reward: -1.9167441112157082 , steps_avg: 315.92901618929017 , reward_avg: -19.67694066816314 , distance traveled: 21.551388690713797 , average speed: 0.15284672830293472 , explore ratio: 0.14312055989789713\n",
      "Episode 803 , steps =  435 , total reward: -20.122213180604867 , steps_avg: 316.0771144278607 , reward_avg: -19.677494489696027 , distance traveled: 41.558129051687416 , average speed: 0.09553592885445383 , explore ratio: 0.1428375625356721\n",
      "Episode 804 , steps =  66 , total reward: -16.476742403117328 , steps_avg: 315.7664596273292 , reward_avg: -19.673518400147483 , distance traveled: -5.020096972435711 , average speed: -0.07606207533993502 , explore ratio: 0.14255512475417456\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 805 , steps =  639 , total reward: -2.2116549613215195 , steps_avg: 316.16749379652606 , reward_avg: -19.651853557171272 , distance traveled: 98.98680517315825 , average speed: 0.15490892828350272 , explore ratio: 0.14227324544692568\n",
      "Episode 806 , steps =  65 , total reward: -2.1788975033101963 , steps_avg: 315.85625774473357 , reward_avg: -19.63020181484926 , distance traveled: 8.942730429768563 , average speed: 0.13758046815028557 , explore ratio: 0.14199192350963452\n",
      "Episode 807 , steps =  609 , total reward: 6.474222224185201 , steps_avg: 316.2190594059406 , reward_avg: -19.59789435935541 , distance traveled: 109.95371732789674 , average speed: 0.1805479759078764 , explore ratio: 0.14171115784019367\n",
      "Episode 808 , steps =  77 , total reward: -8.63857482745871 , steps_avg: 315.9233621755253 , reward_avg: -19.5843476108611 , distance traveled: 5.033501202464105 , average speed: 0.06537014548654682 , explore ratio: 0.14143094733867495\n",
      "Episode 809 , steps =  85 , total reward: -6.195214360908926 , steps_avg: 315.63827160493827 , reward_avg: -19.567817816725356 , distance traveled: 11.312053605616093 , average speed: 0.13308298359548346 , explore ratio: 0.14115129090732514\n",
      "Episode 810 , steps =  50 , total reward: -20.55892748588076 , steps_avg: 315.31072749691737 , reward_avg: -19.569039900164512 , distance traveled: -6.736940947640687 , average speed: -0.13473881895281375 , explore ratio: 0.14087218745056165\n",
      "Episode 811 , steps =  601 , total reward: 21.157171374461896 , steps_avg: 315.6625615763547 , reward_avg: -19.518884467560294 , distance traveled: 126.02943536756382 , average speed: 0.2096995596798067 , explore ratio: 0.14059363587496818\n",
      "Episode 812 , steps =  63 , total reward: -18.711913852397352 , steps_avg: 315.3517835178352 , reward_avg: -19.517891883777803 , distance traveled: -6.4954506055265675 , average speed: -0.10310239056391376 , explore ratio: 0.1403156350892905\n",
      "Episode 813 , steps =  60 , total reward: -16.51347243544646 , steps_avg: 315.0380835380835 , reward_avg: -19.514200950794596 , distance traveled: -2.627245193514972 , average speed: -0.043787419891916195 , explore ratio: 0.14003818400443221\n",
      "Episode 814 , steps =  479 , total reward: -2.9734790215287763 , steps_avg: 315.23926380368096 , reward_avg: -19.49390558646421 , distance traveled: 74.69181146392596 , average speed: 0.15593280055099365 , explore ratio: 0.13976128153345033\n",
      "Episode 815 , steps =  97 , total reward: -11.454163920996711 , steps_avg: 314.9718137254902 , reward_avg: -19.484052961874177 , distance traveled: 2.3591221114620553 , average speed: 0.024320846509918097 , explore ratio: 0.13948492659155118\n",
      "Episode 816 , steps =  60 , total reward: -4.109137233532967 , steps_avg: 314.6597307221542 , reward_avg: -19.465234215572654 , distance traveled: 8.740581423640249 , average speed: 0.1456763570606708 , explore ratio: 0.13920911809608608\n",
      "Episode 817 , steps =  41 , total reward: -12.28776231301452 , steps_avg: 314.3251833740831 , reward_avg: -19.456459800043856 , distance traveled: 3.0980292483419185 , average speed: 0.07556168898394923 , explore ratio: 0.13893385496654712\n",
      "Episode 818 , steps =  625 , total reward: -43.793048034027954 , steps_avg: 314.7045177045177 , reward_avg: -19.48617480399255 , distance traveled: 44.38195926530286 , average speed: 0.07101113482448458 , explore ratio: 0.13865913612456288\n",
      "Episode 819 , steps =  169 , total reward: -4.774562969389701 , steps_avg: 314.52682926829266 , reward_avg: -19.468233813950356 , distance traveled: 30.752941336054356 , average speed: 0.1819700670772447 , explore ratio: 0.13838496049389426\n",
      "Episode 820 , steps =  61 , total reward: -7.124020348530887 , steps_avg: 314.2180267965895 , reward_avg: -19.453198231166652 , distance traveled: 4.968526674360037 , average speed: 0.08145125695672192 , explore ratio: 0.13811132700043025\n",
      "Episode 821 , steps =  156 , total reward: -1.949388339899489 , steps_avg: 314.0255474452555 , reward_avg: -19.43190405854954 , distance traveled: 27.388625955507163 , average speed: 0.1755681150994049 , explore ratio: 0.13783823457218372\n",
      "Episode 822 , steps =  1210 , total reward: -13.686017114671854 , steps_avg: 315.1142162818955 , reward_avg: -19.424922421922712 , distance traveled: 173.50361420228566 , average speed: 0.14339141669610386 , explore ratio: 0.13756568213928722\n",
      "Episode 823 , steps =  167 , total reward: 4.133295681949076 , steps_avg: 314.93446601941747 , reward_avg: -19.396332351408308 , distance traveled: 39.237636262401935 , average speed: 0.23495590576288583 , explore ratio: 0.13729366863398876\n",
      "Episode 824 , steps =  78 , total reward: -4.394011907537782 , steps_avg: 314.6472727272727 , reward_avg: -19.378147720567252 , distance traveled: 8.82027748927474 , average speed: 0.11308048063172745 , explore ratio: 0.1370221929906477\n",
      "Episode 825 , steps =  148 , total reward: -11.277391841955492 , steps_avg: 314.4455205811138 , reward_avg: -19.36834051006046 , distance traveled: 9.086285872980953 , average speed: 0.06139382346608752 , explore ratio: 0.13675125414573047\n",
      "Episode 826 , steps =  135 , total reward: -2.828416399204487 , steps_avg: 314.2285368802902 , reward_avg: -19.348340601824837 , distance traveled: 18.971088870763776 , average speed: 0.1405265842278798 , explore ratio: 0.13648085103780652\n",
      "Episode 827 , steps =  210 , total reward: -7.417372973148411 , steps_avg: 314.1026570048309 , reward_avg: -19.333931220630785 , distance traveled: 23.35566703850405 , average speed: 0.11121746208811452 , explore ratio: 0.13621098260754408\n",
      "Episode 828 , steps =  86 , total reward: -26.349310027408738 , steps_avg: 313.82750301568154 , reward_avg: -19.342393679987573 , distance traveled: -9.62821433220059 , average speed: -0.11195598060698361 , explore ratio: 0.13594164779770604\n",
      "Episode 829 , steps =  100 , total reward: 5.7556053005127845 , steps_avg: 313.5698795180723 , reward_avg: -19.31215512699902 , distance traveled: 26.614972489401694 , average speed: 0.26614972489401695 , explore ratio: 0.1356728455531458\n",
      "Episode 830 , steps =  182 , total reward: -5.611256083280487 , steps_avg: 313.4115523465704 , reward_avg: -19.295667883865786 , distance traveled: 22.479872431308035 , average speed: 0.12351578258960459 , explore ratio: 0.13540457482080312\n",
      "Episode 831 , steps =  236 , total reward: 27.301776478444502 , steps_avg: 313.31850961538464 , reward_avg: -19.23966134016109 , distance traveled: 81.20362763380632 , average speed: 0.34408316793985727 , explore ratio: 0.13513683454970005\n",
      "Episode 832 , steps =  89 , total reward: -4.997061888062094 , steps_avg: 313.04921968787517 , reward_avg: -19.222563381635158 , distance traveled: 11.145974850654603 , average speed: 0.1252356724792652 , explore ratio: 0.13486962369093672\n",
      "Episode 833 , steps =  182 , total reward: 27.830307349643952 , steps_avg: 312.89208633093523 , reward_avg: -19.166145071405808 , distance traveled: 70.69433070302011 , average speed: 0.3884303884781325 , explore ratio: 0.13460294119768734\n",
      "Episode 834 , steps =  122 , total reward: -6.799122493763148 , steps_avg: 312.66347305389223 , reward_avg: -19.151334265923598 , distance traveled: 11.587999165139626 , average speed: 0.09498359971425924 , explore ratio: 0.13433678602519605\n",
      "Episode 835 , steps =  120 , total reward: -10.434735144538191 , steps_avg: 312.433014354067 , reward_avg: -19.14090771195065 , distance traveled: 7.324348254315555 , average speed: 0.06103623545262962 , explore ratio: 0.13407115713077278\n",
      "Episode 836 , steps =  176 , total reward: 12.412870454470307 , steps_avg: 312.2700119474313 , reward_avg: -19.10320905225361 , distance traveled: 49.14101813705172 , average speed: 0.2792103303241575 , explore ratio: 0.13380605347378924\n",
      "Episode 837 , steps =  81 , total reward: -29.523686875599758 , steps_avg: 311.9940334128878 , reward_avg: -19.115643989990303 , distance traveled: -13.335822252631187 , average speed: -0.16463978089668133 , explore ratio: 0.1335414740156748\n",
      "Episode 838 , steps =  382 , total reward: 32.95445131966281 , steps_avg: 312.07747318235994 , reward_avg: -19.053581897845305 , distance traveled: 110.16989517398174 , average speed: 0.2884028669475962 , explore ratio: 0.1332774177199124\n",
      "Episode 839 , steps =  186 , total reward: 3.8398471899938933 , steps_avg: 311.92738095238093 , reward_avg: -19.026327815597877 , distance traveled: 39.87827437207104 , average speed: 0.2143993245810271 , explore ratio: 0.13301388355203458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 840 , steps =  52 , total reward: -9.407459013417988 , steps_avg: 311.61831153388823 , reward_avg: -19.01489039728375 , distance traveled: 1.1286534258350733 , average speed: 0.02170487357375141 , explore ratio: 0.13275087047961937\n",
      "Episode 841 , steps =  63 , total reward: -5.732707358745236 , steps_avg: 311.32304038004753 , reward_avg: -18.999115833104966 , distance traveled: 7.682465580208226 , average speed: 0.12194389809854327 , explore ratio: 0.13248837747228617\n",
      "Episode 842 , steps =  52 , total reward: -1.7451650767984526 , steps_avg: 311.01542111506524 , reward_avg: -18.978648513109345 , distance traveled: 6.719391060769557 , average speed: 0.12921905886095303 , explore ratio: 0.13222640350169187\n",
      "Episode 843 , steps =  145 , total reward: -4.873094974849385 , steps_avg: 310.8187203791469 , reward_avg: -18.96193577195027 , distance traveled: 17.361244959086186 , average speed: 0.1197327238557668 , explore ratio: 0.1319649475415267\n",
      "Episode 844 , steps =  66 , total reward: -28.01705918258801 , steps_avg: 310.52899408284026 , reward_avg: -18.972651894329722 , distance traveled: -14.900947181582445 , average speed: -0.2257719269936734 , explore ratio: 0.13170400856751027\n",
      "Episode 845 , steps =  197 , total reward: 10.912349912056056 , steps_avg: 310.39479905437355 , reward_avg: -18.93732683309286 , distance traveled: 52.215251182168714 , average speed: 0.2650520364577092 , explore ratio: 0.1314435855573875\n",
      "Episode 846 , steps =  194 , total reward: 10.560799881932002 , steps_avg: 310.2573789846517 , reward_avg: -18.902500237207352 , distance traveled: 46.78497379302979 , average speed: 0.2411596587269577 , explore ratio: 0.13118367749092466\n",
      "Episode 847 , steps =  51 , total reward: -17.774763629586747 , steps_avg: 309.9516509433962 , reward_avg: -18.90117035913233 , distance traveled: -7.157731944322584 , average speed: -0.14034768518279575 , explore ratio: 0.1309242833499054\n",
      "Episode 848 , steps =  63 , total reward: 0.9378823280514555 , steps_avg: 309.660777385159 , reward_avg: -18.87780280590832 , distance traveled: 12.26355235219002 , average speed: 0.19465956114587332 , explore ratio: 0.13066540211812672\n",
      "Episode 849 , steps =  172 , total reward: -0.3349285374544643 , steps_avg: 309.49882352941177 , reward_avg: -18.855987659710138 , distance traveled: 29.125005594603717 , average speed: 0.169331427875603 , explore ratio: 0.13040703278139493\n",
      "Episode 850 , steps =  49 , total reward: -2.0121142444312587 , steps_avg: 309.192714453584 , reward_avg: -18.836194623969504 , distance traveled: 6.348199187144637 , average speed: 0.12955508545193137 , explore ratio: 0.1301491743275218\n",
      "Episode 851 , steps =  50 , total reward: -0.5790364873191963 , steps_avg: 308.88849765258215 , reward_avg: -18.81476603460724 , distance traveled: 6.6672956818342195 , average speed: 0.13334591363668438 , explore ratio: 0.12989182574632052\n",
      "Episode 852 , steps =  51 , total reward: -15.493707632200172 , steps_avg: 308.58616647127786 , reward_avg: -18.810872648437947 , distance traveled: -3.619505465067922 , average speed: -0.07097069539348867 , explore ratio: 0.1296349860296018\n",
      "Episode 853 , steps =  216 , total reward: 10.00107496578431 , steps_avg: 308.4777517564403 , reward_avg: -18.777135004861574 , distance traveled: 54.01005752546713 , average speed: 0.25004656261790337 , explore ratio: 0.1293786541711698\n",
      "Episode 854 , steps =  69 , total reward: 3.741660670878365 , steps_avg: 308.1976608187135 , reward_avg: -18.750797232141412 , distance traveled: 16.42918330281973 , average speed: 0.2381041058379671 , explore ratio: 0.12912282916681833\n",
      "Episode 855 , steps =  183 , total reward: 9.052658243191098 , steps_avg: 308.0514018691589 , reward_avg: -18.718316559857143 , distance traveled: 44.551435123980035 , average speed: 0.24345046515836086 , explore ratio: 0.1288675100143268\n",
      "Episode 856 , steps =  192 , total reward: 15.44841621696699 , steps_avg: 307.91598599766627 , reward_avg: -18.6784487269787 , distance traveled: 55.44122540114213 , average speed: 0.28875638229761524 , explore ratio: 0.1286126957134564\n",
      "Episode 857 , steps =  439 , total reward: 21.59443402958223 , steps_avg: 308.06876456876455 , reward_avg: -18.631510635187837 , distance traveled: 102.85349333077677 , average speed: 0.23429041760996985 , explore ratio: 0.12835838526594612\n",
      "Episode 858 , steps =  53 , total reward: -18.823439980677644 , steps_avg: 307.77182770663563 , reward_avg: -18.63173406865174 , distance traveled: -7.760879577398299 , average speed: -0.14643169013959054 , explore ratio: 0.12810457767550879\n",
      "Episode 859 , steps =  505 , total reward: 31.97690750724674 , steps_avg: 308.00116279069766 , reward_avg: -18.572886811005343 , distance traveled: 127.06004120087262 , average speed: 0.251604041981926 , explore ratio: 0.12785127194782728\n",
      "Episode 860 , steps =  68 , total reward: 1.6296582902992758 , steps_avg: 307.7224157955865 , reward_avg: -18.549422763268637 , distance traveled: 13.26388956069946 , average speed: 0.19505719942205088 , explore ratio: 0.1275984670905506\n",
      "Episode 861 , steps =  53 , total reward: -0.7687730080857881 , steps_avg: 307.42691415313226 , reward_avg: -18.528795559376313 , distance traveled: 7.968453781306744 , average speed: 0.15034818455295743 , explore ratio: 0.12734616211328986\n",
      "Episode 862 , steps =  325 , total reward: -47.480368420438126 , steps_avg: 307.4472769409038 , reward_avg: -18.562343152494577 , distance traveled: 5.122504982514076 , average speed: 0.015761553792351002 , explore ratio: 0.1270943560276146\n",
      "Episode 863 , steps =  98 , total reward: -33.977532973131794 , steps_avg: 307.2048611111111 , reward_avg: -18.580184807379574 , distance traveled: -14.514666851693764 , average speed: -0.14810884542544658 , explore ratio: 0.12684304784704878\n",
      "Episode 864 , steps =  360 , total reward: -15.578226242533951 , steps_avg: 307.26589595375725 , reward_avg: -18.576714335050276 , distance traveled: 39.05377727963961 , average speed: 0.10848271466566559 , explore ratio: 0.12659223658706695\n",
      "Episode 865 , steps =  71 , total reward: 0.10785193447830843 , steps_avg: 306.9930715935335 , reward_avg: -18.555138623422643 , distance traveled: 12.796660701557991 , average speed: 0.1802346577684224 , explore ratio: 0.1263419212650904\n",
      "Episode 866 , steps =  546 , total reward: 15.310611953985518 , steps_avg: 307.26874279123416 , reward_avg: -18.516077780772807 , distance traveled: 108.38076949631339 , average speed: 0.1984995778320758 , explore ratio: 0.1260921009004833\n",
      "Episode 867 , steps =  71 , total reward: 4.692604408703739 , steps_avg: 306.9965437788018 , reward_avg: -18.48933966765129 , distance traveled: 16.83844929703759 , average speed: 0.23716125770475482 , explore ratio: 0.12584277451454892\n",
      "Episode 868 , steps =  512 , total reward: -8.821399291405395 , steps_avg: 307.2324510932106 , reward_avg: -18.47821430473271 , distance traveled: 73.53771644401364 , average speed: 0.14362835242971414 , explore ratio: 0.12559394113052566\n",
      "Episode 869 , steps =  55 , total reward: -13.06069530177862 , steps_avg: 306.9425287356322 , reward_avg: -18.47198727139598 , distance traveled: -0.486128133460879 , average speed: -0.008838693335652346 , explore ratio: 0.12534559977358337\n",
      "Episode 870 , steps =  43 , total reward: -13.904973525275173 , steps_avg: 306.6394948335247 , reward_avg: -18.46674385722133 , distance traveled: -2.183112841844559 , average speed: -0.050770066089408344 , explore ratio: 0.12509774947081942\n",
      "Episode 871 , steps =  100 , total reward: -12.676372298098483 , steps_avg: 306.4025229357798 , reward_avg: -18.46010352286454 , distance traveled: -0.5303965008258821 , average speed: -0.005303965008258821 , explore ratio: 0.12485038925125498\n",
      "Episode 872 , steps =  440 , total reward: -12.706407297793373 , steps_avg: 306.55555555555554 , reward_avg: -18.45351280553914 , distance traveled: 55.196027349215 , average speed: 0.12544551670276136 , explore ratio: 0.12460351814583114\n",
      "Episode 873 , steps =  320 , total reward: -5.689723907727613 , steps_avg: 306.57093821510296 , reward_avg: -18.43890892808169 , distance traveled: 47.268880326524375 , average speed: 0.14771525102038868 , explore ratio: 0.12435713518740514\n",
      "Episode 874 , steps =  306 , total reward: -38.46841178612268 , steps_avg: 306.5702857142857 , reward_avg: -18.461799788490882 , distance traveled: 2.329372934103013 , average speed: 0.0076123298500098465 , explore ratio: 0.12411123941074662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 875 , steps =  66 , total reward: -17.595177187712867 , steps_avg: 306.29566210045664 , reward_avg: -18.460810493284512 , distance traveled: -6.38557269961573 , average speed: -0.09675110150932924 , explore ratio: 0.12386582985253376\n",
      "Episode 876 , steps =  67 , total reward: -8.500455923474089 , steps_avg: 306.02280501710374 , reward_avg: -18.44945319046831 , distance traveled: 4.94186379281804 , average speed: 0.07375916108683642 , explore ratio: 0.12362090555134958\n",
      "Episode 877 , steps =  52 , total reward: -18.60307339595569 , steps_avg: 305.73348519362185 , reward_avg: -18.449628156533787 , distance traveled: -7.087888033390047 , average speed: -0.13630553910365475 , explore ratio: 0.12337646554767814\n",
      "Episode 878 , steps =  295 , total reward: -21.131323584985438 , steps_avg: 305.7212741751991 , reward_avg: -18.452679004575256 , distance traveled: 22.29213501680642 , average speed: 0.0755665593790048 , explore ratio: 0.12313250888390077\n",
      "Episode 879 , steps =  101 , total reward: 7.416353463914232 , steps_avg: 305.4886363636364 , reward_avg: -18.423282376770153 , distance traveled: 30.13802593544127 , average speed: 0.29839629639050763 , explore ratio: 0.12288903460429236\n",
      "Episode 880 , steps =  244 , total reward: -7.1104569510979125 , steps_avg: 305.4188422247446 , reward_avg: -18.410441485254065 , distance traveled: 33.32577760230751 , average speed: 0.13658105574716192 , explore ratio: 0.12264604175501756\n",
      "Episode 881 , steps =  63 , total reward: 1.1613444096713001 , steps_avg: 305.14399092970524 , reward_avg: -18.38825125181311 , distance traveled: 13.36763740360737 , average speed: 0.21218472069218047 , explore ratio: 0.12240352938412709\n",
      "Episode 882 , steps =  60 , total reward: -5.76474281722059 , steps_avg: 304.86636466591165 , reward_avg: -18.373955092770533 , distance traveled: 4.033497895784676 , average speed: 0.0672249649297446 , explore ratio: 0.12216149654155399\n",
      "Episode 883 , steps =  63 , total reward: -0.09852358960298213 , steps_avg: 304.59276018099547 , reward_avg: -18.353281527721702 , distance traveled: 11.10160886675119 , average speed: 0.1762160137579554 , explore ratio: 0.1219199422791099\n",
      "Episode 884 , steps =  364 , total reward: -20.473887943701797 , steps_avg: 304.6598870056497 , reward_avg: -18.35567769316349 , distance traveled: 35.99540146228623 , average speed: 0.0988884655557314 , explore ratio: 0.12167886565048136\n",
      "Episode 885 , steps =  240 , total reward: 10.478738145899628 , steps_avg: 304.58690744920995 , reward_avg: -18.32313320576048 , distance traveled: 55.89692601565273 , average speed: 0.23290385839855304 , explore ratio: 0.12143826571122605\n",
      "Episode 886 , steps =  152 , total reward: -31.752825289687728 , steps_avg: 304.41488162344984 , reward_avg: -18.338273783081707 , distance traveled: -4.853714919369668 , average speed: -0.03193233499585307 , explore ratio: 0.12119814151876918\n",
      "Episode 887 , steps =  73 , total reward: -6.815442778537057 , steps_avg: 304.15427927927925 , reward_avg: -18.325297622040555 , distance traveled: 4.149034603536129 , average speed: 0.056836090459399025 , explore ratio: 0.1209584921323997\n",
      "Episode 888 , steps =  230 , total reward: -22.06926466737561 , steps_avg: 304.07086614173227 , reward_avg: -18.329509058536992 , distance traveled: 7.305386974319117 , average speed: 0.03176255206225703 , explore ratio: 0.1207193166132667\n",
      "Episode 889 , steps =  396 , total reward: -12.491831670954017 , steps_avg: 304.1741573033708 , reward_avg: -18.322949870461056 , distance traveled: 46.572483349051325 , average speed: 0.11760728118447304 , explore ratio: 0.12048061402437567\n",
      "Episode 890 , steps =  43 , total reward: -14.070890895793214 , steps_avg: 303.8810325476992 , reward_avg: -18.318177638166254 , distance traveled: -2.2412305569648736 , average speed: -0.052121640859648224 , explore ratio: 0.12024238343058485\n",
      "Episode 891 , steps =  80 , total reward: -7.000958173004912 , steps_avg: 303.63004484304935 , reward_avg: -18.305490172398137 , distance traveled: 4.469791807830332 , average speed: 0.05587239759787915 , explore ratio: 0.1200046238986016\n",
      "Episode 892 , steps =  152 , total reward: 15.750756125379347 , steps_avg: 303.4602463605823 , reward_avg: -18.267353278447658 , distance traveled: 49.235263227056706 , average speed: 0.32391620544116256 , explore ratio: 0.11976733449697867\n",
      "Episode 893 , steps =  162 , total reward: -10.006972797590008 , steps_avg: 303.3020134228188 , reward_avg: -18.258113479252067 , distance traveled: 12.3312009382993 , average speed: 0.0761185243104895 , explore ratio: 0.11953051429611063\n",
      "Episode 894 , steps =  253 , total reward: -4.924265157646209 , steps_avg: 303.24581005586595 , reward_avg: -18.24321532470279 , distance traveled: 34.094778466299175 , average speed: 0.1347619702225264 , explore ratio: 0.11929416236823016\n",
      "Episode 895 , steps =  318 , total reward: -23.522103082680864 , steps_avg: 303.2622767857143 , reward_avg: -18.249106940504102 , distance traveled: 19.93844234512536 , average speed: 0.06269950422995396 , explore ratio: 0.11905827778740448\n",
      "Episode 896 , steps =  163 , total reward: 11.477786975241564 , steps_avg: 303.10590858416947 , reward_avg: -18.21596659054229 , distance traveled: 44.98942546628414 , average speed: 0.27600874519192725 , explore ratio: 0.11882285962953165\n",
      "Episode 897 , steps =  95 , total reward: -17.81448739725166 , steps_avg: 302.87416481069044 , reward_avg: -18.21551950903529 , distance traveled: -1.7831611221749333 , average speed: -0.018770117075525613 , explore ratio: 0.11858790697233704\n",
      "Episode 898 , steps =  103 , total reward: -20.40759785511592 , steps_avg: 302.65183537263624 , reward_avg: -18.217957860921917 , distance traveled: -10.123221615739174 , average speed: -0.09828370500717645 , explore ratio: 0.11835341889536961\n",
      "Episode 899 , steps =  118 , total reward: 7.3017230227955885 , steps_avg: 302.44666666666666 , reward_avg: -18.189602659940007 , distance traveled: 32.93832290109245 , average speed: 0.27913832967027497 , explore ratio: 0.11811939447999842\n",
      "Episode 900 , steps =  204 , total reward: 8.333363025742258 , steps_avg: 302.3374028856826 , reward_avg: -18.160165406126822 , distance traveled: 47.064316558018334 , average speed: 0.230707434107933 , explore ratio: 0.11788583280940892\n",
      "Episode 901 , steps =  498 , total reward: -18.278199681298716 , steps_avg: 302.55432372505544 , reward_avg: -18.160296264525012 , distance traveled: 52.85966917431445 , average speed: 0.10614391400464748 , explore ratio: 0.11765273296859945\n",
      "Episode 902 , steps =  54 , total reward: -16.98160583247617 , steps_avg: 302.27906976744185 , reward_avg: -18.158990959506134 , distance traveled: -7.077279860973357 , average speed: -0.13106073816617328 , explore ratio: 0.11742009404437757\n",
      "Episode 903 , steps =  80 , total reward: -7.179455058105918 , steps_avg: 302.033185840708 , reward_avg: -18.146845455190427 , distance traveled: 4.98513298228383 , average speed: 0.06231416227854788 , explore ratio: 0.11718791512535658\n",
      "Episode 904 , steps =  84 , total reward: -23.262750756248813 , steps_avg: 301.79226519337016 , reward_avg: -18.152498389224746 , distance traveled: -7.506500764489172 , average speed: -0.08936310433915681 , explore ratio: 0.11695619530195185\n",
      "Episode 905 , steps =  63 , total reward: -1.440189339149744 , steps_avg: 301.5286975717439 , reward_avg: -18.13405213199508 , distance traveled: 9.275271869301797 , average speed: 0.14722653760796503 , explore ratio: 0.11672493366637735\n",
      "Episode 906 , steps =  90 , total reward: -15.696762869379798 , steps_avg: 301.2954796030871 , reward_avg: -18.13136493324909 , distance traveled: -2.584309140890838 , average speed: -0.028714546009898197 , explore ratio: 0.116494129312642\n",
      "Episode 907 , steps =  243 , total reward: -19.14572619414008 , steps_avg: 301.23127753303964 , reward_avg: -18.132482071201615 , distance traveled: 13.78484741739929 , average speed: 0.05672776714979132 , explore ratio: 0.11626378133654619\n",
      "Episode 908 , steps =  62 , total reward: -14.506241787835958 , steps_avg: 300.96809680968096 , reward_avg: -18.12849280796359 , distance traveled: -3.3345592273771776 , average speed: -0.05378321334479318 , explore ratio: 0.11603388883567824\n",
      "Episode 909 , steps =  198 , total reward: 15.823841593047588 , steps_avg: 300.85494505494506 , reward_avg: -18.091182550380058 , distance traveled: 55.07522177668288 , average speed: 0.2781576857408226 , explore ratio: 0.1158044509094108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 910 , steps =  52 , total reward: -6.378869394317896 , steps_avg: 300.58177826564213 , reward_avg: -18.078326004654414 , distance traveled: 0.7792933928710407 , average speed: 0.014986411401366168 , explore ratio: 0.11557546665889738\n",
      "Episode 911 , steps =  72 , total reward: -4.627126185260096 , steps_avg: 300.3311403508772 , reward_avg: -18.063576882045425 , distance traveled: 6.378959257258102 , average speed: 0.08859665635080698 , explore ratio: 0.11534693518706882\n",
      "Episode 912 , steps =  92 , total reward: -1.5847421078439812 , steps_avg: 300.10295728368015 , reward_avg: -18.045527774954298 , distance traveled: 16.823882401585575 , average speed: 0.18286828697375626 , explore ratio: 0.11511885559862975\n",
      "Episode 913 , steps =  152 , total reward: 5.867404476882883 , steps_avg: 299.94091903719914 , reward_avg: -18.01936482938336 , distance traveled: 34.9829506766796 , average speed: 0.23015099129394473 , explore ratio: 0.11489122700005511\n",
      "Episode 914 , steps =  279 , total reward: 27.080909415661683 , steps_avg: 299.91803278688525 , reward_avg: -17.97007491217566 , distance traveled: 84.1341968341079 , average speed: 0.3015562610541502 , explore ratio: 0.11466404849958664\n",
      "Episode 915 , steps =  66 , total reward: 1.3646008589540903 , steps_avg: 299.66266375545854 , reward_avg: -17.94896718753469 , distance traveled: 12.731865735054017 , average speed: 0.19290705659172752 , explore ratio: 0.11443731920722938\n",
      "Episode 916 , steps =  110 , total reward: -21.870970396207014 , steps_avg: 299.4558342420938 , reward_avg: -17.953244181219173 , distance traveled: -1.670472790785133 , average speed: -0.015186116279864846 , explore ratio: 0.1142110382347482\n",
      "Episode 917 , steps =  181 , total reward: -3.073039986315507 , steps_avg: 299.3267973856209 , reward_avg: -17.93703480845784 , distance traveled: 28.469601690173157 , average speed: 0.15729061707277986 , explore ratio: 0.11398520469566427\n",
      "Episode 918 , steps =  47 , total reward: -6.443261934487148 , steps_avg: 299.0522306855278 , reward_avg: -17.92452798269726 , distance traveled: -0.1175667739659547 , average speed: -0.002501420722679887 , explore ratio: 0.11375981770525168\n",
      "Episode 919 , steps =  242 , total reward: 24.29298920030143 , steps_avg: 298.9902173913043 , reward_avg: -17.878639377063568 , distance traveled: 75.5422025329247 , average speed: 0.31215786170630044 , explore ratio: 0.11353487638053388\n",
      "Episode 920 , steps =  60 , total reward: -4.619791182142992 , steps_avg: 298.7307274701412 , reward_avg: -17.86424323352945 , distance traveled: 6.037218141853812 , average speed: 0.1006203023642302 , explore ratio: 0.11331037984028028\n",
      "Episode 921 , steps =  59 , total reward: 0.6578672742297231 , steps_avg: 298.470715835141 , reward_avg: -17.844154176579604 , distance traveled: 11.6403047901392 , average speed: 0.19729330152778307 , explore ratio: 0.11308632720500278\n",
      "Episode 922 , steps =  45 , total reward: -23.632005895425884 , steps_avg: 298.1960996749729 , reward_avg: -17.85042487183296 , distance traveled: -5.400605506002903 , average speed: -0.1200134556889534 , explore ratio: 0.11286271759695231\n",
      "Episode 923 , steps =  50 , total reward: -11.82163078809468 , steps_avg: 297.9274891774892 , reward_avg: -17.843900202911165 , distance traveled: 0.6577287217229606 , average speed: 0.013154574434459212 , explore ratio: 0.11263955014011542\n",
      "Episode 924 , steps =  62 , total reward: 0.3869889612005413 , steps_avg: 297.67243243243246 , reward_avg: -17.82419113354456 , distance traveled: 11.223409528434278 , average speed: 0.18102273432958513 , explore ratio: 0.11241682396021083\n",
      "Episode 925 , steps =  386 , total reward: 1.3887045241879652 , steps_avg: 297.767818574514 , reward_avg: -17.8034428660956 , distance traveled: 67.39526839837431 , average speed: 0.17459914092843087 , explore ratio: 0.11219453818468597\n",
      "Episode 926 , steps =  94 , total reward: -13.542462725219014 , steps_avg: 297.5480043149946 , reward_avg: -17.79884633951429 , distance traveled: -0.17687227464281013 , average speed: -0.0018816199430086184 , explore ratio: 0.11197269194271367\n",
      "Episode 927 , steps =  792 , total reward: 33.21772109718421 , steps_avg: 298.08081896551727 , reward_avg: -17.743871590121294 , distance traveled: 174.18056275751442 , average speed: 0.21992495297665962 , explore ratio: 0.11175128436518861\n",
      "Episode 928 , steps =  59 , total reward: -0.4384191859439011 , steps_avg: 297.8234660925727 , reward_avg: -17.72524354662918 , distance traveled: 8.912787316739559 , average speed: 0.15106419180914507 , explore ratio: 0.11153031458472402\n",
      "Episode 929 , steps =  80 , total reward: -3.4717350551237782 , steps_avg: 297.58924731182793 , reward_avg: -17.709917193412505 , distance traveled: 10.211679333066568 , average speed: 0.1276459916633321 , explore ratio: 0.11130978173564825\n",
      "Episode 930 , steps =  58 , total reward: -7.587898877751089 , steps_avg: 297.33190118152527 , reward_avg: -17.699044993288272 , distance traveled: 2.4681663276627663 , average speed: 0.04255459185625459 , explore ratio: 0.11108968495400133\n",
      "Episode 931 , steps =  254 , total reward: -27.645722100258357 , steps_avg: 297.2854077253219 , reward_avg: -17.70971739361764 , distance traveled: 6.827799264346248 , average speed: 0.02688109946593011 , explore ratio: 0.11087002337753167\n",
      "Episode 932 , steps =  85 , total reward: 6.138803849412745 , steps_avg: 297.05787781350483 , reward_avg: -17.684156277601527 , distance traveled: 25.269640390276912 , average speed: 0.29728988694443426 , explore ratio: 0.11065079614569263\n",
      "Episode 933 , steps =  162 , total reward: -36.715004769749264 , steps_avg: 296.9132762312634 , reward_avg: -17.704531918385413 , distance traveled: -4.936135274078697 , average speed: -0.030469970827646277 , explore ratio: 0.11043200239963917\n",
      "Episode 934 , steps =  57 , total reward: -0.041980497861279664 , steps_avg: 296.65668449197864 , reward_avg: -17.68564148905865 , distance traveled: 10.101905905008316 , average speed: 0.1772264193861108 , explore ratio: 0.11021364128222445\n",
      "Episode 935 , steps =  49 , total reward: -1.5743321893041347 , steps_avg: 296.392094017094 , reward_avg: -17.668428551772585 , distance traveled: 7.482748672328888 , average speed: 0.15270915657814058 , explore ratio: 0.10999571193799651\n",
      "Episode 936 , steps =  59 , total reward: 1.0965021034125262 , steps_avg: 296.13874066168626 , reward_avg: -17.648401944883386 , distance traveled: 12.09104944109917 , average speed: 0.2049330413745622 , explore ratio: 0.1097782135131949\n",
      "Episode 937 , steps =  46 , total reward: -15.44387090243834 , steps_avg: 295.8720682302772 , reward_avg: -17.646051698569476 , distance traveled: -5.531704834699632 , average speed: -0.12025445292825286 , explore ratio: 0.10956114515574736\n",
      "Episode 938 , steps =  89 , total reward: -33.06888693717185 , steps_avg: 295.6517571884984 , reward_avg: -17.662476443232524 , distance traveled: -10.966693619191654 , average speed: -0.12322127662013094 , explore ratio: 0.10934450601526643\n",
      "Episode 939 , steps =  89 , total reward: -7.2454066092663805 , steps_avg: 295.43191489361703 , reward_avg: -17.651394454047452 , distance traveled: 7.379676249325277 , average speed: 0.08291771066657615 , explore ratio: 0.10912829524304618\n",
      "Episode 940 , steps =  56 , total reward: -1.168888599293306 , steps_avg: 295.1774707757705 , reward_avg: -17.633878507336767 , distance traveled: 9.078717716038227 , average speed: 0.16211995921496833 , explore ratio: 0.10891251199205884\n",
      "Episode 941 , steps =  40 , total reward: -16.377319589409357 , steps_avg: 294.90658174097666 , reward_avg: -17.632544580672302 , distance traveled: -1.5736021276004613 , average speed: -0.039340053190011534 , explore ratio: 0.10869715541695152\n",
      "Episode 942 , steps =  74 , total reward: -10.482192403235166 , steps_avg: 294.67232237539764 , reward_avg: -17.624962022689868 , distance traveled: 1.0399843372777102 , average speed: 0.014053842395644733 , explore ratio: 0.10848222467404284\n",
      "Episode 943 , steps =  64 , total reward: -6.2413527272877625 , steps_avg: 294.4279661016949 , reward_avg: -17.612903114537957 , distance traveled: 4.835076180696486 , average speed: 0.0755480653233826 , explore ratio: 0.10826771892131969\n",
      "Episode 944 , steps =  81 , total reward: -28.903467319373057 , steps_avg: 294.2021164021164 , reward_avg: -17.624850801527202 , distance traveled: -14.69015054695308 , average speed: -0.18135988329571703 , explore ratio: 0.1080536373184339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 945 , steps =  93 , total reward: -25.136917286472404 , steps_avg: 293.98942917547566 , reward_avg: -17.632791675189935 , distance traveled: -9.500201326198878 , average speed: -0.102152702432246 , explore ratio: 0.10783997902669894\n",
      "Episode 946 , steps =  82 , total reward: -24.55339204082204 , steps_avg: 293.76557550158395 , reward_avg: -17.640099595322596 , distance traveled: -6.970362840100425 , average speed: -0.08500442487927348 , explore ratio: 0.10762674320908663\n",
      "Episode 947 , steps =  42 , total reward: -14.148329101312905 , steps_avg: 293.5 , reward_avg: -17.636416293113726 , distance traveled: -2.1575313735008237 , average speed: -0.05136979460716247 , explore ratio: 0.10741392903022393\n",
      "Episode 948 , steps =  178 , total reward: 5.3782732549489705 , steps_avg: 293.3782929399368 , reward_avg: -17.612164776203226 , distance traveled: 39.036690914332866 , average speed: 0.21930725232771273 , explore ratio: 0.10720153565638955\n",
      "Episode 949 , steps =  68 , total reward: 1.2458114411365204 , steps_avg: 293.14105263157893 , reward_avg: -17.59231427492182 , distance traveled: 13.257601648271084 , average speed: 0.1949647301216336 , explore ratio: 0.10698956225551079\n",
      "Episode 950 , steps =  73 , total reward: -0.8287466939234456 , steps_avg: 292.90956887486857 , reward_avg: -17.574686969368717 , distance traveled: 12.36227935731411 , average speed: 0.16934629256594672 , explore ratio: 0.10677800799716021\n",
      "Episode 951 , steps =  136 , total reward: -7.723278561480974 , steps_avg: 292.7447478991597 , reward_avg: -17.564338851293204 , distance traveled: 14.017454018443821 , average speed: 0.10306951484149869 , explore ratio: 0.10656687205255241\n",
      "Episode 952 , steps =  337 , total reward: -25.69577066426703 , steps_avg: 292.791185729276 , reward_avg: -17.57287130859958 , distance traveled: 19.4412966050099 , average speed: 0.057689307433263795 , explore ratio: 0.1063561535945408\n",
      "Episode 953 , steps =  94 , total reward: -21.73454651335441 , steps_avg: 292.5828092243187 , reward_avg: -17.5772336515815 , distance traveled: -10.446986397542057 , average speed: -0.11113815316534104 , explore ratio: 0.1061458517976143\n",
      "Episode 954 , steps =  509 , total reward: -20.828708913899 , steps_avg: 292.8094240837696 , reward_avg: -17.580638337720053 , distance traveled: 53.3322195170343 , average speed: 0.10477842734191414 , explore ratio: 0.10593596583789416\n",
      "Episode 955 , steps =  160 , total reward: -2.330813103805614 , steps_avg: 292.6705020920502 , reward_avg: -17.56468663768458 , distance traveled: 24.938213123381136 , average speed: 0.1558638320211321 , explore ratio: 0.10572649489313073\n",
      "Episode 956 , steps =  63 , total reward: -6.8939692403134 , steps_avg: 292.4305120167189 , reward_avg: -17.553536462765695 , distance traveled: 5.731916873026639 , average speed: 0.09098280750835935 , explore ratio: 0.10551743814270019\n",
      "Episode 957 , steps =  593 , total reward: 13.825620520076992 , steps_avg: 292.74425887265136 , reward_avg: -17.520781601614505 , distance traveled: 116.49359859138778 , average speed: 0.19644788969879895 , explore ratio: 0.1053087947676014\n",
      "Episode 958 , steps =  68 , total reward: 0.07618073627601152 , steps_avg: 292.5099061522419 , reward_avg: -17.50243231867614 , distance traveled: 13.551756688132878 , average speed: 0.19929053953136586 , explore ratio: 0.10510056395045263\n",
      "Episode 959 , steps =  153 , total reward: -29.776279311516014 , steps_avg: 292.3645833333333 , reward_avg: -17.515217575960346 , distance traveled: -12.147915128655729 , average speed: -0.07939813809578908 , explore ratio: 0.10489274487548841\n",
      "Episode 960 , steps =  45 , total reward: -16.584595421627164 , steps_avg: 292.10718002081165 , reward_avg: -17.51424918662181 , distance traveled: -3.491578192859888 , average speed: -0.07759062650799751 , explore ratio: 0.10468533672855633\n",
      "Episode 961 , steps =  54 , total reward: -11.909858148736262 , steps_avg: 291.85966735966736 , reward_avg: -17.508423416312162 , distance traveled: -1.54296296516899 , average speed: -0.028573388243870186 , explore ratio: 0.10447833869711379\n",
      "Episode 962 , steps =  410 , total reward: -33.1345580489559 , steps_avg: 291.98234683281413 , reward_avg: -17.52464993202622 , distance traveled: 20.54757551880553 , average speed: 0.0501160378507452 , explore ratio: 0.10427174997022487\n",
      "Episode 963 , steps =  58 , total reward: -14.719943174444142 , steps_avg: 291.7396265560166 , reward_avg: -17.52174048518226 , distance traveled: -2.319530812427402 , average speed: -0.03999191055909314 , explore ratio: 0.10406556973855716\n",
      "Episode 964 , steps =  68 , total reward: 0.19141714168650248 , steps_avg: 291.5077720207254 , reward_avg: -17.503384881423845 , distance traveled: 13.683129556775095 , average speed: 0.20122249348198668 , explore ratio: 0.10385979719437856\n",
      "Episode 965 , steps =  598 , total reward: -42.14553213937894 , steps_avg: 291.82505175983437 , reward_avg: -17.52889435063498 , distance traveled: 37.831990243766356 , average speed: 0.06326419773205076 , explore ratio: 0.10365443153155413\n",
      "Episode 966 , steps =  190 , total reward: -10.189331092145304 , steps_avg: 291.7197518097208 , reward_avg: -17.521304316241505 , distance traveled: 22.377325563020996 , average speed: 0.1177753977001105 , explore ratio: 0.10344947194554292\n",
      "Episode 967 , steps =  110 , total reward: 0.4466535743139576 , steps_avg: 291.5320247933884 , reward_avg: -17.502742376271925 , distance traveled: 20.076212004432456 , average speed: 0.18251101822211324 , explore ratio: 0.10324491763339486\n",
      "Episode 968 , steps =  270 , total reward: 7.7536426288758475 , steps_avg: 291.5098039215686 , reward_avg: -17.476677995461657 , distance traveled: 58.16278588458897 , average speed: 0.21541772549847768 , explore ratio: 0.10304076779374753\n",
      "Episode 969 , steps =  409 , total reward: -7.105590368365284 , steps_avg: 291.6309278350515 , reward_avg: -17.465986152547124 , distance traveled: 56.084751313026054 , average speed: 0.13712653132769206 , explore ratio: 0.10283702162682312\n",
      "Episode 970 , steps =  200 , total reward: -23.203411989885723 , steps_avg: 291.53656024716787 , reward_avg: -17.471894933018124 , distance traveled: 9.480767800882454 , average speed: 0.04740383900441227 , explore ratio: 0.10263367833442523\n",
      "Episode 971 , steps =  54 , total reward: -15.276294435075172 , steps_avg: 291.2921810699589 , reward_avg: -17.46963608476921 , distance traveled: -8.471440148949624 , average speed: -0.15687852127684487 , explore ratio: 0.10243073711993575\n",
      "Episode 972 , steps =  70 , total reward: -5.378513188318661 , steps_avg: 291.0647482014389 , reward_avg: -17.457209442532367 , distance traveled: 5.126171211758628 , average speed: 0.07323101731083755 , explore ratio: 0.10222819718831176\n",
      "Episode 973 , steps =  48 , total reward: -14.201700426539404 , steps_avg: 290.8151950718686 , reward_avg: -17.453867030811637 , distance traveled: -6.84801041007042 , average speed: -0.14266688354313375 , explore ratio: 0.10202605774608242\n",
      "Episode 974 , steps =  223 , total reward: -9.876360636220642 , steps_avg: 290.745641025641 , reward_avg: -17.446095229381285 , distance traveled: 22.73201507750899 , average speed: 0.10193728734308964 , explore ratio: 0.10182431800134584\n",
      "Episode 975 , steps =  91 , total reward: -23.92899557015052 , steps_avg: 290.5409836065574 , reward_avg: -17.452737545304203 , distance traveled: -13.955101891733937 , average speed: -0.1533527680410323 , explore ratio: 0.10162297716376596\n",
      "Episode 976 , steps =  145 , total reward: 0.8392504426029728 , steps_avg: 290.39201637666326 , reward_avg: -17.434014937332957 , distance traveled: 23.539394701123243 , average speed: 0.16234065311119478 , explore ratio: 0.10142203444456953\n",
      "Episode 977 , steps =  294 , total reward: 18.016135531755197 , steps_avg: 290.3957055214724 , reward_avg: -17.3977673397163 , distance traveled: 72.85453812271352 , average speed: 0.24780455143780108 , explore ratio: 0.10122148905654292\n",
      "Episode 978 , steps =  349 , total reward: 8.848597461312595 , steps_avg: 290.4555669050051 , reward_avg: -17.37095797832608 , distance traveled: 68.32426089562479 , average speed: 0.19577152119090196 , explore ratio: 0.10102134021402912\n",
      "Episode 979 , steps =  77 , total reward: -23.78463006493265 , steps_avg: 290.2377551020408 , reward_avg: -17.37750254167976 , distance traveled: -1.9702410830184827 , average speed: -0.025587546532707568 , explore ratio: 0.1008215871329246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 980 , steps =  61 , total reward: 0.8555401326330996 , steps_avg: 290.0040774719674 , reward_avg: -17.35891636158362 , distance traveled: 11.679740479588508 , average speed: 0.1914711554030903 , explore ratio: 0.10062222903067632\n",
      "Episode 981 , steps =  186 , total reward: 27.96087920968602 , steps_avg: 289.89816700611 , reward_avg: -17.31276585692856 , distance traveled: 71.54490905463697 , average speed: 0.38465004868084396 , explore ratio: 0.10042326512627853\n",
      "Episode 982 , steps =  69 , total reward: -20.006740633921687 , steps_avg: 289.6734486266531 , reward_avg: -17.315506421299865 , distance traveled: 0.04099629409611242 , average speed: 0.0005941491897987307 , explore ratio: 0.10022469464026984\n",
      "Episode 983 , steps =  65 , total reward: -16.680486923949793 , steps_avg: 289.4451219512195 , reward_avg: -17.314861076282234 , distance traveled: -7.840640510302039 , average speed: -0.12062523862003137 , explore ratio: 0.10002651679473011\n",
      "Episode 984 , steps =  85 , total reward: -20.26390902400015 , steps_avg: 289.2375634517766 , reward_avg: -17.31785503358956 , distance traveled: -3.3675438331626357 , average speed: -0.03961816274308983 , explore ratio: 0.09982873081327741\n",
      "Episode 985 , steps =  45 , total reward: -26.410276690799122 , steps_avg: 288.9898580121704 , reward_avg: -17.327076556568475 , distance traveled: -5.627920654029585 , average speed: -0.12506490342287965 , explore ratio: 0.09963133592106496\n",
      "Episode 986 , steps =  79 , total reward: 4.558422973498706 , steps_avg: 288.7771023302938 , reward_avg: -17.30490279817935 , distance traveled: 21.304769293069846 , average speed: 0.2696806239629094 , explore ratio: 0.09943433134477815\n",
      "Episode 987 , steps =  61 , total reward: -2.439590106055141 , steps_avg: 288.54655870445345 , reward_avg: -17.28985693513064 , distance traveled: 7.222910238057374 , average speed: 0.11840836455831762 , explore ratio: 0.09923771631263144\n",
      "Episode 988 , steps =  95 , total reward: 7.264627338619903 , steps_avg: 288.3508594539939 , reward_avg: -17.26502934739176 , distance traveled: 25.16388765351847 , average speed: 0.2648830279317734 , explore ratio: 0.09904149005436537\n",
      "Episode 989 , steps =  560 , total reward: -25.920869908276625 , steps_avg: 288.6252525252525 , reward_avg: -17.273772620685584 , distance traveled: 54.34102353958412 , average speed: 0.09703754203497164 , explore ratio: 0.09884565180124355\n",
      "Episode 990 , steps =  54 , total reward: -11.581504668306565 , steps_avg: 288.38849646821393 , reward_avg: -17.26802865706058 , distance traveled: -1.6813754259422422 , average speed: -0.031136581961893374 , explore ratio: 0.09865020078604964\n",
      "Episode 991 , steps =  56 , total reward: -0.5073394874992452 , steps_avg: 288.15423387096774 , reward_avg: -17.25113280104288 , distance traveled: 9.436050150096413 , average speed: 0.16850089553743594 , explore ratio: 0.09845513624308433\n",
      "Episode 992 , steps =  171 , total reward: 3.2154141342596243 , steps_avg: 288.03625377643505 , reward_avg: -17.23052197834872 , distance traveled: 35.34739902880043 , average speed: 0.2067099358409382 , explore ratio: 0.09826045740816239\n",
      "Episode 993 , steps =  212 , total reward: 11.3857831911221 , steps_avg: 287.95975855130786 , reward_avg: -17.20173293894281 , distance traveled: 52.31905445493758 , average speed: 0.24678799271196972 , explore ratio: 0.09806616351860961\n",
      "Episode 994 , steps =  167 , total reward: 6.225289984131837 , steps_avg: 287.8381909547739 , reward_avg: -17.178188192286452 , distance traveled: 36.7946771534253 , average speed: 0.2203274081043431 , explore ratio: 0.09787225381325984\n",
      "Episode 995 , steps =  533 , total reward: -10.61432427646346 , steps_avg: 288.0843373493976 , reward_avg: -17.171597967471367 , distance traveled: 69.8385810140544 , average speed: 0.13102923267177186 , explore ratio: 0.09767872753245203\n",
      "Episode 996 , steps =  669 , total reward: 16.558226093508715 , steps_avg: 288.46639919759275 , reward_avg: -17.137766649456346 , distance traveled: 132.50094640301535 , average speed: 0.19805821584905134 , explore ratio: 0.09748558391802724\n",
      "Episode 997 , steps =  72 , total reward: -3.8718320068990275 , steps_avg: 288.249498997996 , reward_avg: -17.124474129774423 , distance traveled: 7.4905102434649615 , average speed: 0.10403486449256891 , explore ratio: 0.09729282221332562\n",
      "Episode 998 , steps =  68 , total reward: -9.470698240542783 , steps_avg: 288.029029029029 , reward_avg: -17.116812692447866 , distance traveled: -0.2286264421418306 , average speed: -0.0033621535609092736 , explore ratio: 0.09710044166318355\n",
      "Episode 999 , steps =  174 , total reward: 25.769772104845707 , steps_avg: 287.915 , reward_avg: -17.07392610765057 , distance traveled: 68.03851361453532 , average speed: 0.39102594031342136 , explore ratio: 0.09690844151393056\n",
      "Episode 1000 , steps =  65 , total reward: 0.6927315724827283 , steps_avg: 287.6923076923077 , reward_avg: -17.05617719887921 , distance traveled: 13.17717012226581 , average speed: 0.20272569418870479 , explore ratio: 0.09671682101338651\n",
      "Episode 1001 , steps =  138 , total reward: 20.1130533241971 , steps_avg: 287.54291417165666 , reward_avg: -17.01908215843702 , distance traveled: 54.77942621827125 , average speed: 0.3969523639005163 , explore ratio: 0.09652557941085851\n",
      "Episode 1002 , steps =  73 , total reward: -4.4023900961975295 , steps_avg: 287.32901296111663 , reward_avg: -17.006503203240367 , distance traveled: 6.820645565874876 , average speed: 0.09343350090239556 , explore ratio: 0.09633471595713808\n",
      "Episode 1003 , steps =  274 , total reward: -13.285916251312159 , steps_avg: 287.31573705179284 , reward_avg: -17.002797439344025 , distance traveled: 28.514727667914705 , average speed: 0.10406834915297337 , explore ratio: 0.09614422990449815\n",
      "Episode 1004 , steps =  374 , total reward: -14.234446674590297 , steps_avg: 287.40199004975125 , reward_avg: -17.00004286146865 , distance traveled: 41.12322723202408 , average speed: 0.10995515302680235 , explore ratio: 0.09595412050669018\n",
      "Episode 1005 , steps =  159 , total reward: 0.0021948173716589414 , steps_avg: 287.27435387673955 , reward_avg: -16.983142028785903 , distance traveled: 31.604908477216973 , average speed: 0.1987730092906728 , explore ratio: 0.09576438701894119\n",
      "Episode 1006 , steps =  82 , total reward: -23.844385952952017 , steps_avg: 287.07050645481627 , reward_avg: -16.989955577866507 , distance traveled: -5.532539355754851 , average speed: -0.06746999214335185 , explore ratio: 0.0955750286979509\n",
      "Episode 1007 , steps =  112 , total reward: 11.260222380078082 , steps_avg: 286.8968253968254 , reward_avg: -16.961929607670132 , distance traveled: 35.30324484128505 , average speed: 0.3152075432257594 , explore ratio: 0.09538604480188874\n",
      "Episode 1008 , steps =  64 , total reward: -0.0363953681681317 , steps_avg: 286.6759167492567 , reward_avg: -16.945155044499167 , distance traveled: 11.217731457352638 , average speed: 0.17527705402113497 , explore ratio: 0.09519743459039103\n",
      "Episode 1009 , steps =  75 , total reward: -25.360190572980777 , steps_avg: 286.4663366336634 , reward_avg: -16.9534867628442 , distance traveled: -3.41104718953371 , average speed: -0.0454806291937828 , explore ratio: 0.09500919732455801\n",
      "Episode 1010 , steps =  207 , total reward: 2.3636168767145387 , steps_avg: 286.38773491592485 , reward_avg: -16.93437983540646 , distance traveled: 37.07469763979316 , average speed: 0.17910481951590898 , explore ratio: 0.094821332266951\n",
      "Episode 1011 , steps =  56 , total reward: -1.6622777264422428 , steps_avg: 286.1600790513834 , reward_avg: -16.919288825417365 , distance traveled: 8.828156578838826 , average speed: 0.15764565319355045 , explore ratio: 0.09463383868158945\n",
      "Episode 1012 , steps =  292 , total reward: -23.41003417323897 , steps_avg: 286.1658440276407 , reward_avg: -16.925696273934463 , distance traveled: 19.95149178332649 , average speed: 0.0683270266552277 , explore ratio: 0.0944467158339481\n",
      "Episode 1013 , steps =  63 , total reward: -0.08899871025606765 , steps_avg: 285.94575936883626 , reward_avg: -16.90909203570598 , distance traveled: 11.13922532200813 , average speed: 0.1768131003493354 , explore ratio: 0.09425996299095411\n",
      "Episode 1014 , steps =  38 , total reward: -13.446462086076535 , steps_avg: 285.7014778325123 , reward_avg: -16.905680577627532 , distance traveled: -0.5888571127317844 , average speed: -0.015496239808731169 , explore ratio: 0.09407357942098415\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1015 , steps =  203 , total reward: 9.065095400604713 , steps_avg: 285.62007874015745 , reward_avg: -16.88011879024738 , distance traveled: 46.823816596381356 , average speed: 0.2306591950560658 , explore ratio: 0.09388756439386159\n",
      "Episode 1016 , steps =  295 , total reward: 24.413552929026423 , steps_avg: 285.6293018682399 , reward_avg: -16.839515376560776 , distance traveled: 86.71375799993055 , average speed: 0.29394494237264596 , explore ratio: 0.09370191718085355\n",
      "Episode 1017 , steps =  39 , total reward: -14.29622350473764 , steps_avg: 285.38703339882125 , reward_avg: -16.837017054486296 , distance traveled: -0.3505055410042406 , average speed: -0.008987321564211297 , explore ratio: 0.09351663705466813\n",
      "Episode 1018 , steps =  186 , total reward: 6.973800710543976 , steps_avg: 285.28949950932287 , reward_avg: -16.813650206826797 , distance traveled: 42.44200129201635 , average speed: 0.2281828026452492 , explore ratio: 0.09333172328945154\n",
      "Episode 1019 , steps =  67 , total reward: -1.6957824138763056 , steps_avg: 285.0754901960784 , reward_avg: -16.7988287678141 , distance traveled: 10.539364594817165 , average speed: 0.1573039491763756 , explore ratio: 0.09314717516078523\n",
      "Episode 1020 , steps =  110 , total reward: -15.639344746327657 , steps_avg: 284.9040156709109 , reward_avg: -16.79769313214173 , distance traveled: -1.9578733668476336 , average speed: -0.017798848789523942 , explore ratio: 0.09296299194568308\n",
      "Episode 1021 , steps =  52 , total reward: -12.83691210418257 , steps_avg: 284.6761252446184 , reward_avg: -16.793817612544903 , distance traveled: -0.2782437274348923 , average speed: -0.005350840912209467 , explore ratio: 0.09277917292258854\n",
      "Episode 1022 , steps =  59 , total reward: -11.673832348993667 , steps_avg: 284.455522971652 , reward_avg: -16.7888127393645 , distance traveled: -3.567429927885533 , average speed: -0.06046491403195819 , explore ratio: 0.09259571737137183\n",
      "Episode 1023 , steps =  60 , total reward: -1.8009728312368183 , steps_avg: 284.236328125 , reward_avg: -16.77417617695422 , distance traveled: 9.36984359364957 , average speed: 0.1561640598941595 , explore ratio: 0.09241262457332712\n",
      "Episode 1024 , steps =  69 , total reward: -0.026372411134959917 , steps_avg: 284.0263414634146 , reward_avg: -16.75783685620708 , distance traveled: 11.47268105238676 , average speed: 0.16627073988966318 , explore ratio: 0.09222989381116968\n",
      "Episode 1025 , steps =  120 , total reward: -18.038582423964215 , steps_avg: 283.8664717348928 , reward_avg: -16.759085146234135 , distance traveled: 1.4007706556282946 , average speed: 0.011673088796902455 , explore ratio: 0.0920475243690331\n",
      "Episode 1026 , steps =  568 , total reward: -1.5153089600805227 , steps_avg: 284.143135345667 , reward_avg: -16.74424213144723 , distance traveled: 93.70525660296902 , average speed: 0.1649740433150863 , explore ratio: 0.09186551553246648\n",
      "Episode 1027 , steps =  267 , total reward: 24.20233571140469 , steps_avg: 284.1264591439689 , reward_avg: -16.704410830043678 , distance traveled: 76.41489277437331 , average speed: 0.28619810027855175 , explore ratio: 0.09168386658843163\n",
      "Episode 1028 , steps =  142 , total reward: -3.07995266086982 , steps_avg: 283.9883381924198 , reward_avg: -16.691170345914255 , distance traveled: 21.870109698213632 , average speed: 0.15401485702967346 , explore ratio: 0.09150257682530026\n",
      "Episode 1029 , steps =  75 , total reward: -23.3212182658383 , steps_avg: 283.7854368932039 , reward_avg: -16.697607285642334 , distance traveled: -8.19325865395367 , average speed: -0.10924344871938227 , explore ratio: 0.09132164553285124\n",
      "Episode 1030 , steps =  87 , total reward: -11.877171755860875 , steps_avg: 283.5945683802134 , reward_avg: -16.692931790463113 , distance traveled: 2.9991220610216263 , average speed: 0.03447266736806467 , explore ratio: 0.09114107200226777\n",
      "Episode 1031 , steps =  274 , total reward: 1.0534181809002883 , steps_avg: 283.58527131782944 , reward_avg: -16.675735714909464 , distance traveled: 46.45941520525083 , average speed: 0.1695599095082147 , explore ratio: 0.09096085552613462\n",
      "Episode 1032 , steps =  47 , total reward: -1.5618237012152858 , steps_avg: 283.3562439496612 , reward_avg: -16.66110462873938 , distance traveled: 5.73822923541069 , average speed: 0.12208998373214233 , explore ratio: 0.09078099539843534\n",
      "Episode 1033 , steps =  291 , total reward: 11.001995704452163 , steps_avg: 283.3636363636364 , reward_avg: -16.63435114679239 , distance traveled: 64.76505143836141 , average speed: 0.22256031422117323 , explore ratio: 0.09060149091454954\n",
      "Episode 1034 , steps =  420 , total reward: 16.559758057665668 , steps_avg: 283.495652173913 , reward_avg: -16.602279543696294 , distance traveled: 92.96237877052278 , average speed: 0.22133899707267327 , explore ratio: 0.09042234137125008\n",
      "Episode 1035 , steps =  169 , total reward: 12.690850364200763 , steps_avg: 283.38513513513516 , reward_avg: -16.574004321777473 , distance traveled: 50.954634687392975 , average speed: 0.30150671412658564 , explore ratio: 0.09024354606670033\n",
      "Episode 1036 , steps =  116 , total reward: -4.88970232819332 , steps_avg: 283.2237222757956 , reward_avg: -16.562736913876236 , distance traveled: 15.694781641848385 , average speed: 0.13529984174007229 , explore ratio: 0.09006510430045146\n",
      "Episode 1037 , steps =  276 , total reward: 22.57257414382133 , steps_avg: 283.21676300578036 , reward_avg: -16.52503430206728 , distance traveled: 79.91192869548688 , average speed: 0.28953597353437277 , explore ratio: 0.08988701537343963\n",
      "Episode 1038 , steps =  109 , total reward: -20.524723211929174 , steps_avg: 283.04908565928775 , reward_avg: -16.528883858284665 , distance traveled: -3.5021550562977795 , average speed: -0.03212986290181449 , explore ratio: 0.08970927858798329\n",
      "Episode 1039 , steps =  278 , total reward: -3.5913152029806366 , steps_avg: 283.04423076923075 , reward_avg: -16.516443888423794 , distance traveled: 38.54752314671877 , average speed: 0.13866015520402433 , explore ratio: 0.08953189324778045\n",
      "Episode 1040 , steps =  74 , total reward: -18.25641764922331 , steps_avg: 282.84341978866473 , reward_avg: -16.51811533295866 , distance traveled: -4.210755289793014 , average speed: -0.05690209851071641 , explore ratio: 0.08935485865790593\n",
      "Episode 1041 , steps =  269 , total reward: -11.507820960868795 , steps_avg: 282.83013435700576 , reward_avg: -16.513306989031513 , distance traveled: 27.579841935820877 , average speed: 0.1025272934417133 , explore ratio: 0.08917817412480868\n",
      "Episode 1042 , steps =  63 , total reward: -0.21155567186946322 , steps_avg: 282.61936720997124 , reward_avg: -16.497677313751396 , distance traveled: 10.76555766284466 , average speed: 0.17088186766420096 , explore ratio: 0.08900183895630899\n",
      "Episode 1043 , steps =  209 , total reward: 6.083424438341811 , steps_avg: 282.5488505747126 , reward_avg: -16.476047905942877 , distance traveled: 42.27080646514893 , average speed: 0.2022526625126743 , explore ratio: 0.08882585246159586\n",
      "Episode 1044 , steps =  264 , total reward: -5.025900638971492 , steps_avg: 282.5311004784689 , reward_avg: -16.465090827218503 , distance traveled: 37.555453338660286 , average speed: 0.1422555050706829 , explore ratio: 0.08865021395122422\n",
      "Episode 1045 , steps =  114 , total reward: -35.032950763105106 , steps_avg: 282.3699808795411 , reward_avg: -16.482842127348416 , distance traveled: -21.93630148373544 , average speed: -0.19242369722574948 , explore ratio: 0.0884749227371123\n",
      "Episode 1046 , steps =  354 , total reward: 31.13761219838441 , steps_avg: 282.43839541547277 , reward_avg: -16.437359362949433 , distance traveled: 102.98514226349069 , average speed: 0.2909184809703127 , explore ratio: 0.08829997813253887\n",
      "Episode 1047 , steps =  84 , total reward: -1.2159538889477641 , steps_avg: 282.24904580152673 , reward_avg: -16.422835121084926 , distance traveled: 12.321277519203722 , average speed: 0.14668187522861573 , explore ratio: 0.08812537945214059\n",
      "Episode 1048 , steps =  197 , total reward: 10.668320019031553 , steps_avg: 282.1677788369876 , reward_avg: -16.3970094250505 , distance traveled: 46.617334856092924 , average speed: 0.2366362175436189 , explore ratio: 0.08795112601190931\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1049 , steps =  68 , total reward: 2.995636824291198 , steps_avg: 281.9638095238095 , reward_avg: -16.378540238146364 , distance traveled: 15.883293347954753 , average speed: 0.23357784335227577 , explore ratio: 0.0877772171291894\n",
      "Episode 1050 , steps =  210 , total reward: 9.839615136152123 , steps_avg: 281.895337773549 , reward_avg: -16.353594324374434 , distance traveled: 48.43573063820602 , average speed: 0.2306463363724096 , explore ratio: 0.08760365212267507\n",
      "Episode 1051 , steps =  278 , total reward: -18.871948306247617 , steps_avg: 281.8916349809886 , reward_avg: -16.355988196980775 , distance traveled: 40.756158857150034 , average speed: 0.14660488797535984 , explore ratio: 0.08743043031240769\n",
      "Episode 1052 , steps =  38 , total reward: -13.170086964518449 , steps_avg: 281.6600189933523 , reward_avg: -16.35296264975147 , distance traveled: -0.5836420688498765 , average speed: -0.015359001811838854 , explore ratio: 0.08725755101977313\n",
      "Episode 1053 , steps =  163 , total reward: -10.443377453250822 , steps_avg: 281.5474383301708 , reward_avg: -16.34735583267699 , distance traveled: 13.599366175155154 , average speed: 0.08343169432610524 , explore ratio: 0.08708501356749913\n",
      "Episode 1054 , steps =  58 , total reward: -16.3544521428744 , steps_avg: 281.3355450236967 , reward_avg: -16.347362559037364 , distance traveled: -3.1674633049964904 , average speed: -0.054611436293042936 , explore ratio: 0.08691281727965262\n",
      "Episode 1055 , steps =  223 , total reward: 36.726187881373434 , steps_avg: 281.280303030303 , reward_avg: -16.297103515059703 , distance traveled: 91.04033336587244 , average speed: 0.40825261599045937 , explore ratio: 0.08674096148163705\n",
      "Episode 1056 , steps =  120 , total reward: -4.9548078175230685 , steps_avg: 281.1277199621571 , reward_avg: -16.28637286633923 , distance traveled: 13.30457296550274 , average speed: 0.1108714413791895 , explore ratio: 0.08656944550018981\n",
      "Episode 1057 , steps =  68 , total reward: -22.038587559024492 , steps_avg: 280.92627599243855 , reward_avg: -16.29180974223024 , distance traveled: -4.5459255022555585 , average speed: -0.06685184562140527 , explore ratio: 0.08639826866337955\n",
      "Episode 1058 , steps =  526 , total reward: 29.708837652459724 , steps_avg: 281.15769593956566 , reward_avg: -16.248371925993517 , distance traveled: 125.67826869527347 , average speed: 0.2389320697628773 , explore ratio: 0.08622743030060352\n",
      "Episode 1059 , steps =  146 , total reward: 22.57693727361224 , steps_avg: 281.03018867924527 , reward_avg: -16.211744275805206 , distance traveled: 58.274164614281645 , average speed: 0.39913811379644965 , explore ratio: 0.08605692974258501\n",
      "Episode 1060 , steps =  379 , total reward: 2.653016061423966 , steps_avg: 281.1225259189444 , reward_avg: -16.193964105836095 , distance traveled: 68.05515675164757 , average speed: 0.17956505739220996 , explore ratio: 0.08588676632137068\n",
      "Episode 1061 , steps =  209 , total reward: 20.97608801177517 , steps_avg: 281.0546139359699 , reward_avg: -16.158964056761132 , distance traveled: 68.30717796016486 , average speed: 0.3268286026802147 , explore ratio: 0.08571693937032798\n",
      "Episode 1062 , steps =  59 , total reward: -0.32012394748193823 , steps_avg: 280.84571966133586 , reward_avg: -16.144063924955603 , distance traveled: 9.391005345582963 , average speed: 0.1591695821285248 , explore ratio: 0.08554744822414248\n",
      "Episode 1063 , steps =  57 , total reward: -8.40804196591427 , steps_avg: 280.6353383458647 , reward_avg: -16.136793227625677 , distance traveled: 0.9057886436954141 , average speed: 0.01589102883676165 , explore ratio: 0.08537829221881532\n",
      "Episode 1064 , steps =  146 , total reward: -10.764530841790144 , steps_avg: 280.5089201877934 , reward_avg: -16.131748849798598 , distance traveled: 16.683686019256715 , average speed: 0.11427182204970353 , explore ratio: 0.0852094706916606\n",
      "Episode 1065 , steps =  232 , total reward: 8.54223989141854 , steps_avg: 280.4634146341463 , reward_avg: -16.108602518896898 , distance traveled: 53.9634371870756 , average speed: 0.23260102235808447 , explore ratio: 0.08504098298130275\n",
      "Episode 1066 , steps =  345 , total reward: -19.679201346511476 , steps_avg: 280.52389878163075 , reward_avg: -16.111948909550705 , distance traveled: 30.147293656546097 , average speed: 0.08738345987404665 , explore ratio: 0.08487282842767396\n",
      "Episode 1067 , steps =  53 , total reward: -0.6961639002126935 , steps_avg: 280.31086142322096 , reward_avg: -16.09751465392398 , distance traveled: 8.066030284166336 , average speed: 0.15218925064464786 , explore ratio: 0.08470500637201163\n",
      "Episode 1068 , steps =  140 , total reward: 6.33766556529327 , steps_avg: 280.17960710944806 , reward_avg: -16.076527581688982 , distance traveled: 32.3325073108077 , average speed: 0.23094648079148355 , explore ratio: 0.08453751615685572\n",
      "Episode 1069 , steps =  227 , total reward: -16.47044606407721 , steps_avg: 280.12990654205606 , reward_avg: -16.07689572980336 , distance traveled: 13.12044456175994 , average speed: 0.057799315250043795 , explore ratio: 0.08437035712604621\n",
      "Episode 1070 , steps =  169 , total reward: 24.903498664027644 , steps_avg: 280.0261437908497 , reward_avg: -16.038632056233027 , distance traveled: 63.29658305207268 , average speed: 0.3745359943909626 , explore ratio: 0.08420352862472055\n",
      "Episode 1071 , steps =  71 , total reward: -11.477225614374511 , steps_avg: 279.8311567164179 , reward_avg: -16.034377012910397 , distance traveled: 0.7683485031500457 , average speed: 0.01082180990352177 , explore ratio: 0.08403702999931106\n",
      "Episode 1072 , steps =  345 , total reward: -17.772474901942996 , steps_avg: 279.8918918918919 , reward_avg: -16.035996861828412 , distance traveled: 40.3582441613171 , average speed: 0.11698041785889016 , explore ratio: 0.0838708605975424\n",
      "Episode 1073 , steps =  204 , total reward: -16.317471004676563 , steps_avg: 279.8212290502793 , reward_avg: -16.036258942035907 , distance traveled: 9.850436623579007 , average speed: 0.048286454037151996 , explore ratio: 0.08370501976842895\n",
      "Episode 1074 , steps =  59 , total reward: -8.687646290267512 , steps_avg: 279.6158139534884 , reward_avg: -16.029423023290075 , distance traveled: 3.93926494807005 , average speed: 0.06676720250966187 , explore ratio: 0.08353950686227236\n",
      "Episode 1075 , steps =  264 , total reward: -0.782888653038085 , steps_avg: 279.60130111524165 , reward_avg: -16.015253381682033 , distance traveled: 41.3051699113939 , average speed: 0.1564589769370981 , explore ratio: 0.08337432123065892\n",
      "Episode 1076 , steps =  169 , total reward: -0.3385496879946547 , steps_avg: 279.49860724233986 , reward_avg: -16.000697482245 , distance traveled: 29.002820937061916 , average speed: 0.17161432507137228 , explore ratio: 0.08320946222645707\n",
      "Episode 1077 , steps =  145 , total reward: 4.028679833651197 , steps_avg: 279.373840445269 , reward_avg: -15.98211735486476 , distance traveled: 31.0257925593853 , average speed: 0.2139709831681745 , explore ratio: 0.08304492920381484\n",
      "Episode 1078 , steps =  399 , total reward: 48.44193579562895 , steps_avg: 279.48470806302134 , reward_avg: -15.922410169368474 , distance traveled: 138.83753597036 , average speed: 0.34796374929914786 , explore ratio: 0.08288072151815731\n",
      "Episode 1079 , steps =  131 , total reward: -2.987053054563088 , steps_avg: 279.34722222222223 , reward_avg: -15.910432986854765 , distance traveled: 19.821776825487614 , average speed: 0.15131127347700468 , explore ratio: 0.08271683852618412\n",
      "Episode 1080 , steps =  278 , total reward: 16.69327432782016 , steps_avg: 279.3459759481961 , reward_avg: -15.880272295536843 , distance traveled: 71.74112464919688 , average speed: 0.2580615994575427 , explore ratio: 0.08255327958586693\n",
      "Episode 1081 , steps =  58 , total reward: -11.63107020561025 , steps_avg: 279.141404805915 , reward_avg: -15.876345121701421 , distance traveled: -3.7736919314134876 , average speed: -0.06506365398988771 , explore ratio: 0.0823900440564469\n",
      "Episode 1082 , steps =  372 , total reward: 16.16861085003302 , steps_avg: 279.2271468144044 , reward_avg: -15.84675605801561 , distance traveled: 83.24568737603724 , average speed: 0.22377872950547645 , explore ratio: 0.08222713129843218\n",
      "Episode 1083 , steps =  161 , total reward: 1.1139656821750061 , steps_avg: 279.1180811808118 , reward_avg: -15.83110963574606 , distance traveled: 30.352671131640676 , average speed: 0.1885259076499421 , explore ratio: 0.0820645406735954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1084 , steps =  68 , total reward: -0.3520836244809164 , steps_avg: 278.92350230414746 , reward_avg: -15.816843252325537 , distance traveled: 10.89011550039053 , average speed: 0.16014875735868428 , explore ratio: 0.08190227154497123\n",
      "Episode 1085 , steps =  58 , total reward: -0.6267290616693634 , steps_avg: 278.72007366482507 , reward_avg: -15.802856038521988 , distance traveled: 9.571640353202818 , average speed: 0.16502828195177274 , explore ratio: 0.08174032327685378\n",
      "Episode 1086 , steps =  256 , total reward: -3.9047293322080385 , steps_avg: 278.69917203311866 , reward_avg: -15.791910199785727 , distance traveled: 36.93748666584492 , average speed: 0.14428705728845673 , explore ratio: 0.08157869523479418\n",
      "Episode 1087 , steps =  177 , total reward: 6.209212646767477 , steps_avg: 278.60569852941177 , reward_avg: -15.771688579522353 , distance traveled: 38.501659765765076 , average speed: 0.2175235015014976 , explore ratio: 0.08141738678559808\n",
      "Episode 1088 , steps =  57 , total reward: -0.5957416287958639 , steps_avg: 278.40220385674934 , reward_avg: -15.757752907391296 , distance traveled: 9.69823645412922 , average speed: 0.17014449919524946 , explore ratio: 0.08125639729732319\n",
      "Episode 1089 , steps =  242 , total reward: 24.783822263529515 , steps_avg: 278.3688073394495 , reward_avg: -15.720558801729897 , distance traveled: 80.22432495899493 , average speed: 0.3315054750371691 , explore ratio: 0.08109572613927674\n",
      "Episode 1090 , steps =  129 , total reward: -22.092475790529175 , steps_avg: 278.23189734188816 , reward_avg: -15.726399238933197 , distance traveled: -2.125061187017708 , average speed: -0.01647334253502099 , explore ratio: 0.08093537268201308\n",
      "Episode 1091 , steps =  167 , total reward: 9.894831101121987 , steps_avg: 278.1300366300366 , reward_avg: -15.702936573786626 , distance traveled: 44.49345096298961 , average speed: 0.26642785007778214 , explore ratio: 0.08077533629733118\n",
      "Episode 1092 , steps =  128 , total reward: -2.1214764355874394 , steps_avg: 277.99268069533395 , reward_avg: -15.690510718216451 , distance traveled: 18.649991894066336 , average speed: 0.14570306167239325 , explore ratio: 0.08061561635827216\n",
      "Episode 1093 , steps =  56 , total reward: -1.1351278715127462 , steps_avg: 277.7897623400366 , reward_avg: -15.677205980696616 , distance traveled: 7.7429147833585725 , average speed: 0.13826633541711736 , explore ratio: 0.08045621223911688\n",
      "Episode 1094 , steps =  67 , total reward: -7.122412140173228 , steps_avg: 277.5972602739726 , reward_avg: -15.669393383581982 , distance traveled: 7.009491564631461 , average speed: 0.10461927708405167 , explore ratio: 0.08029712331538341\n",
      "Episode 1095 , steps =  120 , total reward: -8.322506679392736 , steps_avg: 277.4534671532847 , reward_avg: -15.662690019800786 , distance traveled: 9.733445536724759 , average speed: 0.08111204613937299 , explore ratio: 0.08013834896382468\n",
      "Episode 1096 , steps =  84 , total reward: 1.802387165329102 , steps_avg: 277.2771194165907 , reward_avg: -15.646769256642056 , distance traveled: 21.591030832529075 , average speed: 0.25703608133963185 , explore ratio: 0.07997988856242597\n",
      "Episode 1097 , steps =  80 , total reward: -20.265285754775007 , steps_avg: 277.09744990892534 , reward_avg: -15.650975555820681 , distance traveled: 5.018290020637214 , average speed: 0.06272862525796517 , explore ratio: 0.07982174149040246\n",
      "Episode 1098 , steps =  216 , total reward: -1.4921351213238054 , steps_avg: 277.04185623293904 , reward_avg: -15.638092170529964 , distance traveled: 35.99122522383927 , average speed: 0.16662604270295958 , explore ratio: 0.07966390712819686\n",
      "Episode 1099 , steps =  68 , total reward: 1.330208875028723 , steps_avg: 276.8518181818182 , reward_avg: -15.62266644230673 , distance traveled: 14.68981047749519 , average speed: 0.2160266246690469 , explore ratio: 0.07950638485747696\n",
      "Episode 1100 , steps =  77 , total reward: 1.809645333911598 , steps_avg: 276.67029972752044 , reward_avg: -15.606833279930509 , distance traveled: 16.99631779879331 , average speed: 0.2207313999843287 , explore ratio: 0.0793491740611332\n",
      "Episode 1101 , steps =  143 , total reward: -10.767076454600954 , steps_avg: 276.54900181488205 , reward_avg: -15.602441486078124 , distance traveled: 10.310993686169379 , average speed: 0.07210485095223342 , explore ratio: 0.07919227412327623\n",
      "Episode 1102 , steps =  291 , total reward: 24.36459567990338 , steps_avg: 276.56210335448776 , reward_avg: -15.566206638239517 , distance traveled: 81.1459380482998 , average speed: 0.27885202078453536 , explore ratio: 0.07903568442923453\n",
      "Episode 1103 , steps =  105 , total reward: -2.4942446689804463 , steps_avg: 276.40670289855075 , reward_avg: -15.554366092977508 , distance traveled: 15.090344033762808 , average speed: 0.14371756222631246 , explore ratio: 0.078879404365552\n",
      "Episode 1104 , steps =  73 , total reward: -2.0804665059944036 , steps_avg: 276.22262443438916 , reward_avg: -15.542172518690647 , distance traveled: 11.213243370652197 , average speed: 0.15360607357057804 , explore ratio: 0.07872343331998555\n",
      "Episode 1105 , steps =  114 , total reward: 2.5945279734004214 , steps_avg: 276.0759493670886 , reward_avg: -15.525774055316242 , distance traveled: 23.03368708373979 , average speed: 0.20204988669947183 , explore ratio: 0.07856777068150267\n",
      "Episode 1106 , steps =  68 , total reward: 1.9992481230782908 , steps_avg: 275.88798554652215 , reward_avg: -15.50994296030414 , distance traveled: 13.896069569885737 , average speed: 0.20435396426302554 , explore ratio: 0.0784124158402791\n",
      "Episode 1107 , steps =  57 , total reward: -1.4161059905427233 , steps_avg: 275.69043321299637 , reward_avg: -15.497222890836849 , distance traveled: 8.238775067925454 , average speed: 0.14453991347237638 , explore ratio: 0.0782573681876964\n",
      "Episode 1108 , steps =  418 , total reward: 23.26139255683804 , steps_avg: 275.8187556357078 , reward_avg: -15.462273733535067 , distance traveled: 101.95847426005642 , average speed: 0.24391979488051774 , explore ratio: 0.07810262711633956\n",
      "Episode 1109 , steps =  71 , total reward: -0.13973973531710682 , steps_avg: 275.6342342342342 , reward_avg: -15.448469648851988 , distance traveled: 13.929593691491755 , average speed: 0.19619146044354585 , explore ratio: 0.07794819201999464\n",
      "Episode 1110 , steps =  170 , total reward: -5.854659466737274 , steps_avg: 275.5391539153915 , reward_avg: -15.439834356158816 , distance traveled: 20.586795615646988 , average speed: 0.12109879773909993 , explore ratio: 0.07779406229364641\n",
      "Episode 1111 , steps =  349 , total reward: 10.470917411376389 , steps_avg: 275.60521582733816 , reward_avg: -15.416533320396644 , distance traveled: 78.28042221057696 , average speed: 0.22429920404176779 , explore ratio: 0.07764023733347593\n",
      "Episode 1112 , steps =  46 , total reward: -11.739712913580863 , steps_avg: 275.39892183288407 , reward_avg: -15.413229798018554 , distance traveled: -5.488760538697242 , average speed: -0.119320881276027 , explore ratio: 0.07748671653685821\n",
      "Episode 1113 , steps =  188 , total reward: -29.42826238544088 , steps_avg: 275.3204667863555 , reward_avg: -15.425810617217314 , distance traveled: -7.55756593286991 , average speed: -0.04019981879186122 , explore ratio: 0.07733349930235987\n",
      "Episode 1114 , steps =  42 , total reward: -13.398093519986297 , steps_avg: 275.11121076233184 , reward_avg: -15.423992036861053 , distance traveled: -5.483928483724593 , average speed: -0.1305697258029665 , explore ratio: 0.07718058502973676\n",
      "Episode 1115 , steps =  126 , total reward: -3.5603521903058004 , steps_avg: 274.97759856630825 , reward_avg: -15.413361535206436 , distance traveled: 16.923933634981513 , average speed: 0.1343169336109644 , explore ratio: 0.07702797311993162\n",
      "Episode 1116 , steps =  172 , total reward: 8.16559754038291 , steps_avg: 274.8854073410922 , reward_avg: -15.392252350716204 , distance traveled: 40.03958245016634 , average speed: 0.23278827005910666 , explore ratio: 0.0768756629750717\n",
      "Episode 1117 , steps =  163 , total reward: -0.8065088360142126 , steps_avg: 274.78533094812167 , reward_avg: -15.379206068502695 , distance traveled: 25.253924075961113 , average speed: 0.1549320495457737 , explore ratio: 0.07672365399846648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1118 , steps =  88 , total reward: -12.65304298431675 , steps_avg: 274.6184092940125 , reward_avg: -15.376769819097701 , distance traveled: 5.512530018612742 , average speed: 0.0626423865751448 , explore ratio: 0.07657194559460527\n",
      "Episode 1119 , steps =  127 , total reward: -6.700734505041204 , steps_avg: 274.48660714285717 , reward_avg: -15.369023358995864 , distance traveled: 11.852946008294822 , average speed: 0.09333028352988049 , explore ratio: 0.07642053716915494\n",
      "Episode 1120 , steps =  100 , total reward: -25.847539607808 , steps_avg: 274.33095450490634 , reward_avg: -15.37837083111791 , distance traveled: -2.566310363486409 , average speed: -0.02566310363486409 , explore ratio: 0.0762694281289575\n",
      "Episode 1121 , steps =  59 , total reward: -17.146891228670256 , steps_avg: 274.13903743315507 , reward_avg: -15.379947052506104 , distance traveled: -7.22235877007246 , average speed: -0.12241286050970271 , explore ratio: 0.07611861788202788\n",
      "Episode 1122 , steps =  136 , total reward: 0.4910227956672413 , steps_avg: 274.01602849510243 , reward_avg: -15.365814399034889 , distance traveled: 24.78303049606271 , average speed: 0.1822281654122258 , explore ratio: 0.07596810583755156\n",
      "Episode 1123 , steps =  96 , total reward: -17.540551111109544 , steps_avg: 273.8576512455516 , reward_avg: -15.367749218173746 , distance traveled: -3.927285436196252 , average speed: -0.04090922329371096 , explore ratio: 0.07581789140588223\n",
      "Episode 1124 , steps =  56 , total reward: -1.7915433354719243 , steps_avg: 273.664 , reward_avg: -15.355681479611343 , distance traveled: 6.939411871433259 , average speed: 0.12391806913273676 , explore ratio: 0.07566797399853953\n",
      "Episode 1125 , steps =  70 , total reward: 1.2528864785035463 , steps_avg: 273.4831261101243 , reward_avg: -15.34093141925778 , distance traveled: 13.565654599517583 , average speed: 0.19379506570739405 , explore ratio: 0.07551835302820671\n",
      "Episode 1126 , steps =  238 , total reward: -3.8041490639535276 , steps_avg: 273.4516415261757 , reward_avg: -15.33069470022024 , distance traveled: 32.69159728109837 , average speed: 0.1373596524415898 , explore ratio: 0.07536902790872836\n",
      "Episode 1127 , steps =  61 , total reward: -15.596803636847062 , steps_avg: 273.26329787234044 , reward_avg: -15.3309306123981 , distance traveled: -5.387753109522164 , average speed: -0.08832382146757646 , explore ratio: 0.0752199980551081\n",
      "Episode 1128 , steps =  53 , total reward: -0.39268684757314737 , steps_avg: 273.0682019486271 , reward_avg: -15.317699218452288 , distance traveled: 8.652862100601196 , average speed: 0.1632615490679471 , explore ratio: 0.07507126288350624\n",
      "Episode 1129 , steps =  96 , total reward: 1.3604951194878674 , steps_avg: 272.91150442477874 , reward_avg: -15.30293975443641 , distance traveled: 20.709630164355037 , average speed: 0.21572531421203164 , explore ratio: 0.07492282181123759\n",
      "Episode 1130 , steps =  158 , total reward: 6.767555479114867 , steps_avg: 272.8099027409372 , reward_avg: -15.28342561187801 , distance traveled: 35.501956096405635 , average speed: 0.22469592466079516 , explore ratio: 0.07477467425676909\n",
      "Episode 1131 , steps =  175 , total reward: 14.35466486654554 , steps_avg: 272.72349823321554 , reward_avg: -15.257243553151486 , distance traveled: 50.71675135452302 , average speed: 0.28981000774013155 , explore ratio: 0.07462681963971758\n",
      "Episode 1132 , steps =  150 , total reward: 17.995365852120653 , steps_avg: 272.6151809355693 , reward_avg: -15.227894383332185 , distance traveled: 49.650822281241425 , average speed: 0.33100548187494283 , explore ratio: 0.07447925738084751\n",
      "Episode 1133 , steps =  81 , total reward: -2.1021851080327076 , steps_avg: 272.4462081128748 , reward_avg: -15.216319683794882 , distance traveled: 10.531263471934945 , average speed: 0.13001559841894994 , explore ratio: 0.07433198690206867\n",
      "Episode 1134 , steps =  122 , total reward: 12.649983722099408 , steps_avg: 272.3136563876652 , reward_avg: -15.191767874626692 , distance traveled: 39.263500599637624 , average speed: 0.32183197212817727 , explore ratio: 0.07418500762643394\n",
      "Episode 1135 , steps =  63 , total reward: -23.789144933981824 , steps_avg: 272.1294014084507 , reward_avg: -15.199335988235278 , distance traveled: -11.26786407709122 , average speed: -0.17885498535065428 , explore ratio: 0.074038318978137\n",
      "Episode 1136 , steps =  203 , total reward: 4.786969057109808 , steps_avg: 272.06860158311343 , reward_avg: -15.181757883534008 , distance traveled: 42.00981723167002 , average speed: 0.20694491247128088 , explore ratio: 0.07389192038251009\n",
      "Episode 1137 , steps =  54 , total reward: -11.632645701469858 , steps_avg: 271.8769771528998 , reward_avg: -15.178639155781758 , distance traveled: -1.0661659229546776 , average speed: -0.019743813388049584 , explore ratio: 0.0737458112660218\n",
      "Episode 1138 , steps =  56 , total reward: -1.2330922948271046 , steps_avg: 271.68744512730467 , reward_avg: -15.166395479872225 , distance traveled: 9.787749774456023 , average speed: 0.17478124597242897 , explore ratio: 0.07359999105627472\n",
      "Episode 1139 , steps =  219 , total reward: 38.44718016595694 , steps_avg: 271.64122807017543 , reward_avg: -15.119366027551322 , distance traveled: 93.05786287263035 , average speed: 0.4249217482768509 , explore ratio: 0.07345445918200334\n",
      "Episode 1140 , steps =  291 , total reward: -2.419837304584572 , steps_avg: 271.65819456617004 , reward_avg: -15.108235853385706 , distance traveled: 45.513347002118806 , average speed: 0.15640325430281377 , explore ratio: 0.07330921507307167\n",
      "Episode 1141 , steps =  66 , total reward: -25.872737231066456 , steps_avg: 271.47810858143606 , reward_avg: -15.117661861597337 , distance traveled: -14.204575209617609 , average speed: -0.21522083650935772 , explore ratio: 0.07316425816047109\n",
      "Episode 1142 , steps =  54 , total reward: -7.076862586465357 , steps_avg: 271.2878390201225 , reward_avg: -15.110627041584099 , distance traveled: 2.6901891911029807 , average speed: 0.049818318353758904 , explore ratio: 0.0730195878763181\n",
      "Episode 1143 , steps =  64 , total reward: -2.8962510196200313 , steps_avg: 271.10664335664336 , reward_avg: -15.099950139466998 , distance traveled: 6.80064554773271 , average speed: 0.1062600866833236 , explore ratio: 0.0728752036538521\n",
      "Episode 1144 , steps =  98 , total reward: -16.454665519384672 , steps_avg: 270.95545851528385 , reward_avg: -15.101133297004043 , distance traveled: -4.621305761109107 , average speed: -0.04715618123580721 , explore ratio: 0.07273110492743316\n",
      "Episode 1145 , steps =  230 , total reward: 22.886702024893196 , steps_avg: 270.9197207678883 , reward_avg: -15.067985098642875 , distance traveled: 73.59365549907085 , average speed: 0.3199724152133515 , explore ratio: 0.07258729113253982\n",
      "Episode 1146 , steps =  102 , total reward: -19.504175069039704 , steps_avg: 270.7724498692241 , reward_avg: -15.071852744650197 , distance traveled: -5.103493244047279 , average speed: -0.05003424749065959 , explore ratio: 0.07244376170576687\n",
      "Episode 1147 , steps =  73 , total reward: -16.561702751008795 , steps_avg: 270.6001742160279 , reward_avg: -15.07315052340138 , distance traveled: -4.719466961547733 , average speed: -0.06465023234996894 , explore ratio: 0.07230051608482313\n",
      "Episode 1148 , steps =  117 , total reward: 11.921086178705092 , steps_avg: 270.46649260226286 , reward_avg: -15.04965684480947 , distance traveled: 37.3562758514285 , average speed: 0.31928440898656835 , explore ratio: 0.07215755370852926\n",
      "Episode 1149 , steps =  113 , total reward: -3.402705612493686 , steps_avg: 270.3295652173913 , reward_avg: -15.039529061129192 , distance traveled: 14.24720814429224 , average speed: 0.1260814880025862 , explore ratio: 0.07201487401681556\n",
      "Episode 1150 , steps =  62 , total reward: 0.842232302455853 , steps_avg: 270.1485664639444 , reward_avg: -15.02573083231635 , distance traveled: 12.484020459651948 , average speed: 0.20135516870406367 , explore ratio: 0.07187247645071977\n",
      "Episode 1151 , steps =  171 , total reward: 1.8817211518982884 , steps_avg: 270.0625 , reward_avg: -15.011054224691163 , distance traveled: 34.10211956377142 , average speed: 0.19942759978813696 , explore ratio: 0.07173036045238491\n",
      "Episode 1152 , steps =  125 , total reward: -3.3723920061097896 , steps_avg: 269.9366869037294 , reward_avg: -15.000959981656834 , distance traveled: 16.88420437697321 , average speed: 0.13507363501578568 , explore ratio: 0.07158852546505705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1153 , steps =  142 , total reward: 3.579465609159313 , steps_avg: 269.8258232235702 , reward_avg: -14.984859092929955 , distance traveled: 30.081652339920407 , average speed: 0.21184262211211555 , explore ratio: 0.07144697093308314\n",
      "Episode 1154 , steps =  148 , total reward: -8.794701098756876 , steps_avg: 269.7203463203463 , reward_avg: -14.979499648779159 , distance traveled: 13.124078177497715 , average speed: 0.08867620390201159 , explore ratio: 0.07130569630190886\n",
      "Episode 1155 , steps =  162 , total reward: 2.3916691455220103 , steps_avg: 269.6271626297578 , reward_avg: -14.964472686154329 , distance traveled: 30.88400170342995 , average speed: 0.19064198582364167 , explore ratio: 0.07116470101807644\n",
      "Episode 1156 , steps =  41 , total reward: -12.911590793987742 , steps_avg: 269.42955920484013 , reward_avg: -14.962698371640789 , distance traveled: -1.7482269921898839 , average speed: -0.042639682736338634 , explore ratio: 0.07102398452922246\n",
      "Episode 1157 , steps =  110 , total reward: -4.700000867871577 , steps_avg: 269.29188255613127 , reward_avg: -14.953835938563268 , distance traveled: 13.156427757516505 , average speed: 0.1196038887046955 , explore ratio: 0.0708835462840757\n",
      "Episode 1158 , steps =  102 , total reward: 7.9965490966513695 , steps_avg: 269.1475409836066 , reward_avg: -14.934034053286982 , distance traveled: 29.431628688275815 , average speed: 0.2885453792968217 , explore ratio: 0.07074338573245502\n",
      "Episode 1159 , steps =  69 , total reward: -1.4445814781965072 , steps_avg: 268.975 , reward_avg: -14.922405214860179 , distance traveled: 9.725054812878371 , average speed: 0.14094282337504885 , explore ratio: 0.07060350232526716\n",
      "Episode 1160 , steps =  54 , total reward: -0.14417888673208673 , steps_avg: 268.7898363479759 , reward_avg: -14.909676337747236 , distance traveled: 9.68195969939232 , average speed: 0.17929554998874664 , explore ratio: 0.07046389551450459\n",
      "Episode 1161 , steps =  344 , total reward: -31.954923968645982 , steps_avg: 268.85456110154905 , reward_avg: -14.924345225553518 , distance traveled: 10.949822211004793 , average speed: 0.031830878520362774 , explore ratio: 0.07032456475324338\n",
      "Episode 1162 , steps =  48 , total reward: -26.140624448173384 , steps_avg: 268.664660361135 , reward_avg: -14.93398948971742 , distance traveled: -5.423196829073131 , average speed: -0.1129832672723569 , explore ratio: 0.07018550949564105\n",
      "Episode 1163 , steps =  123 , total reward: 7.715353955228501 , steps_avg: 268.53951890034364 , reward_avg: -14.914531290881557 , distance traveled: 30.98021422214806 , average speed: 0.25187166034266717 , explore ratio: 0.07004672919693444\n",
      "Episode 1164 , steps =  62 , total reward: -5.886979870059843 , steps_avg: 268.36223175965665 , reward_avg: -14.906782319704885 , distance traveled: 3.183777727000415 , average speed: 0.05135125366129702 , explore ratio: 0.06990822331343759\n",
      "Episode 1165 , steps =  874 , total reward: -44.90691117736102 , steps_avg: 268.8816466552316 , reward_avg: -14.932511418210593 , distance traveled: 81.41016059232875 , average speed: 0.09314663683332809 , explore ratio: 0.06976999130253954\n",
      "Episode 1166 , steps =  134 , total reward: -5.730168378550568 , steps_avg: 268.7660668380463 , reward_avg: -14.92462594859649 , distance traveled: 15.781579418494218 , average speed: 0.11777298073503148 , explore ratio: 0.06963203262270229\n",
      "Episode 1167 , steps =  413 , total reward: 6.605422167991588 , steps_avg: 268.88955479452056 , reward_avg: -14.9061926882227 , distance traveled: 73.48808965045028 , average speed: 0.1779372630761508 , explore ratio: 0.06949434673345864\n",
      "Episode 1168 , steps =  58 , total reward: -0.13059902035383414 , steps_avg: 268.70915312232677 , reward_avg: -14.89355317268132 , distance traveled: 10.835226509571072 , average speed: 0.1868142501650185 , explore ratio: 0.06935693309541005\n",
      "Episode 1169 , steps =  281 , total reward: -5.480672531905295 , steps_avg: 268.7196581196581 , reward_avg: -14.885507975552454 , distance traveled: 38.58980983100831 , average speed: 0.13733028409611497 , explore ratio: 0.06921979117022459\n",
      "Episode 1170 , steps =  556 , total reward: 44.47156911495003 , steps_avg: 268.9649871904355 , reward_avg: -14.834818755150657 , distance traveled: 153.42283688329155 , average speed: 0.2759403541066395 , explore ratio: 0.06908292042063476\n",
      "Episode 1171 , steps =  67 , total reward: 0.7557014391018668 , steps_avg: 268.79266211604096 , reward_avg: -14.821516263517335 , distance traveled: 13.016967085003856 , average speed: 0.19428309082095307 , explore ratio: 0.06894632031043543\n",
      "Episode 1172 , steps =  64 , total reward: -0.32736184156064757 , steps_avg: 268.618073316283 , reward_avg: -14.809159780634168 , distance traveled: 11.153740594983098 , average speed: 0.1742771967966109 , explore ratio: 0.06880999030448175\n",
      "Episode 1173 , steps =  156 , total reward: -12.29242145488785 , steps_avg: 268.5221465076661 , reward_avg: -14.807016051225526 , distance traveled: 11.15325816173572 , average speed: 0.07149524462651102 , explore ratio: 0.06867392986868699\n",
      "Episode 1174 , steps =  109 , total reward: 8.62978331027366 , steps_avg: 268.3863829787234 , reward_avg: -14.787069839002974 , distance traveled: 33.02195485979319 , average speed: 0.30295371431002927 , explore ratio: 0.06853813847002052\n",
      "Episode 1175 , steps =  73 , total reward: -16.499101700056965 , steps_avg: 268.2202380952381 , reward_avg: -14.788525648408632 , distance traveled: -5.143656881600618 , average speed: -0.07046105317261121 , explore ratio: 0.06840261557650566\n",
      "Episode 1176 , steps =  92 , total reward: -26.447551260695484 , steps_avg: 268.07051826677997 , reward_avg: -14.798431362607687 , distance traveled: -12.296287938896564 , average speed: -0.1336553036836583 , explore ratio: 0.06826736065721767\n",
      "Episode 1177 , steps =  172 , total reward: 4.07331726003499 , steps_avg: 267.98896434634975 , reward_avg: -14.782411202486598 , distance traveled: 34.97060904029757 , average speed: 0.2033174944203347 , explore ratio: 0.06813237318228157\n",
      "Episode 1178 , steps =  100 , total reward: 4.2988918287741615 , steps_avg: 267.8464800678541 , reward_avg: -14.766226891179334 , distance traveled: 23.050198946893218 , average speed: 0.2305019894689322 , explore ratio: 0.06799765262287018\n",
      "Episode 1179 , steps =  61 , total reward: -0.7309325173820094 , steps_avg: 267.67118644067796 , reward_avg: -14.754332573913407 , distance traveled: 10.259420875310898 , average speed: 0.16818722746411308 , explore ratio: 0.06786319845120194\n",
      "Episode 1180 , steps =  195 , total reward: -7.2433826141990885 , steps_avg: 267.6096528365792 , reward_avg: -14.747972751762926 , distance traveled: 25.328638839572655 , average speed: 0.12989045558755208 , explore ratio: 0.06772901014053892\n",
      "Episode 1181 , steps =  229 , total reward: 15.377344816129632 , steps_avg: 267.57698815566835 , reward_avg: -14.722486019471985 , distance traveled: 59.29006101043896 , average speed: 0.2589085633643623 , explore ratio: 0.06759508716518473\n",
      "Episode 1182 , steps =  50 , total reward: -2.278949397141115 , steps_avg: 267.39306846999153 , reward_avg: -14.71196739172699 , distance traveled: 5.852862183451652 , average speed: 0.11705724366903304 , explore ratio: 0.06746142900048242\n",
      "Episode 1183 , steps =  174 , total reward: -4.426831110152742 , steps_avg: 267.31418918918916 , reward_avg: -14.703280621218903 , distance traveled: 22.717425974719223 , average speed: 0.13055991939493805 , explore ratio: 0.06732803512281252\n",
      "Episode 1184 , steps =  272 , total reward: -18.735687770156606 , steps_avg: 267.31814345991563 , reward_avg: -14.706683496450074 , distance traveled: 17.375181658174835 , average speed: 0.06387934433152513 , explore ratio: 0.0671949050095909\n",
      "Episode 1185 , steps =  64 , total reward: -7.243653610434391 , steps_avg: 267.1467116357504 , reward_avg: -14.700390891149894 , distance traveled: 3.5321944659948348 , average speed: 0.05519053853116929 , explore ratio: 0.06706203813926673\n",
      "Episode 1186 , steps =  226 , total reward: 24.52819019843698 , steps_avg: 267.11204717775905 , reward_avg: -14.66734238138613 , distance traveled: 72.68849399093538 , average speed: 0.32163050438466984 , explore ratio: 0.06692943399132051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1187 , steps =  112 , total reward: 2.7857958493418864 , steps_avg: 266.98148148148147 , reward_avg: -14.652651187589221 , distance traveled: 23.92742314204573 , average speed: 0.2136377066254083 , explore ratio: 0.06679709204626195\n",
      "Episode 1188 , steps =  319 , total reward: 32.28638023809033 , steps_avg: 267.02523128679564 , reward_avg: -14.613173448795544 , distance traveled: 100.81335556374859 , average speed: 0.3160293277860457 , explore ratio: 0.06666501178562798\n",
      "Episode 1189 , steps =  46 , total reward: -2.6072698902692646 , steps_avg: 266.8394957983193 , reward_avg: -14.60308445420855 , distance traveled: 4.197095164060592 , average speed: 0.09124119921870852 , explore ratio: 0.06653319269198069\n",
      "Episode 1190 , steps =  472 , total reward: 39.22952879610219 , steps_avg: 267.01175482787573 , reward_avg: -14.557884946861522 , distance traveled: 127.90229179414925 , average speed: 0.27097943176726536 , explore ratio: 0.06640163424890533\n",
      "Episode 1191 , steps =  66 , total reward: -15.825574448230991 , steps_avg: 266.84312080536915 , reward_avg: -14.558948444765354 , distance traveled: -5.083488556109368 , average speed: -0.07702255388044497 , explore ratio: 0.06627033594100828\n",
      "Episode 1192 , steps =  60 , total reward: -4.009461660881833 , steps_avg: 266.66974015088016 , reward_avg: -14.550105622649776 , distance traveled: 7.6866880986001345 , average speed: 0.12811146831000225 , explore ratio: 0.06613929725391503\n",
      "Episode 1193 , steps =  237 , total reward: 10.396516705124936 , steps_avg: 266.64489112227807 , reward_avg: -14.529212304117301 , distance traveled: 56.535062844827785 , average speed: 0.23854456896551807 , explore ratio: 0.06600851767426813\n",
      "Episode 1194 , steps =  65 , total reward: -7.082899899793177 , steps_avg: 266.4761506276151 , reward_avg: -14.522981080347993 , distance traveled: 4.26375151053071 , average speed: 0.06559617708508785 , explore ratio: 0.06587799668972524\n",
      "Episode 1195 , steps =  53 , total reward: -5.248400607519472 , steps_avg: 266.29765886287623 , reward_avg: -14.515226414400813 , distance traveled: 5.360754818469286 , average speed: 0.10114631732960917 , explore ratio: 0.0657477337889571\n",
      "Episode 1196 , steps =  63 , total reward: -1.1506798090853996 , steps_avg: 266.1278195488722 , reward_avg: -14.504061379642822 , distance traveled: 12.380496535599233 , average speed: 0.19651581802538465 , explore ratio: 0.06561772846164549\n",
      "Episode 1197 , steps =  251 , total reward: 40.70585380583243 , steps_avg: 266.1151919866444 , reward_avg: -14.457976308536415 , distance traveled: 103.92859030690049 , average speed: 0.41405812871275094 , explore ratio: 0.06548798019848126\n",
      "Episode 1198 , steps =  236 , total reward: 16.142754255563005 , steps_avg: 266.0900750625521 , reward_avg: -14.432454431502137 , distance traveled: 62.953382810680765 , average speed: 0.26675162207915576 , explore ratio: 0.06535848849116237\n",
      "Episode 1199 , steps =  65 , total reward: -2.0623187774078318 , steps_avg: 265.9225 , reward_avg: -14.422145985123725 , distance traveled: 8.761120249629018 , average speed: 0.13478646537890795 , explore ratio: 0.06522925283239182\n",
      "Episode 1200 , steps =  401 , total reward: 83.97427470396772 , steps_avg: 266.03497085761865 , reward_avg: -14.340217241835557 , distance traveled: 184.42853764817133 , average speed: 0.45992154026975396 , explore ratio: 0.06510027271587575\n",
      "Episode 1201 , steps =  343 , total reward: 45.22391723321673 , steps_avg: 266.0990016638935 , reward_avg: -14.290663053420372 , distance traveled: 120.63114611025895 , average speed: 0.35169430352845177 , explore ratio: 0.06497154763632138\n",
      "Episode 1202 , steps =  75 , total reward: -4.732192693225425 , steps_avg: 265.94014962593513 , reward_avg: -14.282717525273908 , distance traveled: 8.370799513247329 , average speed: 0.11161066017663106 , explore ratio: 0.06484307708943507\n",
      "Episode 1203 , steps =  474 , total reward: 53.90376762524357 , steps_avg: 266.1129568106312 , reward_avg: -14.226084231959526 , distance traveled: 150.3716182310879 , average speed: 0.3172397009094681 , explore ratio: 0.06471486057192036\n",
      "Episode 1204 , steps =  56 , total reward: -2.1120904818903687 , steps_avg: 265.93858921161825 , reward_avg: -14.216031125112995 , distance traveled: 8.819740371890365 , average speed: 0.15749536378375653 , explore ratio: 0.06458689758147594\n",
      "Episode 1205 , steps =  54 , total reward: -1.539871900645395 , steps_avg: 265.76285240464347 , reward_avg: -14.205520213649919 , distance traveled: 7.897797928154468 , average speed: 0.1462555171880457 , explore ratio: 0.06445918761679376\n",
      "Episode 1206 , steps =  88 , total reward: -16.033728462358944 , steps_avg: 265.6155758077879 , reward_avg: -14.207034884941312 , distance traveled: 1.0323040945641697 , average speed: 0.011730728347320111 , explore ratio: 0.06433173017755697\n",
      "Episode 1207 , steps =  52 , total reward: -0.7056626978789774 , steps_avg: 265.4387417218543 , reward_avg: -14.195858252336127 , distance traveled: 8.245438392162324 , average speed: 0.15856612292619854 , explore ratio: 0.06420452476443807\n",
      "Episode 1208 , steps =  101 , total reward: -6.985316535955924 , steps_avg: 265.30272952853596 , reward_avg: -14.189894197980147 , distance traveled: 9.697556948773563 , average speed: 0.09601541533439172 , explore ratio: 0.06407757087909685\n",
      "Episode 1209 , steps =  66 , total reward: -4.426057683479049 , steps_avg: 265.1380165289256 , reward_avg: -14.181824911604526 , distance traveled: 6.100133267480414 , average speed: 0.09242626162849113 , explore ratio: 0.06395086802417853\n",
      "Episode 1210 , steps =  56 , total reward: -1.0285111528399078 , steps_avg: 264.9653179190751 , reward_avg: -14.170963380837584 , distance traveled: 7.710641849040984 , average speed: 0.137690033018589 , explore ratio: 0.06382441570331174\n",
      "Episode 1211 , steps =  119 , total reward: 3.0017264603990945 , steps_avg: 264.8448844884488 , reward_avg: -14.156794494829967 , distance traveled: 28.65538399547338 , average speed: 0.24080154618044855 , explore ratio: 0.06369821342110661\n",
      "Episode 1212 , steps =  81 , total reward: -1.7041110501668184 , steps_avg: 264.6933223413026 , reward_avg: -14.146528473853328 , distance traveled: 11.923442037105557 , average speed: 0.14720298811241428 , explore ratio: 0.06357226068315282\n",
      "Episode 1213 , steps =  210 , total reward: 9.959704762240856 , steps_avg: 264.6482701812191 , reward_avg: -14.126671609573183 , distance traveled: 51.3882232148247 , average speed: 0.24470582483249856 , explore ratio: 0.06344655699601766\n",
      "Episode 1214 , steps =  145 , total reward: 5.135571294026439 , steps_avg: 264.54979423868315 , reward_avg: -14.110817911710138 , distance traveled: 30.412891876772033 , average speed: 0.20974408190877264 , explore ratio: 0.06332110186724411\n",
      "Episode 1215 , steps =  180 , total reward: 18.00362346130734 , steps_avg: 264.48026315789474 , reward_avg: -14.084408009265223 , distance traveled: 59.400285990005365 , average speed: 0.3300015888333631 , explore ratio: 0.06319589480534892\n",
      "Episode 1216 , steps =  103 , total reward: -13.274262838517942 , steps_avg: 264.34757600657355 , reward_avg: -14.083742318903063 , distance traveled: 3.630127063309773 , average speed: 0.03524395207096867 , explore ratio: 0.06307093531982061\n",
      "Episode 1217 , steps =  290 , total reward: 6.996517507663589 , steps_avg: 264.36863711001644 , reward_avg: -14.066435044825424 , distance traveled: 55.78413286026563 , average speed: 0.19235907882850217 , explore ratio: 0.06294622292111766\n",
      "Episode 1218 , steps =  76 , total reward: 4.341547317612292 , steps_avg: 264.214109926169 , reward_avg: -14.051334156915301 , distance traveled: 19.446356733441345 , average speed: 0.2558731149137019 , explore ratio: 0.06282175712066654\n",
      "Episode 1219 , steps =  138 , total reward: 5.580880915264288 , steps_avg: 264.1106557377049 , reward_avg: -14.03524217734794 , distance traveled: 33.020760612487784 , average speed: 0.23928087400353468 , explore ratio: 0.06269753743085976\n",
      "Episode 1220 , steps =  180 , total reward: 21.892521420555802 , steps_avg: 264.04176904176904 , reward_avg: -14.005817309536392 , distance traveled: 60.76622454978527 , average speed: 0.33759013638769597 , explore ratio: 0.06257356336505401\n",
      "Episode 1221 , steps =  292 , total reward: 35.26880611597615 , steps_avg: 264.0646481178396 , reward_avg: -13.96549437710962 , distance traveled: 100.79016354757827 , average speed: 0.34517179297115846 , explore ratio: 0.062449834437568234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1222 , steps =  91 , total reward: 6.351920345691339 , steps_avg: 263.9231398201145 , reward_avg: -13.948881609552139 , distance traveled: 25.91750805149787 , average speed: 0.28480778078569086 , explore ratio: 0.06232635016368173\n",
      "Episode 1223 , steps =  140 , total reward: 3.1270545144565403 , steps_avg: 263.8218954248366 , reward_avg: -13.934930681346248 , distance traveled: 28.398258878141643 , average speed: 0.2028447062724403 , explore ratio: 0.06220311005963226\n",
      "Episode 1224 , steps =  94 , total reward: 4.275863632796951 , steps_avg: 263.68326530612245 , reward_avg: -13.92006472680409 , distance traveled: 23.233494613319632 , average speed: 0.24716483631191097 , explore ratio: 0.06208011364261414\n",
      "Episode 1225 , steps =  44 , total reward: -14.41147067296195 , steps_avg: 263.5040783034258 , reward_avg: -13.920465547314821 , distance traveled: -1.0186210709251466 , average speed: -0.023150478884662425 , explore ratio: 0.061957360430776355\n",
      "Episode 1226 , steps =  235 , total reward: 9.696503338220817 , steps_avg: 263.48084759576204 , reward_avg: -13.90121781391178 , distance traveled: 53.884198556895996 , average speed: 0.22929446194423828 , explore ratio: 0.061834849943220666\n",
      "Episode 1227 , steps =  202 , total reward: -7.22769597436862 , steps_avg: 263.43078175895766 , reward_avg: -13.895783349873064 , distance traveled: 23.255819473189188 , average speed: 0.11512781917420391 , explore ratio: 0.061712581699999734\n",
      "Episode 1228 , steps =  52 , total reward: -0.686488198174787 , steps_avg: 263.2587469487388 , reward_avg: -13.885035347308621 , distance traveled: 7.822883027493953 , average speed: 0.15044005822103756 , explore ratio: 0.06159055522211525\n",
      "Episode 1229 , steps =  56 , total reward: -0.7579435692739959 , steps_avg: 263.090243902439 , reward_avg: -13.874362914968758 , distance traveled: 11.693222181200982 , average speed: 0.20880753895001752 , explore ratio: 0.061468770031516025\n",
      "Episode 1230 , steps =  59 , total reward: 1.0513590842187406 , steps_avg: 262.92445166531274 , reward_avg: -13.862238039258612 , distance traveled: 11.630619571208955 , average speed: 0.19712914527472805 , explore ratio: 0.06134722565109615\n",
      "Episode 1231 , steps =  148 , total reward: 14.804514903767028 , steps_avg: 262.83116883116884 , reward_avg: -13.838969570960701 , distance traveled: 47.57370307881384 , average speed: 0.32144393972171514 , explore ratio: 0.061225921604693104\n",
      "Episode 1232 , steps =  257 , total reward: 26.402946863643766 , steps_avg: 262.8264395782644 , reward_avg: -13.80633216914837 , distance traveled: 80.98651568390426 , average speed: 0.31512262912025 , explore ratio: 0.06110485741708592\n",
      "Episode 1233 , steps =  430 , total reward: -28.434095483229598 , steps_avg: 262.9619124797407 , reward_avg: -13.81818611024568 , distance traveled: 30.292034216764147 , average speed: 0.07044659120177708 , explore ratio: 0.06098403261399328\n",
      "Episode 1234 , steps =  189 , total reward: -17.32729649285038 , steps_avg: 262.902024291498 , reward_avg: -13.821027495170863 , distance traveled: 5.8425999320112165 , average speed: 0.0309132271534985 , explore ratio: 0.06086344672207169\n",
      "Episode 1235 , steps =  155 , total reward: -1.0436568326130686 , steps_avg: 262.81472491909386 , reward_avg: -13.810689816641288 , distance traveled: 24.861240494856613 , average speed: 0.16039509996681686 , explore ratio: 0.060743099268913615\n",
      "Episode 1236 , steps =  68 , total reward: 2.3156368201623274 , steps_avg: 262.65723524656426 , reward_avg: -13.797653174250986 , distance traveled: 15.211802828907972 , average speed: 0.22370298277805842 , explore ratio: 0.060622989783045624\n",
      "Episode 1237 , steps =  245 , total reward: 13.07622558774424 , steps_avg: 262.64297253634896 , reward_avg: -13.775945679289762 , distance traveled: 60.004272143058465 , average speed: 0.24491539650227945 , explore ratio: 0.06050311779392655\n",
      "Episode 1238 , steps =  61 , total reward: -2.1474720682868105 , steps_avg: 262.48022598870057 , reward_avg: -13.766560309143674 , distance traveled: 9.497047111988067 , average speed: 0.15568929691783717 , explore ratio: 0.060383482831945647\n",
      "Episode 1239 , steps =  84 , total reward: -3.002778450746094 , steps_avg: 262.3362903225806 , reward_avg: -13.757879839903028 , distance traveled: 12.470934335337953 , average speed: 0.1484635039921185 , explore ratio: 0.06026408442842073\n",
      "Episode 1240 , steps =  60 , total reward: 0.06652759290300035 , steps_avg: 262.1732473811442 , reward_avg: -13.746740107886264 , distance traveled: 9.901273224055766 , average speed: 0.16502122040092942 , explore ratio: 0.06014492211559638\n",
      "Episode 1241 , steps =  174 , total reward: -11.894275787996145 , steps_avg: 262.1022544283414 , reward_avg: -13.745248590720491 , distance traveled: 12.276269476935267 , average speed: 0.07055327285594981 , explore ratio: 0.060025995426642074\n",
      "Episode 1242 , steps =  134 , total reward: 6.265025547781332 , steps_avg: 261.99919549477073 , reward_avg: -13.729150220536662 , distance traveled: 31.373133505582793 , average speed: 0.23412786198196114 , explore ratio: 0.05990730389565037\n",
      "Episode 1243 , steps =  45 , total reward: -26.173915657031657 , steps_avg: 261.8247588424437 , reward_avg: -13.739154051273392 , distance traveled: -5.693807976767421 , average speed: -0.12652906615038714 , explore ratio: 0.05978884705763508\n",
      "Episode 1244 , steps =  147 , total reward: -3.9883795141081126 , steps_avg: 261.73253012048195 , reward_avg: -13.731322103853984 , distance traveled: 18.976756507381797 , average speed: 0.12909358168286936 , explore ratio: 0.05967062444852947\n",
      "Episode 1245 , steps =  321 , total reward: 36.879842355982625 , steps_avg: 261.7800963081862 , reward_avg: -13.690703191767437 , distance traveled: 105.24805675727309 , average speed: 0.32787556622203456 , explore ratio: 0.05955263560518438\n",
      "Episode 1246 , steps =  49 , total reward: -2.2472941140383482 , steps_avg: 261.6094627105052 , reward_avg: -13.681526440301736 , distance traveled: 6.58866000339389 , average speed: 0.13446244904885488 , explore ratio: 0.05943488006536649\n",
      "Episode 1247 , steps =  66 , total reward: -2.9823077753943767 , steps_avg: 261.45272435897436 , reward_avg: -13.672953348422803 , distance traveled: 9.628498895410445 , average speed: 0.14588634690015825 , explore ratio: 0.05931735736775646\n",
      "Episode 1248 , steps =  135 , total reward: 2.490613029863051 , steps_avg: 261.35148118494794 , reward_avg: -13.660012142355322 , distance traveled: 27.786259288066653 , average speed: 0.2058241428745678 , explore ratio: 0.059200067051947115\n",
      "Episode 1249 , steps =  70 , total reward: 0.3775506189092954 , steps_avg: 261.1984 , reward_avg: -13.64878209214631 , distance traveled: 13.827772777676582 , average speed: 0.19753961110966545 , explore ratio: 0.05908300865844168\n",
      "Episode 1250 , steps =  77 , total reward: -3.489370766359075 , steps_avg: 261.0511590727418 , reward_avg: -13.640661059911467 , distance traveled: 8.891170094422996 , average speed: 0.11546974148601294 , explore ratio: 0.05896618172865196\n",
      "Episode 1251 , steps =  48 , total reward: -3.0782951923155544 , steps_avg: 260.8809904153355 , reward_avg: -13.63222466544853 , distance traveled: 6.147776042819022 , average speed: 0.12807866755872963 , explore ratio: 0.05884958580489653\n",
      "Episode 1252 , steps =  51 , total reward: -14.696271296349666 , steps_avg: 260.71348762968876 , reward_avg: -13.633073864675108 , distance traveled: -3.448091253584717 , average speed: -0.06760963242322975 , explore ratio: 0.058733220430398955\n",
      "Episode 1253 , steps =  66 , total reward: -2.560921712962914 , steps_avg: 260.55821371610847 , reward_avg: -13.624244397249502 , distance traveled: 8.522187921255826 , average speed: 0.12912405941296706 , explore ratio: 0.05861708514928601\n",
      "Episode 1254 , steps =  114 , total reward: 6.606998363492382 , steps_avg: 260.44143426294823 , reward_avg: -13.608123885089547 , distance traveled: 29.15658264309169 , average speed: 0.25575949686922533 , explore ratio: 0.058501179506585885\n",
      "Episode 1255 , steps =  365 , total reward: 1.2549642521421998 , steps_avg: 260.5246815286624 , reward_avg: -13.596290216190477 , distance traveled: 60.892329833339915 , average speed: 0.16682830091326004 , explore ratio: 0.05838550304822639\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1256 , steps =  70 , total reward: 3.0574773153134864 , steps_avg: 260.37311058074783 , reward_avg: -13.5830413955608 , distance traveled: 17.131945239901544 , average speed: 0.24474207485573635 , explore ratio: 0.0582700553210332\n",
      "Episode 1257 , steps =  102 , total reward: -0.9856587376625682 , steps_avg: 260.24721780604136 , reward_avg: -13.573027577867718 , distance traveled: 17.723440856337543 , average speed: 0.17375922408174063 , explore ratio: 0.05815483587272806\n",
      "Episode 1258 , steps =  250 , total reward: 24.58174427980552 , steps_avg: 260.23907863383636 , reward_avg: -13.54272196082429 , distance traveled: 77.55517455965284 , average speed: 0.31022069823861137 , explore ratio: 0.05803984425192702\n",
      "Episode 1259 , steps =  92 , total reward: 2.152247395876167 , steps_avg: 260.10555555555555 , reward_avg: -13.53026563593802 , distance traveled: 19.62299479544163 , average speed: 0.21329342168958296 , explore ratio: 0.057925080008138674\n",
      "Episode 1260 , steps =  63 , total reward: -0.952544902433335 , steps_avg: 259.949246629659 , reward_avg: -13.520291234087502 , distance traveled: 11.420995818972589 , average speed: 0.18128564792019983 , explore ratio: 0.05781054269176239\n",
      "Episode 1261 , steps =  157 , total reward: 18.610033898211398 , steps_avg: 259.8676703645008 , reward_avg: -13.494831388499309 , distance traveled: 53.69453731119631 , average speed: 0.3420034223643077 , explore ratio: 0.05769623185408654\n",
      "Episode 1262 , steps =  54 , total reward: -1.9477339361874981 , steps_avg: 259.7046714172605 , reward_avg: -13.48568879352519 , distance traveled: 9.204498599767685 , average speed: 0.17045367777347564 , explore ratio: 0.057582147047286744\n",
      "Episode 1263 , steps =  58 , total reward: -0.8742092100226665 , steps_avg: 259.54509493670884 , reward_avg: -13.47571135714584 , distance traveled: 9.129692305326463 , average speed: 0.15740848802287005 , explore ratio: 0.05746828782442414\n",
      "Episode 1264 , steps =  49 , total reward: -13.0958647981522 , steps_avg: 259.3786561264822 , reward_avg: -13.47541108318616 , distance traveled: -3.2560013430565595 , average speed: -0.06644900700115428 , explore ratio: 0.057354653739443595\n",
      "Episode 1265 , steps =  86 , total reward: -28.392748044947805 , steps_avg: 259.2417061611374 , reward_avg: -13.487194129759432 , distance traveled: -6.136911692284045 , average speed: -0.07135943828237261 , explore ratio: 0.05724124434717199\n",
      "Episode 1266 , steps =  119 , total reward: 13.481611606365059 , steps_avg: 259.1310181531176 , reward_avg: -13.465908568799584 , distance traveled: 40.27678337216376 , average speed: 0.33846036447196437 , explore ratio: 0.057128059203316456\n",
      "Episode 1267 , steps =  157 , total reward: -5.899971968794876 , steps_avg: 259.05047318611986 , reward_avg: -13.459941741827974 , distance traveled: 18.776443902812897 , average speed: 0.11959518409434966 , explore ratio: 0.05701509786446264\n",
      "Episode 1268 , steps =  128 , total reward: -0.482981578826292 , steps_avg: 258.9472025216706 , reward_avg: -13.44971561088786 , distance traveled: 22.518298407085247 , average speed: 0.1759242063053535 , explore ratio: 0.056902359888072976\n",
      "Episode 1269 , steps =  125 , total reward: -18.789251124948855 , steps_avg: 258.8417322834646 , reward_avg: -13.45391996956035 , distance traveled: -0.32440222145989567 , average speed: -0.0025952177716791654 , explore ratio: 0.056789844832484934\n",
      "Episode 1270 , steps =  177 , total reward: 3.6000858277336913 , steps_avg: 258.77734067663255 , reward_avg: -13.440502183724556 , distance traveled: 36.890405421266344 , average speed: 0.20842036961167426 , explore ratio: 0.0566775522569093\n",
      "Episode 1271 , steps =  254 , total reward: 1.7410271044647563 , steps_avg: 258.77358490566036 , reward_avg: -13.428567019189817 , distance traveled: 44.20960095584391 , average speed: 0.1740535470702516 , explore ratio: 0.056565481721428446\n",
      "Episode 1272 , steps =  317 , total reward: -22.432208223993896 , steps_avg: 258.8193244304792 , reward_avg: -13.435639793113467 , distance traveled: 20.60414609950036 , average speed: 0.06499730630757211 , explore ratio: 0.05645363278699462\n",
      "Episode 1273 , steps =  143 , total reward: -5.357499259841326 , steps_avg: 258.72841444270017 , reward_avg: -13.429299023464115 , distance traveled: 16.156306003468345 , average speed: 0.112981160863415 , explore ratio: 0.05634200501542821\n",
      "Episode 1274 , steps =  80 , total reward: -8.805633118062598 , steps_avg: 258.5882352941176 , reward_avg: -13.425672618832428 , distance traveled: 3.1437156349048014 , average speed: 0.039296445436310015 , explore ratio: 0.05623059796941602\n",
      "Episode 1275 , steps =  158 , total reward: -6.87822332641483 , steps_avg: 258.50940438871476 , reward_avg: -13.420541388979435 , distance traveled: 17.319732483923435 , average speed: 0.10961856002483186 , explore ratio: 0.05611941121250958\n",
      "Episode 1276 , steps =  241 , total reward: 43.62495297575542 , steps_avg: 258.49569303054034 , reward_avg: -13.3758698976993 , distance traveled: 99.8574255819619 , average speed: 0.41434616424050585 , explore ratio: 0.05600844430912343\n",
      "Episode 1277 , steps =  105 , total reward: -2.609924190149962 , steps_avg: 258.3755868544601 , reward_avg: -13.36744584002516 , distance traveled: 14.799986358666795 , average speed: 0.14095225103492184 , explore ratio: 0.055897696824533404\n",
      "Episode 1278 , steps =  50 , total reward: -10.294406374553215 , steps_avg: 258.2126661454261 , reward_avg: -13.365043150841835 , distance traveled: 1.1868389797210692 , average speed: 0.023736779594421383 , explore ratio: 0.05578716832487492\n",
      "Episode 1279 , steps =  71 , total reward: -10.250388190660631 , steps_avg: 258.06640625 , reward_avg: -13.362609826654193 , distance traveled: 0.3471402105409652 , average speed: 0.004889298740013595 , explore ratio: 0.0556768583771413\n",
      "Episode 1280 , steps =  71 , total reward: -1.0634587636509316 , steps_avg: 257.92037470725995 , reward_avg: -13.353008615832177 , distance traveled: 12.911768985986708 , average speed: 0.1818559012110804 , explore ratio: 0.05556676654918207\n",
      "Episode 1281 , steps =  123 , total reward: -6.499547143870972 , steps_avg: 257.8151326053042 , reward_avg: -13.347662702047495 , distance traveled: 15.74117714256048 , average speed: 0.12797704993951609 , explore ratio: 0.05545689240970127\n",
      "Episode 1282 , steps =  195 , total reward: 21.52554132985882 , steps_avg: 257.7661730319563 , reward_avg: -13.320481716831669 , distance traveled: 70.12168170254677 , average speed: 0.359598367705368 , explore ratio: 0.05534723552825573\n",
      "Episode 1283 , steps =  86 , total reward: 4.596006367655472 , steps_avg: 257.6323987538941 , reward_avg: -13.306528065675526 , distance traveled: 21.919211518848318 , average speed: 0.2548745525447479 , explore ratio: 0.05523779547525344\n",
      "Episode 1284 , steps =  53 , total reward: -9.16811023496154 , steps_avg: 257.47315175097276 , reward_avg: -13.3033075070524 , distance traveled: 0.8617750859633089 , average speed: 0.016259907282326583 , explore ratio: 0.05512857182195181\n",
      "Episode 1285 , steps =  47 , total reward: -4.000430235691368 , steps_avg: 257.3094867807154 , reward_avg: -13.296073543388825 , distance traveled: 5.538007655739785 , average speed: 0.11782995012212308 , explore ratio: 0.05501956414045605\n",
      "Episode 1286 , steps =  37 , total reward: -10.989057410656784 , steps_avg: 257.1383061383061 , reward_avg: -13.29428099006114 , distance traveled: 1.828198203351349 , average speed: 0.04941076225273917 , explore ratio: 0.05491077200371743\n",
      "Episode 1287 , steps =  129 , total reward: 7.799449703741192 , steps_avg: 257.0388198757764 , reward_avg: -13.277903869957255 , distance traveled: 34.84930091402494 , average speed: 0.2701496194885654 , explore ratio: 0.05480219498553166\n",
      "Episode 1288 , steps =  176 , total reward: 19.058677841768308 , steps_avg: 256.97595034910785 , reward_avg: -13.252817305401999 , distance traveled: 56.050858962480014 , average speed: 0.31847078955954555 , explore ratio: 0.054693832660537185\n",
      "Episode 1289 , steps =  56 , total reward: -4.56437277178404 , steps_avg: 256.8201550387597 , reward_avg: -13.246082077081363 , distance traveled: 5.499789855480196 , average speed: 0.09821053313357493 , explore ratio: 0.05458568460421354\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1290 , steps =  157 , total reward: -9.40728099500389 , steps_avg: 256.7428350116189 , reward_avg: -13.243108567335371 , distance traveled: 13.779204117134212 , average speed: 0.08776563131932619 , explore ratio: 0.054477750392879686\n",
      "Episode 1291 , steps =  142 , total reward: -8.084350382123155 , steps_avg: 256.65402476780184 , reward_avg: -13.239115720442792 , distance traveled: 13.037896392457183 , average speed: 0.09181617177786748 , explore ratio: 0.054370029603692326\n",
      "Episode 1292 , steps =  742 , total reward: 28.009916821815146 , steps_avg: 257.0293890177881 , reward_avg: -13.207213916465795 , distance traveled: 165.47013910643767 , average speed: 0.2230055783105629 , explore ratio: 0.05426252181464428\n",
      "Episode 1293 , steps =  83 , total reward: -33.99256209882971 , steps_avg: 256.8948995363215 , reward_avg: -13.223276782139955 , distance traveled: -13.446502168346194 , average speed: -0.16200605022103848 , explore ratio: 0.05415522660456281\n",
      "Episode 1294 , steps =  80 , total reward: -1.0685614895944773 , steps_avg: 256.75830115830115 , reward_avg: -13.213890901605172 , distance traveled: 12.92700840085745 , average speed: 0.16158760501071812 , explore ratio: 0.05404814355310798\n",
      "Episode 1295 , steps =  94 , total reward: -1.6225010779953308 , steps_avg: 256.63271604938274 , reward_avg: -13.204946927975842 , distance traveled: 14.934295973796397 , average speed: 0.15887548908294039 , explore ratio: 0.05394127224077102\n",
      "Episode 1296 , steps =  315 , total reward: 20.699917179709306 , steps_avg: 256.67771781033156 , reward_avg: -13.178805937915946 , distance traveled: 79.25884322566914 , average speed: 0.25161537531958456 , explore ratio: 0.05383461224887265\n",
      "Episode 1297 , steps =  127 , total reward: -8.193673251239595 , steps_avg: 256.57781201848996 , reward_avg: -13.174965311809109 , distance traveled: 12.119376061633226 , average speed: 0.09542815796561595 , explore ratio: 0.053728163159561464\n",
      "Episode 1298 , steps =  211 , total reward: 33.876565808550104 , steps_avg: 256.54272517321016 , reward_avg: -13.138743963756484 , distance traveled: 81.32131347924472 , average speed: 0.3854090686220129 , explore ratio: 0.05362192455581229\n",
      "Episode 1299 , steps =  43 , total reward: -19.8712661906959 , steps_avg: 256.3784615384615 , reward_avg: -13.143922827007975 , distance traveled: -2.5060697914659977 , average speed: -0.05828069282479065 , explore ratio: 0.05351589602142457\n",
      "Episode 1300 , steps =  180 , total reward: 6.076517663607355 , steps_avg: 256.3197540353574 , reward_avg: -13.129149237084366 , distance traveled: 38.97884270293638 , average speed: 0.21654912612742436 , explore ratio: 0.05341007714102069\n",
      "Episode 1301 , steps =  118 , total reward: -4.630918858955313 , steps_avg: 256.21351766513055 , reward_avg: -13.12262217842221 , distance traveled: 16.044292341023684 , average speed: 0.13596857916121766 , explore ratio: 0.05330446750004439\n",
      "Episode 1302 , steps =  64 , total reward: -3.699558859810861 , steps_avg: 256.0660015349194 , reward_avg: -13.1153903569958 , distance traveled: 9.6539382737875 , average speed: 0.15084278552792968 , explore ratio: 0.05319906668475912\n",
      "Episode 1303 , steps =  35 , total reward: -8.37105236460765 , steps_avg: 255.89647239263803 , reward_avg: -13.111752060989367 , distance traveled: -3.064759470820428 , average speed: -0.08756455630915509 , explore ratio: 0.05309387428224644\n",
      "Episode 1304 , steps =  49 , total reward: -4.740256136561435 , steps_avg: 255.73793103448276 , reward_avg: -13.105337121583675 , distance traveled: 6.153614547550678 , average speed: 0.1255839703581771 , explore ratio: 0.05298888988040437\n",
      "Episode 1305 , steps =  189 , total reward: 4.495616529029469 , steps_avg: 255.68683001531394 , reward_avg: -13.091860127976775 , distance traveled: 37.25771216869355 , average speed: 0.1971307522153098 , explore ratio: 0.052884113067945805\n",
      "Episode 1306 , steps =  70 , total reward: 3.1453132209274868 , steps_avg: 255.54475899005357 , reward_avg: -13.07943688899521 , distance traveled: 16.996073336452245 , average speed: 0.2428010476636035 , explore ratio: 0.05277954343439689\n",
      "Episode 1307 , steps =  63 , total reward: -9.493175632560007 , steps_avg: 255.39755351681958 , reward_avg: -13.076695099043807 , distance traveled: 0.7932413398940115 , average speed: 0.012591132379270023 , explore ratio: 0.05267518057009542\n",
      "Episode 1308 , steps =  182 , total reward: -13.178856882952083 , steps_avg: 255.3414820473644 , reward_avg: -13.07677314471524 , distance traveled: 14.453325861096383 , average speed: 0.07941387835767244 , explore ratio: 0.05257102406618921\n",
      "Episode 1309 , steps =  65 , total reward: -11.383118482716386 , steps_avg: 255.19618320610687 , reward_avg: -13.075480278561045 , distance traveled: -4.498046658402308 , average speed: -0.06920071782157397 , explore ratio: 0.05246707351463453\n",
      "Episode 1310 , steps =  107 , total reward: 2.552638749636082 , steps_avg: 255.0831426392067 , reward_avg: -13.063559516525803 , distance traveled: 22.297950764994017 , average speed: 0.20839206322424314 , explore ratio: 0.0523633285081945\n",
      "Episode 1311 , steps =  57 , total reward: -0.7950439420336262 , steps_avg: 254.93216463414635 , reward_avg: -13.054208513801347 , distance traveled: 7.927565061673523 , average speed: 0.13908008880128986 , explore ratio: 0.05225978864043746\n",
      "Episode 1312 , steps =  331 , total reward: 4.186023277862777 , steps_avg: 254.990099009901 , reward_avg: -13.041078101164892 , distance traveled: 59.68699400670825 , average speed: 0.18032324473325753 , explore ratio: 0.05215645350573542\n",
      "Episode 1313 , steps =  91 , total reward: -3.136474246952064 , steps_avg: 254.86529680365297 , reward_avg: -13.033540350895324 , distance traveled: 12.44571060910821 , average speed: 0.13676605064954075 , explore ratio: 0.05205332269926243\n",
      "Episode 1314 , steps =  146 , total reward: 3.5287986553882478 , steps_avg: 254.78250950570342 , reward_avg: -13.020945416289784 , distance traveled: 28.805802686791864 , average speed: 0.197300018402684 , explore ratio: 0.051950395816993046\n",
      "Episode 1315 , steps =  50 , total reward: -10.70905828986628 , steps_avg: 254.62689969604864 , reward_avg: -13.019188663154205 , distance traveled: 0.4712723631318658 , average speed: 0.009425447262637316 , explore ratio: 0.0518476724557007\n",
      "Episode 1316 , steps =  179 , total reward: 30.184002782952025 , steps_avg: 254.56947608200454 , reward_avg: -12.98638441756111 , distance traveled: 74.10651361003521 , average speed: 0.4140028693298056 , explore ratio: 0.051745152212956134\n",
      "Episode 1317 , steps =  134 , total reward: -5.306943444152063 , steps_avg: 254.47799696509864 , reward_avg: -12.980557831086596 , distance traveled: 16.12564905853942 , average speed: 0.12034066461596582 , explore ratio: 0.05164283468712584\n",
      "Episode 1318 , steps =  89 , total reward: -11.458827394894639 , steps_avg: 254.35253980288098 , reward_avg: -12.979404130983342 , distance traveled: 3.0614640160091224 , average speed: 0.03439847208999014 , explore ratio: 0.05154071947737047\n",
      "Episode 1319 , steps =  46 , total reward: -26.783046975990764 , steps_avg: 254.19469696969696 , reward_avg: -12.989861436168953 , distance traveled: -8.161264629252255 , average speed: -0.17741879628809248 , explore ratio: 0.051438806183643264\n",
      "Episode 1320 , steps =  248 , total reward: 9.685273988597075 , steps_avg: 254.19000757002271 , reward_avg: -12.972696307157017 , distance traveled: 54.2931764598191 , average speed: 0.21892409862830284 , explore ratio: 0.0513370944066885\n",
      "Episode 1321 , steps =  238 , total reward: 27.689782309444574 , steps_avg: 254.17776096822996 , reward_avg: -12.941938002605882 , distance traveled: 82.71345030840483 , average speed: 0.3475355054974993 , explore ratio: 0.051235583748039916\n",
      "Episode 1322 , steps =  64 , total reward: 0.0777276901043954 , steps_avg: 254.03401360544217 , reward_avg: -12.93209698545342 , distance traveled: 11.342617946863172 , average speed: 0.17722840541973706 , explore ratio: 0.05113427381001914\n",
      "Episode 1323 , steps =  134 , total reward: 1.0568132691470167 , steps_avg: 253.94335347432025 , reward_avg: -12.921531343267164 , distance traveled: 23.60048646502196 , average speed: 0.17612303332105939 , explore ratio: 0.05103316419573416\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1324 , steps =  168 , total reward: -8.230766047894972 , steps_avg: 253.87849056603773 , reward_avg: -12.917991143044242 , distance traveled: 16.953663676148278 , average speed: 0.10091466473897784 , explore ratio: 0.05093225450907773\n",
      "Episode 1325 , steps =  248 , total reward: 31.424451624281733 , steps_avg: 253.87405731523378 , reward_avg: -12.884550386809458 , distance traveled: 86.31087603248665 , average speed: 0.34802772593744613 , explore ratio: 0.05083154435472586\n",
      "Episode 1326 , steps =  98 , total reward: -4.978940545783702 , steps_avg: 253.75659382064808 , reward_avg: -12.87859288127741 , distance traveled: 10.086723657622933 , average speed: 0.10292575160839727 , explore ratio: 0.05073103333813625\n",
      "Episode 1327 , steps =  212 , total reward: 8.767437215848497 , steps_avg: 253.72515060240963 , reward_avg: -12.862293159818732 , distance traveled: 48.76515935554168 , average speed: 0.23002433658274377 , explore ratio: 0.05063072106554673\n",
      "Episode 1328 , steps =  70 , total reward: -23.804768406429027 , steps_avg: 253.58690744920995 , reward_avg: -12.870526775504668 , distance traveled: -11.969606337323784 , average speed: -0.17099437624748262 , explore ratio: 0.05053060714397374\n",
      "Episode 1329 , steps =  75 , total reward: -1.2975630247344627 , steps_avg: 253.45263157894738 , reward_avg: -12.861825299000328 , distance traveled: 12.775648696124552 , average speed: 0.17034198261499403 , explore ratio: 0.05043069118121077\n",
      "Episode 1330 , steps =  74 , total reward: -13.251366634889196 , steps_avg: 253.31780616078137 , reward_avg: -12.862117967171544 , distance traveled: 0.7528163977526129 , average speed: 0.010173194564224499 , explore ratio: 0.05033097278582684\n",
      "Episode 1331 , steps =  99 , total reward: 0.38598414518683766 , steps_avg: 253.20195195195194 , reward_avg: -12.85217194456467 , distance traveled: 17.70668404904427 , average speed: 0.1788553944347906 , explore ratio: 0.05023145156716497\n",
      "Episode 1332 , steps =  71 , total reward: -17.801972057134535 , steps_avg: 253.06526631657914 , reward_avg: -12.855885222968697 , distance traveled: -11.738031022734939 , average speed: -0.16532438060190055 , explore ratio: 0.05013212713534062\n",
      "Episode 1333 , steps =  84 , total reward: -6.840266577764727 , steps_avg: 252.93853073463268 , reward_avg: -12.851375763714422 , distance traveled: 6.442548514644149 , average speed: 0.07669700612671607 , explore ratio: 0.05003299910124019\n",
      "Episode 1334 , steps =  138 , total reward: -15.735427866625288 , steps_avg: 252.85243445692885 , reward_avg: -12.853536102368288 , distance traveled: 3.0619978760182853 , average speed: 0.022188390405929605 , explore ratio: 0.0499340670765195\n",
      "Episode 1335 , steps =  159 , total reward: -4.699684779021898 , steps_avg: 252.78218562874252 , reward_avg: -12.847432920240035 , distance traveled: 29.507746619582168 , average speed: 0.18558331207284381 , explore ratio: 0.0499340670765195\n",
      "Episode 1336 , steps =  62 , total reward: 0.8814187972098569 , steps_avg: 252.6394913986537 , reward_avg: -12.837164519553834 , distance traveled: 11.520947163999079 , average speed: 0.18582172845159806 , explore ratio: 0.0499340670765195\n",
      "Episode 1337 , steps =  123 , total reward: 0.8573822995237974 , steps_avg: 252.542600896861 , reward_avg: -12.826929432245107 , distance traveled: 25.209083086852907 , average speed: 0.20495189501506428 , explore ratio: 0.0499340670765195\n",
      "Episode 1338 , steps =  62 , total reward: -1.6172830496287585 , steps_avg: 252.4002987303958 , reward_avg: -12.818557776992966 , distance traveled: 9.655187600255012 , average speed: 0.1557288322621776 , explore ratio: 0.0499340670765195\n",
      "Episode 1339 , steps =  69 , total reward: -11.505203476444507 , steps_avg: 252.2634328358209 , reward_avg: -12.817577661843304 , distance traveled: 1.3785086192720335 , average speed: 0.01997838578655121 , explore ratio: 0.0499340670765195\n",
      "Episode 1340 , steps =  56 , total reward: -5.262495419430858 , steps_avg: 252.11707680835198 , reward_avg: -12.811943745182294 , distance traveled: 3.9501742449402806 , average speed: 0.070538825802505 , explore ratio: 0.0499340670765195\n",
      "Episode 1341 , steps =  77 , total reward: 4.194625378307576 , steps_avg: 251.9865871833085 , reward_avg: -12.799271189948696 , distance traveled: 19.961438153386123 , average speed: 0.2592394565374821 , explore ratio: 0.0499340670765195\n",
      "Episode 1342 , steps =  387 , total reward: 12.886491296912814 , steps_avg: 252.08711839166045 , reward_avg: -12.780145529124523 , distance traveled: 78.88279024355113 , average speed: 0.2038314993373414 , explore ratio: 0.0499340670765195\n",
      "Episode 1343 , steps =  41 , total reward: -19.805523366550617 , steps_avg: 251.93005952380952 , reward_avg: -12.785372744777371 , distance traveled: -3.0064062908291818 , average speed: -0.07332698270315077 , explore ratio: 0.0499340670765195\n",
      "Episode 1344 , steps =  99 , total reward: -1.9706224648145394 , steps_avg: 251.81635687732341 , reward_avg: -12.777332038249517 , distance traveled: 14.314952025935051 , average speed: 0.14459547500944497 , explore ratio: 0.0499340670765195\n",
      "Episode 1345 , steps =  149 , total reward: -2.847015906524545 , steps_avg: 251.73997028231798 , reward_avg: -12.7699543888203 , distance traveled: 21.155240047420378 , average speed: 0.14198147682832468 , explore ratio: 0.0499340670765195\n",
      "Episode 1346 , steps =  135 , total reward: -9.689210490956915 , steps_avg: 251.65330363771344 , reward_avg: -12.7676672738256 , distance traveled: 10.839011142952366 , average speed: 0.08028897142927678 , explore ratio: 0.0499340670765195\n",
      "Episode 1347 , steps =  102 , total reward: -1.596422957541428 , steps_avg: 251.54228486646883 , reward_avg: -12.759380000593934 , distance traveled: 16.37965629626065 , average speed: 0.1605848656496142 , explore ratio: 0.0499340670765195\n",
      "Episode 1348 , steps =  87 , total reward: -1.5411376488854582 , steps_avg: 251.42031134173462 , reward_avg: -12.751064031467392 , distance traveled: 13.618804430812599 , average speed: 0.15653798196336322 , explore ratio: 0.0499340670765195\n",
      "Episode 1349 , steps =  62 , total reward: -7.109464896770818 , steps_avg: 251.28 , reward_avg: -12.746885069145392 , distance traveled: 0.9848843387793749 , average speed: 0.01588523127063508 , explore ratio: 0.0499340670765195\n",
      "Episode 1350 , steps =  801 , total reward: 59.92619812990394 , steps_avg: 251.68689859363434 , reward_avg: -12.693093001640543 , distance traveled: 211.56274525097166 , average speed: 0.26412327746688097 , explore ratio: 0.0499340670765195\n",
      "Episode 1351 , steps =  167 , total reward: 8.330485605321813 , steps_avg: 251.62426035502958 , reward_avg: -12.677543017463796 , distance traveled: 41.679440349563976 , average speed: 0.24957748712313757 , explore ratio: 0.0499340670765195\n",
      "Episode 1352 , steps =  150 , total reward: 4.593882913244883 , steps_avg: 251.54915003695493 , reward_avg: -12.664777735918559 , distance traveled: 31.80898492703447 , average speed: 0.21205989951356313 , explore ratio: 0.0499340670765195\n",
      "Episode 1353 , steps =  69 , total reward: 1.0431981762852498 , steps_avg: 251.41432791728212 , reward_avg: -12.654653676899207 , distance traveled: 14.65495686650276 , average speed: 0.21239067922467766 , explore ratio: 0.0499340670765195\n",
      "Episode 1354 , steps =  48 , total reward: -6.4502618914476315 , steps_avg: 251.26420664206643 , reward_avg: -12.650074789972672 , distance traveled: 0.7779890301078557 , average speed: 0.01620810479391366 , explore ratio: 0.0499340670765195\n",
      "Episode 1355 , steps =  259 , total reward: -23.662837214788272 , steps_avg: 251.26991150442478 , reward_avg: -12.658196296185663 , distance traveled: 10.447395624071351 , average speed: 0.04033743484197433 , explore ratio: 0.0499340670765195\n",
      "Episode 1356 , steps =  263 , total reward: 1.6960637022269016 , steps_avg: 251.27855563743552 , reward_avg: -12.647618359561925 , distance traveled: 47.44578687834553 , average speed: 0.18040223147659898 , explore ratio: 0.0499340670765195\n",
      "Episode 1357 , steps =  79 , total reward: -9.60893757251589 , steps_avg: 251.1516936671576 , reward_avg: -12.645380744843925 , distance traveled: 4.477971926734316 , average speed: 0.056683188946004 , explore ratio: 0.0499340670765195\n",
      "Episode 1358 , steps =  40 , total reward: -17.189963983511554 , steps_avg: 250.99632082413538 , reward_avg: -12.648724809037203 , distance traveled: -1.8578193333512174 , average speed: -0.046445483333780437 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1359 , steps =  86 , total reward: -10.541163222430903 , steps_avg: 250.875 , reward_avg: -12.647175131399994 , distance traveled: 3.687501224689186 , average speed: 0.042877921217316116 , explore ratio: 0.0499340670765195\n",
      "Episode 1360 , steps =  61 , total reward: -13.640313090605666 , steps_avg: 250.73548861131522 , reward_avg: -12.647904843346508 , distance traveled: -4.638227739036083 , average speed: -0.07603652031206692 , explore ratio: 0.0499340670765195\n",
      "Episode 1361 , steps =  215 , total reward: 33.270061077686556 , steps_avg: 250.7092511013216 , reward_avg: -12.61419121198011 , distance traveled: 82.29608614929018 , average speed: 0.3827724937176287 , explore ratio: 0.0499340670765195\n",
      "Episode 1362 , steps =  49 , total reward: -18.227067225378633 , steps_avg: 250.5612619222304 , reward_avg: -12.61830924280432 , distance traveled: -4.270581989139318 , average speed: -0.08715473447223097 , explore ratio: 0.0499340670765195\n",
      "Episode 1363 , steps =  65 , total reward: 2.316410630385697 , steps_avg: 250.42521994134898 , reward_avg: -12.607360034686147 , distance traveled: 15.126917678117755 , average speed: 0.23272181043258083 , explore ratio: 0.0499340670765195\n",
      "Episode 1364 , steps =  129 , total reward: 4.990432759772977 , steps_avg: 250.33626373626373 , reward_avg: -12.59446787879277 , distance traveled: 30.17894375771283 , average speed: 0.2339453004473863 , explore ratio: 0.0499340670765195\n",
      "Episode 1365 , steps =  56 , total reward: -2.8292433470934637 , steps_avg: 250.1939970717423 , reward_avg: -12.587319105343502 , distance traveled: 7.115679640173913 , average speed: 0.12706570786024846 , explore ratio: 0.0499340670765195\n",
      "Episode 1366 , steps =  266 , total reward: 51.62641136922107 , steps_avg: 250.20555961960497 , reward_avg: -12.540344906020486 , distance traveled: 117.94075876504185 , average speed: 0.44338631114677385 , explore ratio: 0.0499340670765195\n",
      "Episode 1367 , steps =  76 , total reward: -11.706766003163533 , steps_avg: 250.078216374269 , reward_avg: -12.539735564717226 , distance traveled: 2.9922698414325715 , average speed: 0.03937197159779699 , explore ratio: 0.0499340670765195\n",
      "Episode 1368 , steps =  155 , total reward: -12.333471789397311 , steps_avg: 250.00876552227905 , reward_avg: -12.539584897240735 , distance traveled: 10.271527019818311 , average speed: 0.06626791625689234 , explore ratio: 0.0499340670765195\n",
      "Episode 1369 , steps =  148 , total reward: 5.48147151416415 , steps_avg: 249.93430656934308 , reward_avg: -12.526430841465984 , distance traveled: 39.975476535097705 , average speed: 0.2701045711830926 , explore ratio: 0.0499340670765195\n",
      "Episode 1370 , steps =  81 , total reward: 0.7674329912339521 , steps_avg: 249.8110867979577 , reward_avg: -12.51673436894031 , distance traveled: 17.89596973992884 , average speed: 0.22093789802381286 , explore ratio: 0.0499340670765195\n",
      "Episode 1371 , steps =  145 , total reward: 8.620681423336878 , steps_avg: 249.73469387755102 , reward_avg: -12.50132808920833 , distance traveled: 36.439235541522514 , average speed: 0.2513050727001553 , explore ratio: 0.0499340670765195\n",
      "Episode 1372 , steps =  166 , total reward: -12.172320445665445 , steps_avg: 249.67370721048798 , reward_avg: -12.501088462373994 , distance traveled: 11.593800202757121 , average speed: 0.06984216989612724 , explore ratio: 0.0499340670765195\n",
      "Episode 1373 , steps =  153 , total reward: -12.100965570646663 , steps_avg: 249.60334788937408 , reward_avg: -12.500797252118007 , distance traveled: 12.888728149328385 , average speed: 0.08424005326358422 , explore ratio: 0.0499340670765195\n",
      "Episode 1374 , steps =  65 , total reward: 2.0467472610001773 , steps_avg: 249.4690909090909 , reward_avg: -12.49021721974483 , distance traveled: 17.036241473257537 , average speed: 0.2620960226655006 , explore ratio: 0.0499340670765195\n",
      "Episode 1375 , steps =  81 , total reward: 4.596862096195412 , steps_avg: 249.34665697674419 , reward_avg: -12.477799284195456 , distance traveled: 21.015255983266975 , average speed: 0.25944760473169104 , explore ratio: 0.0499340670765195\n",
      "Episode 1376 , steps =  57 , total reward: -10.569730885198963 , steps_avg: 249.20697167755992 , reward_avg: -12.47641361360795 , distance traveled: 1.4964170559681953 , average speed: 0.026252930806459567 , explore ratio: 0.0499340670765195\n",
      "Episode 1377 , steps =  145 , total reward: -37.08015040893726 , steps_avg: 249.13134978229317 , reward_avg: -12.494268284722121 , distance traveled: -28.02242096185686 , average speed: -0.1932580755990128 , explore ratio: 0.0499340670765195\n",
      "Episode 1378 , steps =  274 , total reward: 6.449322002866589 , steps_avg: 249.14938361131254 , reward_avg: -12.480531090895008 , distance traveled: 56.664639901999585 , average speed: 0.2068052551167868 , explore ratio: 0.0499340670765195\n",
      "Episode 1379 , steps =  119 , total reward: 4.599691164463747 , steps_avg: 249.0550724637681 , reward_avg: -12.468154118246195 , distance traveled: 27.51763290778734 , average speed: 0.23124061267048185 , explore ratio: 0.0499340670765195\n",
      "Episode 1380 , steps =  236 , total reward: 19.14990516479005 , steps_avg: 249.04561911658217 , reward_avg: -12.445259071698018 , distance traveled: 69.28291244029994 , average speed: 0.29357166288262687 , explore ratio: 0.0499340670765195\n",
      "Episode 1381 , steps =  302 , total reward: -1.8790188603562825 , steps_avg: 249.08393632416787 , reward_avg: -12.437613456494441 , distance traveled: 49.713299644589405 , average speed: 0.16461357498208412 , explore ratio: 0.0499340670765195\n",
      "Episode 1382 , steps =  263 , total reward: -7.534383403314916 , steps_avg: 249.0939985538684 , reward_avg: -12.43406809853842 , distance traveled: 32.680674397023395 , average speed: 0.12426111938031709 , explore ratio: 0.0499340670765195\n",
      "Episode 1383 , steps =  335 , total reward: 35.75269012770606 , steps_avg: 249.15606936416185 , reward_avg: -12.399251076698645 , distance traveled: 105.2964892191882 , average speed: 0.3143178782662334 , explore ratio: 0.0499340670765195\n",
      "Episode 1384 , steps =  36 , total reward: -16.315645474190514 , steps_avg: 249.00216606498194 , reward_avg: -12.402078798285283 , distance traveled: -2.1753194725513456 , average speed: -0.060425540904204045 , explore ratio: 0.0499340670765195\n",
      "Episode 1385 , steps =  238 , total reward: 11.047439361080508 , steps_avg: 248.994227994228 , reward_avg: -12.385159954014458 , distance traveled: 58.03551951125263 , average speed: 0.24384672063551524 , explore ratio: 0.0499340670765195\n",
      "Episode 1386 , steps =  97 , total reward: -3.9069443759564377 , steps_avg: 248.8846431146359 , reward_avg: -12.379047325623644 , distance traveled: 13.58820918979123 , average speed: 0.14008463082259 , explore ratio: 0.0499340670765195\n",
      "Episode 1387 , steps =  65 , total reward: -9.723901003195595 , steps_avg: 248.7521613832853 , reward_avg: -12.377134395996533 , distance traveled: 4.482133639007807 , average speed: 0.06895590213858165 , explore ratio: 0.0499340670765195\n",
      "Episode 1388 , steps =  91 , total reward: -9.960205441823234 , steps_avg: 248.63858891288697 , reward_avg: -12.3753943463535 , distance traveled: 6.67483543826267 , average speed: 0.07334983998090845 , explore ratio: 0.0499340670765195\n",
      "Episode 1389 , steps =  41 , total reward: -18.5647496826804 , steps_avg: 248.4892086330935 , reward_avg: -12.379847119976757 , distance traveled: -3.543596426770091 , average speed: -0.08642918114073392 , explore ratio: 0.0499340670765195\n",
      "Episode 1390 , steps =  222 , total reward: -26.486023820935987 , steps_avg: 248.47016534867 , reward_avg: -12.389988152831508 , distance traveled: 0.6481619608215974 , average speed: 0.0029196484721693574 , explore ratio: 0.0499340670765195\n",
      "Episode 1391 , steps =  367 , total reward: 3.6995638104751443 , steps_avg: 248.555316091954 , reward_avg: -12.378429566650972 , distance traveled: 66.21027057325466 , average speed: 0.18040945660287375 , explore ratio: 0.0499340670765195\n",
      "Episode 1392 , steps =  86 , total reward: 3.3406603676471893 , steps_avg: 248.43862167982772 , reward_avg: -12.367145223553845 , distance traveled: 18.770762598216532 , average speed: 0.21826468137461083 , explore ratio: 0.0499340670765195\n",
      "Episode 1393 , steps =  229 , total reward: 11.504246196751156 , steps_avg: 248.42467718794836 , reward_avg: -12.35002083946467 , distance traveled: 56.60783675276907 , average speed: 0.24719579368021427 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1394 , steps =  213 , total reward: -13.86497486081959 , steps_avg: 248.39928315412186 , reward_avg: -12.351106828010447 , distance traveled: 19.07537108623422 , average speed: 0.08955573279922169 , explore ratio: 0.0499340670765195\n",
      "Episode 1395 , steps =  50 , total reward: -1.8264626202018281 , steps_avg: 248.25716332378224 , reward_avg: -12.34356768459511 , distance traveled: 7.622530887722968 , average speed: 0.15245061775445937 , explore ratio: 0.0499340670765195\n",
      "Episode 1396 , steps =  245 , total reward: 6.529189323497289 , steps_avg: 248.25483178239082 , reward_avg: -12.330058194968702 , distance traveled: 51.26812945431099 , average speed: 0.20925767124208566 , explore ratio: 0.0499340670765195\n",
      "Episode 1397 , steps =  87 , total reward: -17.033610504886752 , steps_avg: 248.13948497854076 , reward_avg: -12.333422681599545 , distance traveled: -2.9887888497859247 , average speed: -0.034353894825125575 , explore ratio: 0.0499340670765195\n",
      "Episode 1398 , steps =  385 , total reward: -10.032992490387146 , steps_avg: 248.2373123659757 , reward_avg: -12.331778342649429 , distance traveled: 50.76677188052795 , average speed: 0.13186174514422844 , explore ratio: 0.0499340670765195\n",
      "Episode 1399 , steps =  81 , total reward: 2.0597712957505117 , steps_avg: 248.11785714285713 , reward_avg: -12.321498664336286 , distance traveled: 17.82426008284092 , average speed: 0.22005259361531998 , explore ratio: 0.0499340670765195\n",
      "Episode 1400 , steps =  66 , total reward: -6.450539863455422 , steps_avg: 247.98786581013562 , reward_avg: -12.317308115584767 , distance traveled: 4.487373515367508 , average speed: 0.0679905078085986 , explore ratio: 0.0499340670765195\n",
      "Episode 1401 , steps =  358 , total reward: -61.293887101961744 , steps_avg: 248.06633380884452 , reward_avg: -12.352241481480899 , distance traveled: -27.895408000387253 , average speed: -0.077920134079294 , explore ratio: 0.0499340670765195\n",
      "Episode 1402 , steps =  64 , total reward: -4.480912665723517 , steps_avg: 247.9351389878831 , reward_avg: -12.34663112594579 , distance traveled: 9.752651708275078 , average speed: 0.1523851829417981 , explore ratio: 0.0499340670765195\n",
      "Episode 1403 , steps =  268 , total reward: -9.75087665150624 , steps_avg: 247.9494301994302 , reward_avg: -12.344782297972541 , distance traveled: 32.64717306219041 , average speed: 0.12181780993354631 , explore ratio: 0.0499340670765195\n",
      "Episode 1404 , steps =  133 , total reward: 8.021392692212013 , steps_avg: 247.86761565836298 , reward_avg: -12.330286799758888 , distance traveled: 39.661080422177925 , average speed: 0.2982036121968265 , explore ratio: 0.0499340670765195\n",
      "Episode 1405 , steps =  185 , total reward: 35.23275152716465 , steps_avg: 247.82290184921763 , reward_avg: -12.296458180749696 , distance traveled: 84.22434565812351 , average speed: 0.4552667332871541 , explore ratio: 0.0499340670765195\n",
      "Episode 1406 , steps =  136 , total reward: 19.520128976744886 , steps_avg: 247.74342572850034 , reward_avg: -12.273845112407482 , distance traveled: 51.12886548623441 , average speed: 0.3759475403399589 , explore ratio: 0.0499340670765195\n",
      "Episode 1407 , steps =  76 , total reward: -26.73905123250063 , steps_avg: 247.62144886363637 , reward_avg: -12.284118696299593 , distance traveled: -3.893420128002762 , average speed: -0.05122921221056266 , explore ratio: 0.0499340670765195\n",
      "Episode 1408 , steps =  248 , total reward: 24.233482326926605 , steps_avg: 247.62171753016324 , reward_avg: -12.25820130735479 , distance traveled: 73.89982993125916 , average speed: 0.29798318520669015 , explore ratio: 0.0499340670765195\n",
      "Episode 1409 , steps =  224 , total reward: 5.7601712602327115 , steps_avg: 247.60496453900709 , reward_avg: -12.245422319718205 , distance traveled: 49.19288820086397 , average speed: 0.2196111080395713 , explore ratio: 0.0499340670765195\n",
      "Episode 1410 , steps =  45 , total reward: -19.300802306644627 , steps_avg: 247.46137491141036 , reward_avg: -12.250422589021483 , distance traveled: -3.2310591977834697 , average speed: -0.07180131550629933 , explore ratio: 0.0499340670765195\n",
      "Episode 1411 , steps =  252 , total reward: 31.088271437706993 , steps_avg: 247.46458923512748 , reward_avg: -12.219729462940231 , distance traveled: 87.09901357367634 , average speed: 0.3456310062447474 , explore ratio: 0.0499340670765195\n",
      "Episode 1412 , steps =  295 , total reward: 12.728885240098437 , steps_avg: 247.49823071479122 , reward_avg: -12.20207297695082 , distance traveled: 68.53508585639297 , average speed: 0.2323223249369253 , explore ratio: 0.0499340670765195\n",
      "Episode 1413 , steps =  59 , total reward: 0.9615861292940854 , steps_avg: 247.36492220650638 , reward_avg: -12.192763458488129 , distance traveled: 11.964435210227967 , average speed: 0.20278703746149096 , explore ratio: 0.0499340670765195\n",
      "Episode 1414 , steps =  165 , total reward: -5.649789683222782 , steps_avg: 247.30671378091873 , reward_avg: -12.18813944875296 , distance traveled: 21.90126923044212 , average speed: 0.13273496503298254 , explore ratio: 0.0499340670765195\n",
      "Episode 1415 , steps =  328 , total reward: 7.38303484993318 , steps_avg: 247.36370056497177 , reward_avg: -12.17431799797705 , distance traveled: 67.39279330803085 , average speed: 0.2054658332561916 , explore ratio: 0.0499340670765195\n",
      "Episode 1416 , steps =  213 , total reward: 14.939806256451934 , steps_avg: 247.3394495412844 , reward_avg: -12.155183118474982 , distance traveled: 59.0480373183824 , average speed: 0.27722083248066853 , explore ratio: 0.0499340670765195\n",
      "Episode 1417 , steps =  491 , total reward: -1.094021575753315 , steps_avg: 247.51128349788434 , reward_avg: -12.147382581420878 , distance traveled: 79.84087005659937 , average speed: 0.16260869665295188 , explore ratio: 0.0499340670765195\n",
      "Episode 1418 , steps =  210 , total reward: -12.098361227406825 , steps_avg: 247.4848484848485 , reward_avg: -12.14734803501213 , distance traveled: 33.881909033060104 , average speed: 0.16134242396695286 , explore ratio: 0.0499340670765195\n",
      "Episode 1419 , steps =  227 , total reward: 5.23929372584198 , steps_avg: 247.47042253521127 , reward_avg: -12.135103921096036 , distance traveled: 46.940203962028015 , average speed: 0.20678503948029964 , explore ratio: 0.0499340670765195\n",
      "Episode 1420 , steps =  59 , total reward: -5.789308250647663 , steps_avg: 247.3377902885292 , reward_avg: -12.13063819578256 , distance traveled: 3.242305222805589 , average speed: 0.05495432581026422 , explore ratio: 0.0499340670765195\n",
      "Episode 1421 , steps =  284 , total reward: 45.89945677622454 , steps_avg: 247.36357243319267 , reward_avg: -12.089829408882414 , distance traveled: 111.91990445818752 , average speed: 0.39408417062742085 , explore ratio: 0.0499340670765195\n",
      "Episode 1422 , steps =  358 , total reward: -27.68155364377158 , steps_avg: 247.44132115249474 , reward_avg: -12.10078634790904 , distance traveled: 28.15241053774954 , average speed: 0.07863801826187022 , explore ratio: 0.0499340670765195\n",
      "Episode 1423 , steps =  323 , total reward: 14.455940387506011 , steps_avg: 247.4943820224719 , reward_avg: -12.08213696115664 , distance traveled: 72.77574325631373 , average speed: 0.2253118986263583 , explore ratio: 0.0499340670765195\n",
      "Episode 1424 , steps =  367 , total reward: 38.31833858741503 , steps_avg: 247.5782456140351 , reward_avg: -12.046768206385714 , distance traveled: 112.98109384641052 , average speed: 0.30785039195207226 , explore ratio: 0.0499340670765195\n",
      "Episode 1425 , steps =  585 , total reward: -13.346686988252342 , steps_avg: 247.81486676016831 , reward_avg: -12.047679790384217 , distance traveled: 73.03957837720398 , average speed: 0.12485398013197262 , explore ratio: 0.0499340670765195\n",
      "Episode 1426 , steps =  63 , total reward: -4.823797957072037 , steps_avg: 247.68535388927822 , reward_avg: -12.042617504586522 , distance traveled: 8.857030093073847 , average speed: 0.14058777925514043 , explore ratio: 0.0499340670765195\n",
      "Episode 1427 , steps =  332 , total reward: 6.709550236476568 , steps_avg: 247.74439775910363 , reward_avg: -12.029485734459728 , distance traveled: 64.87336297569792 , average speed: 0.1954016957099335 , explore ratio: 0.0499340670765195\n",
      "Episode 1428 , steps =  52 , total reward: -3.116410475127402 , steps_avg: 247.6074177746676 , reward_avg: -12.023248452962644 , distance traveled: 8.066443144977091 , average speed: 0.15512390663417483 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1429 , steps =  48 , total reward: -6.277310001766935 , steps_avg: 247.46783216783217 , reward_avg: -12.019230314185583 , distance traveled: 6.294909380078316 , average speed: 0.13114394541829824 , explore ratio: 0.0499340670765195\n",
      "Episode 1430 , steps =  61 , total reward: -0.791963171184065 , steps_avg: 247.33752620545073 , reward_avg: -12.011384564959167 , distance traveled: 10.71953389942646 , average speed: 0.17573006392502394 , explore ratio: 0.0499340670765195\n",
      "Episode 1431 , steps =  334 , total reward: -20.649882648914943 , steps_avg: 247.39804469273744 , reward_avg: -12.017417035688187 , distance traveled: 28.20190730340779 , average speed: 0.08443684821379578 , explore ratio: 0.0499340670765195\n",
      "Episode 1432 , steps =  83 , total reward: -4.227646085428079 , steps_avg: 247.28332170272157 , reward_avg: -12.011981047586122 , distance traveled: 10.199240434630775 , average speed: 0.12288241487506958 , explore ratio: 0.0499340670765195\n",
      "Episode 1433 , steps =  221 , total reward: -14.117236529301154 , steps_avg: 247.2649930264993 , reward_avg: -12.013449147643104 , distance traveled: 19.27624273141846 , average speed: 0.0872228177892238 , explore ratio: 0.0499340670765195\n",
      "Episode 1434 , steps =  520 , total reward: -20.264140469174123 , steps_avg: 247.45505226480836 , reward_avg: -12.01919875832013 , distance traveled: 58.45838354922831 , average speed: 0.1124199683639006 , explore ratio: 0.0499340670765195\n",
      "Episode 1435 , steps =  76 , total reward: -28.127573017597207 , steps_avg: 247.33565459610028 , reward_avg: -12.030416289141355 , distance traveled: -5.537791992161657 , average speed: -0.07286568410739022 , explore ratio: 0.0499340670765195\n",
      "Episode 1436 , steps =  233 , total reward: 27.515804737144418 , steps_avg: 247.32567849686848 , reward_avg: -12.002896302345052 , distance traveled: 76.83984895616774 , average speed: 0.3297847594685311 , explore ratio: 0.0499340670765195\n",
      "Episode 1437 , steps =  203 , total reward: -2.679556198424983 , steps_avg: 247.29485396383868 , reward_avg: -11.996412755680296 , distance traveled: 33.485470763146864 , average speed: 0.16495305794653628 , explore ratio: 0.0499340670765195\n",
      "Episode 1438 , steps =  426 , total reward: -7.535008036858626 , steps_avg: 247.41904100069493 , reward_avg: -11.993312404937543 , distance traveled: 62.01963525105272 , average speed: 0.1455859982419078 , explore ratio: 0.0499340670765195\n",
      "Episode 1439 , steps =  363 , total reward: 16.155666974717228 , steps_avg: 247.49930555555557 , reward_avg: -11.97376450259056 , distance traveled: 84.7352291688602 , average speed: 0.23343038338528982 , explore ratio: 0.0499340670765195\n",
      "Episode 1440 , steps =  175 , total reward: -0.9652670905056158 , steps_avg: 247.44899375433727 , reward_avg: -11.966125017918745 , distance traveled: 30.224039947092535 , average speed: 0.17270879969767164 , explore ratio: 0.0499340670765195\n",
      "Episode 1441 , steps =  63 , total reward: -9.452682237467421 , steps_avg: 247.32108183079058 , reward_avg: -11.964381992412191 , distance traveled: 1.0509844926756342 , average speed: 0.016682293534533876 , explore ratio: 0.0499340670765195\n",
      "Episode 1442 , steps =  259 , total reward: 21.613311781598856 , steps_avg: 247.32917532917534 , reward_avg: -11.941112627357436 , distance traveled: 72.98586458086967 , average speed: 0.28179870494544274 , explore ratio: 0.0499340670765195\n",
      "Episode 1443 , steps =  79 , total reward: -26.9167210489406 , steps_avg: 247.21260387811634 , reward_avg: -11.951483547316982 , distance traveled: -3.4359080982953305 , average speed: -0.04349250757335862 , explore ratio: 0.0499340670765195\n",
      "Episode 1444 , steps =  62 , total reward: -23.304992016966146 , steps_avg: 247.08442906574393 , reward_avg: -11.959340646603938 , distance traveled: -11.417952984273436 , average speed: -0.18416053200441027 , explore ratio: 0.0499340670765195\n",
      "Episode 1445 , steps =  84 , total reward: -3.032700473124785 , steps_avg: 246.9716459197787 , reward_avg: -11.953167313150633 , distance traveled: 14.841991868913176 , average speed: 0.17669037939182353 , explore ratio: 0.0499340670765195\n",
      "Episode 1446 , steps =  238 , total reward: 8.702243125518761 , steps_avg: 246.96544574982724 , reward_avg: -11.93889266875625 , distance traveled: 51.968946226537234 , average speed: 0.21835691691822368 , explore ratio: 0.0499340670765195\n",
      "Episode 1447 , steps =  65 , total reward: -26.626301096410806 , steps_avg: 246.83977900552486 , reward_avg: -11.949035906620653 , distance traveled: -6.594707913994787 , average speed: -0.10145704483068903 , explore ratio: 0.0499340670765195\n",
      "Episode 1448 , steps =  148 , total reward: 6.827989604798448 , steps_avg: 246.77156659765356 , reward_avg: -11.936077296881924 , distance traveled: 37.381606887280945 , average speed: 0.25257842491406046 , explore ratio: 0.0499340670765195\n",
      "Episode 1449 , steps =  75 , total reward: -6.963714919509371 , steps_avg: 246.65310344827586 , reward_avg: -11.932648081449251 , distance traveled: 5.0300047049671415 , average speed: 0.06706672939956189 , explore ratio: 0.0499340670765195\n",
      "Episode 1450 , steps =  43 , total reward: -21.796500762257736 , steps_avg: 246.51274982770502 , reward_avg: -11.939446050216178 , distance traveled: -3.593583945035934 , average speed: -0.08357171965199847 , explore ratio: 0.0499340670765195\n",
      "Episode 1451 , steps =  65 , total reward: -6.721274376856169 , steps_avg: 246.38774104683196 , reward_avg: -11.935852268071992 , distance traveled: 9.853756350874901 , average speed: 0.15159625155192155 , explore ratio: 0.0499340670765195\n",
      "Episode 1452 , steps =  363 , total reward: 12.807657082198267 , steps_avg: 246.467997247075 , reward_avg: -11.918823011808898 , distance traveled: 78.40014822430909 , average speed: 0.2159783697639369 , explore ratio: 0.0499340670765195\n",
      "Episode 1453 , steps =  350 , total reward: -23.028427653250407 , steps_avg: 246.53920220082532 , reward_avg: -11.926463730269314 , distance traveled: 25.30348781816661 , average speed: 0.07229567948047602 , explore ratio: 0.0499340670765195\n",
      "Episode 1454 , steps =  697 , total reward: 37.254588128161146 , steps_avg: 246.8487972508591 , reward_avg: -11.892662320057335 , distance traveled: 163.12775160457954 , average speed: 0.234042685228952 , explore ratio: 0.0499340670765195\n",
      "Episode 1455 , steps =  59 , total reward: -0.8753654988314986 , steps_avg: 246.71978021978023 , reward_avg: -11.885095495317481 , distance traveled: 11.04758674308658 , average speed: 0.18724723293367085 , explore ratio: 0.0499340670765195\n",
      "Episode 1456 , steps =  75 , total reward: 1.4158485555586688 , steps_avg: 246.601921757035 , reward_avg: -11.875966501459638 , distance traveled: 15.363789034187793 , average speed: 0.20485052045583724 , explore ratio: 0.0499340670765195\n",
      "Episode 1457 , steps =  83 , total reward: -27.12205690742843 , steps_avg: 246.4897119341564 , reward_avg: -11.886423353589931 , distance traveled: -13.13691479627509 , average speed: -0.1582760818828324 , explore ratio: 0.0499340670765195\n",
      "Episode 1458 , steps =  271 , total reward: -7.468610062081893 , steps_avg: 246.50651130911584 , reward_avg: -11.883395380120769 , distance traveled: 34.3797263244912 , average speed: 0.12686245876196015 , explore ratio: 0.0499340670765195\n",
      "Episode 1459 , steps =  53 , total reward: -4.601890338330847 , steps_avg: 246.3739726027397 , reward_avg: -11.878408047900365 , distance traveled: 6.414232432813151 , average speed: 0.12102325344930473 , explore ratio: 0.0499340670765195\n",
      "Episode 1460 , steps =  912 , total reward: -17.35445578241928 , steps_avg: 246.82956878850104 , reward_avg: -11.882156198300446 , distance traveled: 119.96701060483349 , average speed: 0.13154277478600163 , explore ratio: 0.0499340670765195\n",
      "Episode 1461 , steps =  372 , total reward: -21.084477807953128 , steps_avg: 246.91518467852256 , reward_avg: -11.888450535926747 , distance traveled: 33.82457162775797 , average speed: 0.09092626781655368 , explore ratio: 0.0499340670765195\n",
      "Episode 1462 , steps =  80 , total reward: -7.397426998838784 , steps_avg: 246.8010936431989 , reward_avg: -11.885380800084583 , distance traveled: 3.916815555095672 , average speed: 0.0489601944386959 , explore ratio: 0.0499340670765195\n",
      "Episode 1463 , steps =  551 , total reward: 33.01612869723605 , steps_avg: 247.00887978142077 , reward_avg: -11.854710370100074 , distance traveled: 140.17005380374843 , average speed: 0.2543921121665126 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1464 , steps =  214 , total reward: 24.1281431359966 , steps_avg: 246.9863481228669 , reward_avg: -11.830148695351886 , distance traveled: 68.72249703805893 , average speed: 0.32113316372924733 , explore ratio: 0.0499340670765195\n",
      "Episode 1465 , steps =  54 , total reward: -2.661160249019663 , steps_avg: 246.85470668485675 , reward_avg: -11.823894269399407 , distance traveled: 9.022531294226647 , average speed: 0.16708391285604904 , explore ratio: 0.0499340670765195\n",
      "Episode 1466 , steps =  220 , total reward: -3.580940127773234 , steps_avg: 246.83640081799592 , reward_avg: -11.818275350420793 , distance traveled: 33.00519237503876 , average speed: 0.15002360170472165 , explore ratio: 0.0499340670765195\n",
      "Episode 1467 , steps =  389 , total reward: 54.93437396500371 , steps_avg: 246.93324250681198 , reward_avg: -11.772803518462057 , distance traveled: 141.59122678533194 , average speed: 0.3639877295252749 , explore ratio: 0.0499340670765195\n",
      "Episode 1468 , steps =  469 , total reward: -11.815982995916796 , steps_avg: 247.08441116405717 , reward_avg: -11.77283291225202 , distance traveled: 59.817817949540895 , average speed: 0.12754332185403175 , explore ratio: 0.0499340670765195\n",
      "Episode 1469 , steps =  215 , total reward: 32.71900148115112 , steps_avg: 247.0625850340136 , reward_avg: -11.742566358242902 , distance traveled: 84.72295034806005 , average speed: 0.3940602341770235 , explore ratio: 0.0499340670765195\n",
      "Episode 1470 , steps =  58 , total reward: -0.8433085893162842 , steps_avg: 246.93405846363018 , reward_avg: -11.735156937597813 , distance traveled: 10.849720941781998 , average speed: 0.18706415416865513 , explore ratio: 0.0499340670765195\n",
      "Episode 1471 , steps =  57 , total reward: -2.631090351404625 , steps_avg: 246.80502717391303 , reward_avg: -11.728972109753931 , distance traveled: 11.570371067225933 , average speed: 0.20298896609168304 , explore ratio: 0.0499340670765195\n",
      "Episode 1472 , steps =  119 , total reward: 2.5951702085584287 , steps_avg: 246.7182620502376 , reward_avg: -11.719247641106062 , distance traveled: 24.22934447564184 , average speed: 0.2036079367700995 , explore ratio: 0.0499340670765195\n",
      "Episode 1473 , steps =  79 , total reward: -25.763334568442794 , steps_avg: 246.6044776119403 , reward_avg: -11.728775515547946 , distance traveled: -6.736669504344463 , average speed: -0.08527429752334763 , explore ratio: 0.0499340670765195\n",
      "Episode 1474 , steps =  56 , total reward: -0.39307631043531116 , steps_avg: 246.47525423728814 , reward_avg: -11.72109029574787 , distance traveled: 9.961332179903982 , average speed: 0.1778809317839997 , explore ratio: 0.0499340670765195\n",
      "Episode 1475 , steps =  137 , total reward: -5.738599438073745 , steps_avg: 246.40108401084012 , reward_avg: -11.717037117660015 , distance traveled: 15.293191641212909 , average speed: 0.1116291360672475 , explore ratio: 0.0499340670765195\n",
      "Episode 1476 , steps =  198 , total reward: -8.224332827556903 , steps_avg: 246.36831415030468 , reward_avg: -11.714672388959878 , distance traveled: 23.520415990976616 , average speed: 0.11878997975240715 , explore ratio: 0.0499340670765195\n",
      "Episode 1477 , steps =  104 , total reward: 0.6004908197789093 , steps_avg: 246.27198917456022 , reward_avg: -11.706340072851123 , distance traveled: 18.306761426813903 , average speed: 0.1760265521809029 , explore ratio: 0.0499340670765195\n",
      "Episode 1478 , steps =  50 , total reward: -2.0898323416399482 , steps_avg: 246.1392832995267 , reward_avg: -11.699838039226234 , distance traveled: 6.8005191814899435 , average speed: 0.13601038362979886 , explore ratio: 0.0499340670765195\n",
      "Episode 1479 , steps =  156 , total reward: 10.580495843463876 , steps_avg: 246.07837837837837 , reward_avg: -11.684783759575767 , distance traveled: 41.383339927755294 , average speed: 0.2652778200497134 , explore ratio: 0.0499340670765195\n",
      "Episode 1480 , steps =  288 , total reward: 15.821103664204458 , steps_avg: 246.10668467251858 , reward_avg: -11.66621124949894 , distance traveled: 72.24916042563974 , average speed: 0.2508651403668047 , explore ratio: 0.0499340670765195\n",
      "Episode 1481 , steps =  53 , total reward: -0.5571773887431875 , steps_avg: 245.97638326585695 , reward_avg: -11.658715275233925 , distance traveled: 8.307595597207547 , average speed: 0.15674708673976503 , explore ratio: 0.0499340670765195\n",
      "Episode 1482 , steps =  389 , total reward: 35.8782039394645 , steps_avg: 246.07282535401214 , reward_avg: -11.626660710692658 , distance traveled: 117.73713933806859 , average speed: 0.3026661679641866 , explore ratio: 0.0499340670765195\n",
      "Episode 1483 , steps =  57 , total reward: -8.94185800419127 , steps_avg: 245.9454177897574 , reward_avg: -11.624851544448383 , distance traveled: -0.20101459168014127 , average speed: -0.0035265717838621276 , explore ratio: 0.0499340670765195\n",
      "Episode 1484 , steps =  202 , total reward: 0.6251910866585726 , steps_avg: 245.9158249158249 , reward_avg: -11.61660235749141 , distance traveled: 36.081890213030846 , average speed: 0.17862321887639032 , explore ratio: 0.0499340670765195\n",
      "Episode 1485 , steps =  226 , total reward: 31.192884312574975 , steps_avg: 245.90242261103634 , reward_avg: -11.587793820028379 , distance traveled: 83.12373262401671 , average speed: 0.3678041266549412 , explore ratio: 0.0499340670765195\n",
      "Episode 1486 , steps =  77 , total reward: 2.5914330533898084 , steps_avg: 245.7888365837256 , reward_avg: -11.578258361471942 , distance traveled: 17.50374935030937 , average speed: 0.22732142013388792 , explore ratio: 0.0499340670765195\n",
      "Episode 1487 , steps =  50 , total reward: -15.21476837451259 , steps_avg: 245.65725806451613 , reward_avg: -11.580702252609738 , distance traveled: -3.676323191821575 , average speed: -0.07352646383643151 , explore ratio: 0.0499340670765195\n",
      "Episode 1488 , steps =  68 , total reward: -5.345964508504302 , steps_avg: 245.53794492948288 , reward_avg: -11.576515054662053 , distance traveled: 5.883932437822221 , average speed: 0.08652841820326795 , explore ratio: 0.0499340670765195\n",
      "Episode 1489 , steps =  182 , total reward: 12.212397477900597 , steps_avg: 245.49530201342282 , reward_avg: -11.56054934155295 , distance traveled: 48.05674578404054 , average speed: 0.26404805375846446 , explore ratio: 0.0499340670765195\n",
      "Episode 1490 , steps =  243 , total reward: 16.67346249625023 , steps_avg: 245.4936284372904 , reward_avg: -11.54161304924054 , distance traveled: 63.57741080330683 , average speed: 0.26163543540455486 , explore ratio: 0.0499340670765195\n",
      "Episode 1491 , steps =  61 , total reward: -1.7316994235335543 , steps_avg: 245.36997319034853 , reward_avg: -11.535038040108029 , distance traveled: 11.56384922683239 , average speed: 0.189571298800531 , explore ratio: 0.0499340670765195\n",
      "Episode 1492 , steps =  606 , total reward: -12.255414234062341 , steps_avg: 245.61152042866712 , reward_avg: -11.53552054258221 , distance traveled: 78.79732789047526 , average speed: 0.13002859387867205 , explore ratio: 0.0499340670765195\n",
      "Episode 1493 , steps =  205 , total reward: -28.900811447370707 , steps_avg: 245.5843373493976 , reward_avg: -11.547143896601481 , distance traveled: -0.4223637122567736 , average speed: -0.0020603107914964566 , explore ratio: 0.0499340670765195\n",
      "Episode 1494 , steps =  91 , total reward: 3.6038092984091428 , steps_avg: 245.4809364548495 , reward_avg: -11.537009479748631 , distance traveled: 23.387829177081592 , average speed: 0.25700911183606145 , explore ratio: 0.0499340670765195\n",
      "Episode 1495 , steps =  123 , total reward: -2.970830834943196 , steps_avg: 245.399064171123 , reward_avg: -11.531283424504776 , distance traveled: 18.968464199602597 , average speed: 0.15421515609433006 , explore ratio: 0.0499340670765195\n",
      "Episode 1496 , steps =  40 , total reward: -14.2794726182986 , steps_avg: 245.26185704742818 , reward_avg: -11.533119222229422 , distance traveled: -1.2283926322404295 , average speed: -0.03070981580601074 , explore ratio: 0.0499340670765195\n",
      "Episode 1497 , steps =  59 , total reward: -0.11012403578683932 , steps_avg: 245.13751668891857 , reward_avg: -11.525493724775187 , distance traveled: 10.81600913465023 , average speed: 0.18332218872288525 , explore ratio: 0.0499340670765195\n",
      "Episode 1498 , steps =  169 , total reward: -8.459376009611377 , steps_avg: 245.08672448298867 , reward_avg: -11.52344828267034 , distance traveled: 16.044648555815215 , average speed: 0.0949387488509776 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1499 , steps =  46 , total reward: -2.7580389411790893 , steps_avg: 244.954 , reward_avg: -11.517604676442682 , distance traveled: 6.725071935653686 , average speed: 0.14619721599247143 , explore ratio: 0.0499340670765195\n",
      "Episode 1500 , steps =  411 , total reward: -0.5611869941788359 , steps_avg: 245.06462358427714 , reward_avg: -11.510305264262625 , distance traveled: 64.56999463970772 , average speed: 0.15710460982897254 , explore ratio: 0.0499340670765195\n",
      "Episode 1501 , steps =  56 , total reward: -5.954207260088385 , steps_avg: 244.9387483355526 , reward_avg: -11.506606131104055 , distance traveled: 7.673113611638545 , average speed: 0.13701988592211686 , explore ratio: 0.0499340670765195\n",
      "Episode 1502 , steps =  103 , total reward: -6.207423538845665 , steps_avg: 244.8443113772455 , reward_avg: -11.503080394183055 , distance traveled: 11.206509316731244 , average speed: 0.1088010613274878 , explore ratio: 0.0499340670765195\n",
      "Episode 1503 , steps =  85 , total reward: -27.644004837696762 , steps_avg: 244.7380319148936 , reward_avg: -11.513812391818371 , distance traveled: -6.034438248462974 , average speed: -0.07099339115838793 , explore ratio: 0.0499340670765195\n",
      "Episode 1504 , steps =  81 , total reward: -27.44429140452111 , steps_avg: 244.62923588039868 , reward_avg: -11.52439742770721 , distance traveled: -5.451622920110822 , average speed: -0.06730398666803483 , explore ratio: 0.0499340670765195\n",
      "Episode 1505 , steps =  160 , total reward: 7.350564607946813 , steps_avg: 244.5730411686587 , reward_avg: -11.511864252384731 , distance traveled: 40.33773380769867 , average speed: 0.2521108362981167 , explore ratio: 0.0499340670765195\n",
      "Episode 1506 , steps =  78 , total reward: 1.7555620995530226 , steps_avg: 244.46250829462508 , reward_avg: -11.503060386192335 , distance traveled: 17.062729366421703 , average speed: 0.21875294059515005 , explore ratio: 0.0499340670765195\n",
      "Episode 1507 , steps =  1062 , total reward: -40.97806720331594 , steps_avg: 245.00464190981432 , reward_avg: -11.522606146681147 , distance traveled: 109.22903170113247 , average speed: 0.1028521955754543 , explore ratio: 0.0499340670765195\n",
      "Episode 1508 , steps =  60 , total reward: -7.615352616260453 , steps_avg: 244.88204108681245 , reward_avg: -11.520016846793524 , distance traveled: 2.8862266839668154 , average speed: 0.04810377806611359 , explore ratio: 0.0499340670765195\n",
      "Episode 1509 , steps =  38 , total reward: -15.014879552943 , steps_avg: 244.74503311258277 , reward_avg: -11.522331325406867 , distance traveled: -0.9712187455315144 , average speed: -0.025558388040303012 , explore ratio: 0.0499340670765195\n",
      "Episode 1510 , steps =  291 , total reward: 17.869127019468717 , steps_avg: 244.77564526803442 , reward_avg: -11.502879665350696 , distance traveled: 73.16195610612633 , average speed: 0.2514156567220836 , explore ratio: 0.0499340670765195\n",
      "Episode 1511 , steps =  286 , total reward: 37.8658241040992 , steps_avg: 244.80291005291005 , reward_avg: -11.470228406243915 , distance traveled: 98.76201894700525 , average speed: 0.3453217445699484 , explore ratio: 0.0499340670765195\n",
      "Episode 1512 , steps =  58 , total reward: -0.8331056123139979 , steps_avg: 244.67944481163252 , reward_avg: -11.463197921912172 , distance traveled: 9.875272981524471 , average speed: 0.1702633272676633 , explore ratio: 0.0499340670765195\n",
      "Episode 1513 , steps =  412 , total reward: 34.08002174486158 , steps_avg: 244.7899603698811 , reward_avg: -11.433116535078106 , distance traveled: 113.86025430511674 , average speed: 0.27635984054639984 , explore ratio: 0.0499340670765195\n",
      "Episode 1514 , steps =  68 , total reward: -0.9642620343379669 , steps_avg: 244.67326732673268 , reward_avg: -11.42620640009412 , distance traveled: 12.172219542860983 , average speed: 0.17900322857148504 , explore ratio: 0.0499340670765195\n",
      "Episode 1515 , steps =  254 , total reward: 27.216104570988506 , steps_avg: 244.67941952506595 , reward_avg: -11.400716749057786 , distance traveled: 82.68291962608703 , average speed: 0.32552330561451587 , explore ratio: 0.0499340670765195\n",
      "Episode 1516 , steps =  181 , total reward: -9.551150306908422 , steps_avg: 244.63744232036916 , reward_avg: -11.399497522662172 , distance traveled: 17.645502481330187 , average speed: 0.09748896398524966 , explore ratio: 0.0499340670765195\n",
      "Episode 1517 , steps =  37 , total reward: -10.639956323270997 , steps_avg: 244.5006587615283 , reward_avg: -11.398997166140832 , distance traveled: 2.3661392048746355 , average speed: 0.06394970823985502 , explore ratio: 0.0499340670765195\n",
      "Episode 1518 , steps =  358 , total reward: 18.845307946524425 , steps_avg: 244.57537853851218 , reward_avg: -11.379086497863897 , distance traveled: 84.21013318552173 , average speed: 0.23522383571374783 , explore ratio: 0.0499340670765195\n",
      "Episode 1519 , steps =  58 , total reward: -10.445903057956453 , steps_avg: 244.45263157894738 , reward_avg: -11.378472561390273 , distance traveled: 3.2392320347204806 , average speed: 0.05584882818483587 , explore ratio: 0.0499340670765195\n",
      "Episode 1520 , steps =  57 , total reward: -7.219979543902601 , steps_avg: 244.32938856015778 , reward_avg: -11.375738509439262 , distance traveled: 1.8881463679857553 , average speed: 0.03312537487694307 , explore ratio: 0.0499340670765195\n",
      "Episode 1521 , steps =  1020 , total reward: 41.21820898670976 , steps_avg: 244.83902759526939 , reward_avg: -11.34118269636689 , distance traveled: 227.40432020947338 , average speed: 0.22294541197007195 , explore ratio: 0.0499340670765195\n",
      "Episode 1522 , steps =  251 , total reward: 0.25955026969808337 , steps_avg: 244.84307288246882 , reward_avg: -11.333565668812023 , distance traveled: 41.97152078012935 , average speed: 0.16721721426346356 , explore ratio: 0.0499340670765195\n",
      "Episode 1523 , steps =  77 , total reward: -14.308190812396512 , steps_avg: 244.73293963254594 , reward_avg: -11.335517522580778 , distance traveled: 1.4354455774649981 , average speed: 0.018642150356688286 , explore ratio: 0.0499340670765195\n",
      "Episode 1524 , steps =  212 , total reward: 27.54998245039083 , steps_avg: 244.71147540983605 , reward_avg: -11.310018834073913 , distance traveled: 77.38623508125544 , average speed: 0.36502941076063883 , explore ratio: 0.0499340670765195\n",
      "Episode 1525 , steps =  72 , total reward: -25.659465210198118 , steps_avg: 244.59829619921362 , reward_avg: -11.31942214100453 , distance traveled: -11.22162032313645 , average speed: -0.1558558378213396 , explore ratio: 0.0499340670765195\n",
      "Episode 1526 , steps =  81 , total reward: -29.582329356587806 , steps_avg: 244.4911591355599 , reward_avg: -11.331382132632287 , distance traveled: -9.871753239892424 , average speed: -0.12187349678879536 , explore ratio: 0.0499340670765195\n",
      "Episode 1527 , steps =  61 , total reward: -2.7661918343553955 , steps_avg: 244.3710732984293 , reward_avg: -11.325776641599383 , distance traveled: 11.862196834087369 , average speed: 0.19446224318176014 , explore ratio: 0.0499340670765195\n",
      "Episode 1528 , steps =  205 , total reward: -3.305244611386847 , steps_avg: 244.3453237410072 , reward_avg: -11.32053103530101 , distance traveled: 31.800785974496964 , average speed: 0.1551257852414486 , explore ratio: 0.0499340670765195\n",
      "Episode 1529 , steps =  56 , total reward: -0.8746761930404843 , steps_avg: 244.22222222222223 , reward_avg: -11.313703679194957 , distance traveled: 10.247040030956267 , average speed: 0.18298285769564762 , explore ratio: 0.0499340670765195\n",
      "Episode 1530 , steps =  53 , total reward: -1.539836829857899 , steps_avg: 244.09732201175703 , reward_avg: -11.307319703460577 , distance traveled: 6.972133943438529 , average speed: 0.13154969704601 , explore ratio: 0.0499340670765195\n",
      "Episode 1531 , steps =  386 , total reward: 76.7013512446129 , steps_avg: 244.18994778067886 , reward_avg: -11.249872790309093 , distance traveled: 170.9867308817106 , average speed: 0.44297080539303263 , explore ratio: 0.0499340670765195\n",
      "Episode 1532 , steps =  88 , total reward: -27.9465696751519 , steps_avg: 244.0880626223092 , reward_avg: -11.260764308172655 , distance traveled: -10.65219548678957 , average speed: -0.1210476759862451 , explore ratio: 0.0499340670765195\n",
      "Episode 1533 , steps =  754 , total reward: 73.31119562801092 , steps_avg: 244.42046936114733 , reward_avg: -11.205632652412431 , distance traveled: 222.04698521990346 , average speed: 0.29449202283806825 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1534 , steps =  90 , total reward: -10.6645692899699 , steps_avg: 244.3198697068404 , reward_avg: -11.205280168137225 , distance traveled: 5.781400107443333 , average speed: 0.0642377789715926 , explore ratio: 0.0499340670765195\n",
      "Episode 1535 , steps =  650 , total reward: 68.24295454649247 , steps_avg: 244.583984375 , reward_avg: -11.153556056994887 , distance traveled: 204.42917768212044 , average speed: 0.3145064272032622 , explore ratio: 0.0499340670765195\n",
      "Episode 1536 , steps =  279 , total reward: 16.87138407253783 , steps_avg: 244.60637605725438 , reward_avg: -11.135322524054398 , distance traveled: 71.08423745173494 , average speed: 0.2547822130886557 , explore ratio: 0.0499340670765195\n",
      "Episode 1537 , steps =  64 , total reward: -2.7166740982408317 , steps_avg: 244.4889466840052 , reward_avg: -11.129848760448537 , distance traveled: 8.447224640250203 , average speed: 0.13198788500390943 , explore ratio: 0.0499340670765195\n",
      "Episode 1538 , steps =  74 , total reward: 3.183852556765078 , steps_avg: 244.37816764132555 , reward_avg: -11.120548109820067 , distance traveled: 17.03654049217701 , average speed: 0.2302235201645542 , explore ratio: 0.0499340670765195\n",
      "Episode 1539 , steps =  65 , total reward: -8.319452874784668 , steps_avg: 244.26168831168832 , reward_avg: -11.118729216810305 , distance traveled: 1.944106462150812 , average speed: 0.02990933018693557 , explore ratio: 0.0499340670765195\n",
      "Episode 1540 , steps =  61 , total reward: -0.11704268984000432 , steps_avg: 244.14276443867618 , reward_avg: -11.111589900439787 , distance traveled: 11.523641434907912 , average speed: 0.1889121546706215 , explore ratio: 0.0499340670765195\n",
      "Episode 1541 , steps =  145 , total reward: -2.3855012844813444 , steps_avg: 244.07846952010377 , reward_avg: -11.10593095840609 , distance traveled: 24.34589053876698 , average speed: 0.16790269337080677 , explore ratio: 0.0499340670765195\n",
      "Episode 1542 , steps =  331 , total reward: 63.83881060178551 , steps_avg: 244.1348023331173 , reward_avg: -11.057360160246537 , distance traveled: 143.6221515867859 , average speed: 0.4339037812289604 , explore ratio: 0.0499340670765195\n",
      "Episode 1543 , steps =  89 , total reward: 3.23170149552139 , steps_avg: 244.03432642487047 , reward_avg: -11.048105586635288 , distance traveled: 18.827377260625365 , average speed: 0.2115435647261277 , explore ratio: 0.0499340670765195\n",
      "Episode 1544 , steps =  907 , total reward: 10.357021050069099 , steps_avg: 244.46343042071197 , reward_avg: -11.034251135737744 , distance traveled: 158.31000290582782 , average speed: 0.17454245083332726 , explore ratio: 0.0499340670765195\n",
      "Episode 1545 , steps =  438 , total reward: 65.25813445150146 , steps_avg: 244.58861578266493 , reward_avg: -10.98490289150279 , distance traveled: 161.91954733796422 , average speed: 0.3696793318218361 , explore ratio: 0.0499340670765195\n",
      "Episode 1546 , steps =  107 , total reward: 9.581483377578971 , steps_avg: 244.49967679379444 , reward_avg: -10.971608524166603 , distance traveled: 34.58902315936982 , average speed: 0.32326189868569927 , explore ratio: 0.0499340670765195\n",
      "Episode 1547 , steps =  508 , total reward: 27.869630739787606 , steps_avg: 244.66989664082686 , reward_avg: -10.946517284332009 , distance traveled: 123.69891084574168 , average speed: 0.2435017930034285 , explore ratio: 0.0499340670765195\n",
      "Episode 1548 , steps =  36 , total reward: -16.703364318042357 , steps_avg: 244.53518398967074 , reward_avg: -10.950233776929625 , distance traveled: -1.707598550319672 , average speed: -0.04743329306443533 , explore ratio: 0.0499340670765195\n",
      "Episode 1549 , steps =  58 , total reward: 0.8232677026086805 , steps_avg: 244.4148387096774 , reward_avg: -10.942637969523473 , distance traveled: 11.359171505570409 , average speed: 0.19584778457880014 , explore ratio: 0.0499340670765195\n",
      "Episode 1550 , steps =  75 , total reward: 4.437196984173107 , steps_avg: 244.3056092843327 , reward_avg: -10.932721892828631 , distance traveled: 19.87652812242508 , average speed: 0.2650203749656677 , explore ratio: 0.0499340670765195\n",
      "Episode 1551 , steps =  74 , total reward: 1.0333836377517596 , steps_avg: 244.1958762886598 , reward_avg: -10.925011773285734 , distance traveled: 14.40360806196928 , average speed: 0.19464335218877404 , explore ratio: 0.0499340670765195\n",
      "Episode 1552 , steps =  559 , total reward: -28.461092808217245 , steps_avg: 244.39858338699293 , reward_avg: -10.936303518961799 , distance traveled: 56.020971419652994 , average speed: 0.10021640683301072 , explore ratio: 0.0499340670765195\n",
      "Episode 1553 , steps =  175 , total reward: 16.3789791658707 , steps_avg: 244.35392535392535 , reward_avg: -10.918726116976707 , distance traveled: 54.93743317477402 , average speed: 0.31392818957013724 , explore ratio: 0.0499340670765195\n",
      "Episode 1554 , steps =  43 , total reward: -13.712168435725076 , steps_avg: 244.22443729903537 , reward_avg: -10.920522542905163 , distance traveled: -2.8995562398433687 , average speed: -0.06743154046147369 , explore ratio: 0.0499340670765195\n",
      "Episode 1555 , steps =  71 , total reward: -5.338324029996374 , steps_avg: 244.11311053984576 , reward_avg: -10.9169350117272 , distance traveled: 7.867842228692025 , average speed: 0.11081467927735246 , explore ratio: 0.0499340670765195\n",
      "Episode 1556 , steps =  551 , total reward: 22.951196606837815 , steps_avg: 244.3102119460501 , reward_avg: -10.895182839846298 , distance traveled: 120.83862793831608 , average speed: 0.21930785469748834 , explore ratio: 0.0499340670765195\n",
      "Episode 1557 , steps =  63 , total reward: 1.035656497670336 , steps_avg: 244.19383825417202 , reward_avg: -10.887525048230435 , distance traveled: 12.212264526486397 , average speed: 0.19384546867438726 , explore ratio: 0.0499340670765195\n",
      "Episode 1558 , steps =  125 , total reward: -5.52860078223671 , steps_avg: 244.11738293778063 , reward_avg: -10.884087636898816 , distance traveled: 15.674007613705472 , average speed: 0.12539206090964378 , explore ratio: 0.0499340670765195\n",
      "Episode 1559 , steps =  271 , total reward: 35.16271678084388 , steps_avg: 244.1346153846154 , reward_avg: -10.854570454579749 , distance traveled: 93.6207811139524 , average speed: 0.3454641369518539 , explore ratio: 0.0499340670765195\n",
      "Episode 1560 , steps =  577 , total reward: 30.29313681623343 , steps_avg: 244.3478539397822 , reward_avg: -10.828210616481856 , distance traveled: 133.7512109699822 , average speed: 0.23180452507795873 , explore ratio: 0.0499340670765195\n",
      "Episode 1561 , steps =  169 , total reward: -6.70104001998158 , steps_avg: 244.29961587708067 , reward_avg: -10.825568381784992 , distance traveled: 22.99711039118701 , average speed: 0.13607757627921307 , explore ratio: 0.0499340670765195\n",
      "Episode 1562 , steps =  365 , total reward: 48.80270503855609 , steps_avg: 244.37683941138835 , reward_avg: -10.787418494759821 , distance traveled: 128.20183603003622 , average speed: 0.35123790693160606 , explore ratio: 0.0499340670765195\n",
      "Episode 1563 , steps =  235 , total reward: 25.752179053264342 , steps_avg: 244.3708439897698 , reward_avg: -10.764055580726557 , distance traveled: 73.56536742031572 , average speed: 0.31304411668219456 , explore ratio: 0.0499340670765195\n",
      "Episode 1564 , steps =  238 , total reward: 1.4270820511157174 , steps_avg: 244.3667731629393 , reward_avg: -10.756265716425062 , distance traveled: 41.772681443095216 , average speed: 0.17551546824829922 , explore ratio: 0.0499340670765195\n",
      "Episode 1565 , steps =  325 , total reward: 14.495889280438407 , steps_avg: 244.41826309067687 , reward_avg: -10.740140457806374 , distance traveled: 75.62660520059524 , average speed: 0.23269724677106227 , explore ratio: 0.0499340670765195\n",
      "Episode 1566 , steps =  781 , total reward: 22.20238019930134 , steps_avg: 244.76068921506064 , reward_avg: -10.719117789869484 , distance traveled: 158.47307489309463 , average speed: 0.20291046721266917 , explore ratio: 0.0499340670765195\n",
      "Episode 1567 , steps =  35 , total reward: -15.455229171542456 , steps_avg: 244.62691326530611 , reward_avg: -10.722138269066978 , distance traveled: -1.5735165856964888 , average speed: -0.04495761673418539 , explore ratio: 0.0499340670765195\n",
      "Episode 1568 , steps =  54 , total reward: -0.45124057890412805 , steps_avg: 244.50541746335244 , reward_avg: -10.715592126498361 , distance traveled: 9.607242470383644 , average speed: 0.1779118975996971 , explore ratio: 0.0499340670765195\n",
      "Episode 1569 , steps =  40 , total reward: -13.935190903544424 , steps_avg: 244.3751592356688 , reward_avg: -10.71764282635635 , distance traveled: -2.052159352898598 , average speed: -0.05130398382246495 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1570 , steps =  935 , total reward: 27.63838214115594 , steps_avg: 244.81476766390833 , reward_avg: -10.693227788184798 , distance traveled: 191.82909004779998 , average speed: 0.2051648021901604 , explore ratio: 0.0499340670765195\n",
      "Episode 1571 , steps =  622 , total reward: 62.366145579228515 , steps_avg: 245.05470737913487 , reward_avg: -10.646752359834025 , distance traveled: 185.74571624340464 , average speed: 0.29862655344598815 , explore ratio: 0.0499340670765195\n",
      "Episode 1572 , steps =  1687 , total reward: 32.6729887383069 , steps_avg: 245.97139224411953 , reward_avg: -10.619212791430884 , distance traveled: 310.0315464158915 , average speed: 0.1837768502761657 , explore ratio: 0.0499340670765195\n",
      "Episode 1573 , steps =  730 , total reward: 14.412489797019967 , steps_avg: 246.27890724269378 , reward_avg: -10.6033095496339 , distance traveled: 139.95436677306887 , average speed: 0.19171831064803954 , explore ratio: 0.0499340670765195\n",
      "Episode 1574 , steps =  389 , total reward: 20.482386833834106 , steps_avg: 246.3695238095238 , reward_avg: -10.58357259954916 , distance traveled: 94.10682829722761 , average speed: 0.2419198670879887 , explore ratio: 0.0499340670765195\n",
      "Episode 1575 , steps =  83 , total reward: -18.916713409918053 , steps_avg: 246.26586294416245 , reward_avg: -10.588860125444063 , distance traveled: -5.493228434622289 , average speed: -0.06618347511593119 , explore ratio: 0.0499340670765195\n",
      "Episode 1576 , steps =  309 , total reward: -29.072211055338443 , steps_avg: 246.30564362714014 , reward_avg: -10.600580703078746 , distance traveled: 26.20419648062903 , average speed: 0.08480322485640462 , explore ratio: 0.0499340670765195\n",
      "Episode 1577 , steps =  193 , total reward: -12.182052241011785 , steps_avg: 246.2718631178707 , reward_avg: -10.601582903039414 , distance traveled: 14.842788155470043 , average speed: 0.07690563811124375 , explore ratio: 0.0499340670765195\n",
      "Episode 1578 , steps =  231 , total reward: 36.869968091074256 , steps_avg: 246.26219126029133 , reward_avg: -10.571518589553591 , distance traveled: 90.841949535124 , average speed: 0.3932551927927446 , explore ratio: 0.0499340670765195\n",
      "Episode 1579 , steps =  56 , total reward: -1.2763110756979614 , steps_avg: 246.14177215189872 , reward_avg: -10.565635546823303 , distance traveled: 9.91731793820858 , average speed: 0.17709496318229606 , explore ratio: 0.0499340670765195\n",
      "Episode 1580 , steps =  130 , total reward: 9.955099236400173 , steps_avg: 246.06831119544592 , reward_avg: -10.552655954930055 , distance traveled: 35.22494771450757 , average speed: 0.2709611362654429 , explore ratio: 0.0499340670765195\n",
      "Episode 1581 , steps =  46 , total reward: -12.50471408851258 , steps_avg: 245.9418457648546 , reward_avg: -10.553889872840033 , distance traveled: -1.7558716626092796 , average speed: -0.03817112310020173 , explore ratio: 0.0499340670765195\n",
      "Episode 1582 , steps =  847 , total reward: 31.754538446385418 , steps_avg: 246.32154137713204 , reward_avg: -10.527163133535403 , distance traveled: 178.1449544332595 , average speed: 0.21032462152687073 , explore ratio: 0.0499340670765195\n",
      "Episode 1583 , steps =  35 , total reward: -9.123046865991002 , steps_avg: 246.18813131313132 , reward_avg: -10.526276696497813 , distance traveled: -2.91113013625145 , average speed: -0.08317514675004144 , explore ratio: 0.0499340670765195\n",
      "Episode 1584 , steps =  81 , total reward: -27.841178741679848 , steps_avg: 246.08391167192428 , reward_avg: -10.537200924917487 , distance traveled: -5.399894537106158 , average speed: -0.06666536465563158 , explore ratio: 0.0499340670765195\n",
      "Episode 1585 , steps =  59 , total reward: -5.495192523349076 , steps_avg: 245.9659520807062 , reward_avg: -10.534021852785349 , distance traveled: 4.17574256144464 , average speed: 0.07077529765160406 , explore ratio: 0.0499340670765195\n",
      "Episode 1586 , steps =  69 , total reward: 1.540906977552296 , steps_avg: 245.85444234404537 , reward_avg: -10.526413201978583 , distance traveled: 16.05121988475323 , average speed: 0.23262637514135118 , explore ratio: 0.0499340670765195\n",
      "Episode 1587 , steps =  97 , total reward: 0.870727229901275 , steps_avg: 245.76070528967256 , reward_avg: -10.519236161404352 , distance traveled: 16.221982579529286 , average speed: 0.16723693380958027 , explore ratio: 0.0499340670765195\n",
      "Episode 1588 , steps =  211 , total reward: -8.653073070674528 , steps_avg: 245.73882945248585 , reward_avg: -10.51806173529313 , distance traveled: 24.280190386343758 , average speed: 0.11507199235234009 , explore ratio: 0.0499340670765195\n",
      "Episode 1589 , steps =  59 , total reward: -9.093514140371235 , steps_avg: 245.62138364779875 , reward_avg: -10.517165793409532 , distance traveled: 3.1756724460236727 , average speed: 0.05382495671226564 , explore ratio: 0.0499340670765195\n",
      "Episode 1590 , steps =  37 , total reward: -16.692438556132203 , steps_avg: 245.49025769956003 , reward_avg: -10.521047171638774 , distance traveled: -2.4978425413370124 , average speed: -0.06750925787397331 , explore ratio: 0.0499340670765195\n",
      "Episode 1591 , steps =  53 , total reward: -0.10048054716922344 , steps_avg: 245.36934673366835 , reward_avg: -10.514501589588228 , distance traveled: 8.727055247426033 , average speed: 0.16466141976275533 , explore ratio: 0.0499340670765195\n",
      "Episode 1592 , steps =  570 , total reward: 20.42187863426901 , steps_avg: 245.5731324544884 , reward_avg: -10.495081388568856 , distance traveled: 117.22753830023812 , average speed: 0.2056623478951546 , explore ratio: 0.0499340670765195\n",
      "Episode 1593 , steps =  445 , total reward: 57.199039631942014 , steps_avg: 245.69824341279798 , reward_avg: -10.452613307627507 , distance traveled: 152.05071160823104 , average speed: 0.3416869923780473 , explore ratio: 0.0499340670765195\n",
      "Episode 1594 , steps =  55 , total reward: -13.803570002987984 , steps_avg: 245.57868338557995 , reward_avg: -10.454714220916136 , distance traveled: -3.3146979609131817 , average speed: -0.06026723565296694 , explore ratio: 0.0499340670765195\n",
      "Episode 1595 , steps =  59 , total reward: -14.339829477129506 , steps_avg: 245.46177944862154 , reward_avg: -10.457148503658123 , distance traveled: -1.1084872253146025 , average speed: -0.018787919073128857 , explore ratio: 0.0499340670765195\n",
      "Episode 1596 , steps =  64 , total reward: 0.8984844576083099 , steps_avg: 245.34815278647463 , reward_avg: -10.450037900676742 , distance traveled: 12.789702621102334 , average speed: 0.19983910345472397 , explore ratio: 0.0499340670765195\n",
      "Episode 1597 , steps =  51 , total reward: -14.463809175241117 , steps_avg: 245.22653316645807 , reward_avg: -10.452549647406755 , distance traveled: -6.902588816285132 , average speed: -0.13534487875068885 , explore ratio: 0.0499340670765195\n",
      "Episode 1598 , steps =  145 , total reward: 1.7740885006015419 , steps_avg: 245.16385240775486 , reward_avg: -10.44490321954684 , distance traveled: 28.370090435296305 , average speed: 0.19565579610549175 , explore ratio: 0.0499340670765195\n",
      "Episode 1599 , steps =  326 , total reward: 20.557349990204575 , steps_avg: 245.214375 , reward_avg: -10.425526811290744 , distance traveled: 84.05057884657289 , average speed: 0.2578238614925549 , explore ratio: 0.0499340670765195\n",
      "Episode 1600 , steps =  246 , total reward: 2.3025322551950604 , steps_avg: 245.2148657089319 , reward_avg: -10.41757674316677 , distance traveled: 43.660767886117085 , average speed: 0.1774827962850288 , explore ratio: 0.0499340670765195\n",
      "Episode 1601 , steps =  460 , total reward: 6.160983761440306 , steps_avg: 245.3489388264669 , reward_avg: -10.407228078681996 , distance traveled: 83.87051399208605 , average speed: 0.18232720433062183 , explore ratio: 0.0499340670765195\n",
      "Episode 1602 , steps =  254 , total reward: -2.606297359098855 , steps_avg: 245.35433562071117 , reward_avg: -10.402361621589304 , distance traveled: 38.7835917647509 , average speed: 0.15269130616043664 , explore ratio: 0.0499340670765195\n",
      "Episode 1603 , steps =  323 , total reward: 54.18000903850649 , steps_avg: 245.40274314214463 , reward_avg: -10.362098298235132 , distance traveled: 131.874540304525 , average speed: 0.4082803105403251 , explore ratio: 0.0499340670765195\n",
      "Episode 1604 , steps =  154 , total reward: 0.5406035448747283 , steps_avg: 245.34579439252337 , reward_avg: -10.355305337585218 , distance traveled: 28.202250079885133 , average speed: 0.18313149402522813 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1605 , steps =  176 , total reward: -14.810927878259387 , steps_avg: 245.30261519302616 , reward_avg: -10.35807969782225 , distance traveled: 11.996390927927575 , average speed: 0.06816131209049758 , explore ratio: 0.0499340670765195\n",
      "Episode 1606 , steps =  448 , total reward: 1.3420607577197146 , steps_avg: 245.42874922215307 , reward_avg: -10.350798963251286 , distance traveled: 74.04592452311896 , average speed: 0.1652810815248191 , explore ratio: 0.0499340670765195\n",
      "Episode 1607 , steps =  226 , total reward: 18.057250365505052 , steps_avg: 245.41666666666666 , reward_avg: -10.333132265907532 , distance traveled: 62.7062806955364 , average speed: 0.2774614190067982 , explore ratio: 0.0499340670765195\n",
      "Episode 1608 , steps =  140 , total reward: -2.1030295884485177 , steps_avg: 245.35114978247358 , reward_avg: -10.328017223845716 , distance traveled: 20.812843614835288 , average speed: 0.1486631686773949 , explore ratio: 0.0499340670765195\n",
      "Episode 1609 , steps =  106 , total reward: -8.065454559730995 , steps_avg: 245.26459627329191 , reward_avg: -10.326611905420801 , distance traveled: 8.808670080816377 , average speed: 0.08310066113977714 , explore ratio: 0.0499340670765195\n",
      "Episode 1610 , steps =  104 , total reward: -1.881734871863089 , steps_avg: 245.17690875232773 , reward_avg: -10.321369896088983 , distance traveled: 23.769977620840073 , average speed: 0.22855747712346225 , explore ratio: 0.0499340670765195\n",
      "Episode 1611 , steps =  102 , total reward: -1.0925999492493883 , steps_avg: 245.08808933002481 , reward_avg: -10.315644852697645 , distance traveled: 17.583813770525154 , average speed: 0.17239033108357993 , explore ratio: 0.0499340670765195\n",
      "Episode 1612 , steps =  68 , total reward: -5.9531033074520545 , steps_avg: 244.97830130192187 , reward_avg: -10.3129402392164 , distance traveled: 4.620281160548329 , average speed: 0.06794531118453424 , explore ratio: 0.0499340670765195\n",
      "Episode 1613 , steps =  35 , total reward: -8.466248283792911 , steps_avg: 244.84820322180917 , reward_avg: -10.311796068240302 , distance traveled: -2.2540517216920852 , average speed: -0.06440147776263101 , explore ratio: 0.0499340670765195\n",
      "Episode 1614 , steps =  531 , total reward: -0.5051477378525039 , steps_avg: 245.02538699690402 , reward_avg: -10.305723840171948 , distance traveled: 83.80177726612834 , average speed: 0.15781878957839612 , explore ratio: 0.0499340670765195\n",
      "Episode 1615 , steps =  281 , total reward: 26.594722448732075 , steps_avg: 245.0476485148515 , reward_avg: -10.282889405587232 , distance traveled: 83.30523833323265 , average speed: 0.29645992289406636 , explore ratio: 0.0499340670765195\n",
      "Episode 1616 , steps =  91 , total reward: 0.28069225210882043 , steps_avg: 244.95238095238096 , reward_avg: -10.276356578340666 , distance traveled: 15.234762685596943 , average speed: 0.16741497456699936 , explore ratio: 0.0499340670765195\n",
      "Episode 1617 , steps =  125 , total reward: 0.9874871357033556 , steps_avg: 244.87824474660073 , reward_avg: -10.269394993844966 , distance traveled: 25.939528698027132 , average speed: 0.20751622958421706 , explore ratio: 0.0499340670765195\n",
      "Episode 1618 , steps =  684 , total reward: 6.139466552676659 , steps_avg: 245.14947498455837 , reward_avg: -10.259259810678492 , distance traveled: 118.78667757494365 , average speed: 0.17366473329670123 , explore ratio: 0.0499340670765195\n",
      "Episode 1619 , steps =  216 , total reward: 25.79078304285676 , steps_avg: 245.13148148148147 , reward_avg: -10.237006697805938 , distance traveled: 75.58125589795412 , average speed: 0.3499132217497876 , explore ratio: 0.0499340670765195\n",
      "Episode 1620 , steps =  206 , total reward: 26.397335765084193 , steps_avg: 245.10734114743985 , reward_avg: -10.214406856681393 , distance traveled: 75.19556597672407 , average speed: 0.3650270193044858 , explore ratio: 0.0499340670765195\n",
      "Episode 1621 , steps =  59 , total reward: -12.934159841396541 , steps_avg: 244.99260172626387 , reward_avg: -10.21608364643769 , distance traveled: -1.340343010453507 , average speed: -0.02271767814327978 , explore ratio: 0.0499340670765195\n",
      "Episode 1622 , steps =  59 , total reward: -0.7104268389555303 , steps_avg: 244.87800369685766 , reward_avg: -10.210226803056617 , distance traveled: 10.648192359209059 , average speed: 0.1804778365967637 , explore ratio: 0.0499340670765195\n",
      "Episode 1623 , steps =  181 , total reward: 12.587621384621896 , steps_avg: 244.8386699507389 , reward_avg: -10.196188719197208 , distance traveled: 48.514056821465495 , average speed: 0.2680334631020193 , explore ratio: 0.0499340670765195\n",
      "Episode 1624 , steps =  52 , total reward: -13.533261992412314 , steps_avg: 244.72 , reward_avg: -10.198242302749955 , distance traveled: -4.515392507314682 , average speed: -0.08683447129451312 , explore ratio: 0.0499340670765195\n",
      "Episode 1625 , steps =  81 , total reward: -0.52356765878822 , steps_avg: 244.61931119311194 , reward_avg: -10.192292318344077 , distance traveled: 13.227957488000392 , average speed: 0.1633081171358073 , explore ratio: 0.0499340670765195\n",
      "Episode 1626 , steps =  368 , total reward: -5.148188637306326 , steps_avg: 244.69514443761526 , reward_avg: -10.189192070230346 , distance traveled: 50.548015960380454 , average speed: 0.13735873902277299 , explore ratio: 0.0499340670765195\n",
      "Episode 1627 , steps =  75 , total reward: -5.177953403123344 , steps_avg: 244.5909090909091 , reward_avg: -10.18611391380092 , distance traveled: 10.821030511781574 , average speed: 0.14428040682375431 , explore ratio: 0.0499340670765195\n",
      "Episode 1628 , steps =  375 , total reward: 39.94042712316216 , steps_avg: 244.670963781461 , reward_avg: -10.155342556503827 , distance traveled: 121.44917265447285 , average speed: 0.32386446041192757 , explore ratio: 0.0499340670765195\n",
      "Episode 1629 , steps =  67 , total reward: -12.109813726279894 , steps_avg: 244.56196319018406 , reward_avg: -10.156541618571175 , distance traveled: -1.689625240210444 , average speed: -0.02521828716732006 , explore ratio: 0.0499340670765195\n",
      "Episode 1630 , steps =  326 , total reward: -2.506237412530955 , steps_avg: 244.61189454322502 , reward_avg: -10.151851058052449 , distance traveled: 51.95646738465351 , average speed: 0.15937566682409052 , explore ratio: 0.0499340670765195\n",
      "Episode 1631 , steps =  110 , total reward: -5.207265168400488 , steps_avg: 244.52941176470588 , reward_avg: -10.148821287286731 , distance traveled: 14.747615561708809 , average speed: 0.13406923237917098 , explore ratio: 0.0499340670765195\n",
      "Episode 1632 , steps =  342 , total reward: 30.87128589405428 , steps_avg: 244.58909981628904 , reward_avg: -10.123701809527184 , distance traveled: 102.91081065655217 , average speed: 0.3009088030893338 , explore ratio: 0.0499340670765195\n",
      "Episode 1633 , steps =  282 , total reward: 29.198515803929354 , steps_avg: 244.61199510403918 , reward_avg: -10.099636804867787 , distance traveled: 90.59976780870932 , average speed: 0.3212757723713096 , explore ratio: 0.0499340670765195\n",
      "Episode 1634 , steps =  196 , total reward: 6.539871644991121 , steps_avg: 244.5822629969419 , reward_avg: -10.089459735479494 , distance traveled: 45.507111578565095 , average speed: 0.23217914070696477 , explore ratio: 0.0499340670765195\n",
      "Episode 1635 , steps =  311 , total reward: 13.535699067710562 , steps_avg: 244.6228606356968 , reward_avg: -10.075018929365074 , distance traveled: 69.32844161689283 , average speed: 0.22292103413791908 , explore ratio: 0.0499340670765195\n",
      "Episode 1636 , steps =  257 , total reward: 4.462357177036495 , steps_avg: 244.63042150274893 , reward_avg: -10.06613843082726 , distance traveled: 49.47675806427374 , average speed: 0.19251656834347758 , explore ratio: 0.0499340670765195\n",
      "Episode 1637 , steps =  334 , total reward: 27.815595039996726 , steps_avg: 244.6849816849817 , reward_avg: -10.0430116094165 , distance traveled: 94.20051467468497 , average speed: 0.2820374690858831 , explore ratio: 0.0499340670765195\n",
      "Episode 1638 , steps =  289 , total reward: 16.81431954583275 , steps_avg: 244.71201952410007 , reward_avg: -10.026625196265035 , distance traveled: 73.49569522507488 , average speed: 0.25431036410060515 , explore ratio: 0.0499340670765195\n",
      "Episode 1639 , steps =  94 , total reward: 2.333466569490728 , steps_avg: 244.62012195121952 , reward_avg: -10.019088554944455 , distance traveled: 23.11921974465251 , average speed: 0.24594914621970757 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1640 , steps =  190 , total reward: -28.530465205681207 , steps_avg: 244.58683729433272 , reward_avg: -10.030369101349534 , distance traveled: 9.950983610423284 , average speed: 0.052373597949596236 , explore ratio: 0.0499340670765195\n",
      "Episode 1641 , steps =  43 , total reward: -3.8724568465140963 , steps_avg: 244.4640682095006 , reward_avg: -10.026618850280816 , distance traveled: 4.5792827099561695 , average speed: 0.10649494674316673 , explore ratio: 0.0499340670765195\n",
      "Episode 1642 , steps =  138 , total reward: 0.5935115286360112 , steps_avg: 244.39926962872795 , reward_avg: -10.020154985168876 , distance traveled: 25.804223671993242 , average speed: 0.18698712805792203 , explore ratio: 0.0499340670765195\n",
      "Episode 1643 , steps =  103 , total reward: -11.259260429361841 , steps_avg: 244.3132603406326 , reward_avg: -10.020908698942717 , distance traveled: 1.5429092500358799 , average speed: 0.014979701456659028 , explore ratio: 0.0499340670765195\n",
      "Episode 1644 , steps =  73 , total reward: -24.247449647185725 , steps_avg: 244.20911854103343 , reward_avg: -10.029557052102742 , distance traveled: -2.966743429899214 , average speed: -0.040640320957523485 , explore ratio: 0.0499340670765195\n",
      "Episode 1645 , steps =  592 , total reward: 37.38347445674928 , steps_avg: 244.42041312272175 , reward_avg: -10.000752051186064 , distance traveled: 144.28296431017117 , average speed: 0.24372122349691075 , explore ratio: 0.0499340670765195\n",
      "Episode 1646 , steps =  201 , total reward: -10.301238573156004 , steps_avg: 244.3940497874924 , reward_avg: -10.00093449594743 , distance traveled: 18.889361519319937 , average speed: 0.09397692298169123 , explore ratio: 0.0499340670765195\n",
      "Episode 1647 , steps =  140 , total reward: -14.98171410553779 , steps_avg: 244.33070388349515 , reward_avg: -10.003956813671696 , distance traveled: 18.880688694119456 , average speed: 0.13486206210085325 , explore ratio: 0.0499340670765195\n",
      "Episode 1648 , steps =  162 , total reward: 1.9393593694648268 , steps_avg: 244.28077622801698 , reward_avg: -9.996714050674038 , distance traveled: 28.130195628264925 , average speed: 0.17364318289052422 , explore ratio: 0.0499340670765195\n",
      "Episode 1649 , steps =  52 , total reward: -22.72439090146932 , steps_avg: 244.16424242424242 , reward_avg: -10.004427794219975 , distance traveled: -3.7933854165673266 , average speed: -0.07294971954937167 , explore ratio: 0.0499340670765195\n",
      "Episode 1650 , steps =  256 , total reward: 23.483632362871738 , steps_avg: 244.17141126589945 , reward_avg: -9.984144293216286 , distance traveled: 74.52729139049535 , average speed: 0.29112223199412246 , explore ratio: 0.0499340670765195\n",
      "Episode 1651 , steps =  54 , total reward: -11.838200582398104 , steps_avg: 244.05629539951573 , reward_avg: -9.985266603318697 , distance traveled: 1.3728527025505903 , average speed: 0.025423198195381302 , explore ratio: 0.0499340670765195\n",
      "Episode 1652 , steps =  210 , total reward: 1.213356032616761 , steps_avg: 244.0356926799758 , reward_avg: -9.978491876981167 , distance traveled: 35.61977246001362 , average speed: 0.16961796409530297 , explore ratio: 0.0499340670765195\n",
      "Episode 1653 , steps =  62 , total reward: -7.3346899777427375 , steps_avg: 243.92563482466747 , reward_avg: -9.976893447779693 , distance traveled: 5.608046062812211 , average speed: 0.09045235585180986 , explore ratio: 0.0499340670765195\n",
      "Episode 1654 , steps =  76 , total reward: -13.962205822667736 , steps_avg: 243.82416918429004 , reward_avg: -9.979301491510743 , distance traveled: 8.505615009292958 , average speed: 0.11191598696438103 , explore ratio: 0.0499340670765195\n",
      "Episode 1655 , steps =  378 , total reward: 10.804833499456418 , steps_avg: 243.90519323671498 , reward_avg: -9.966750685356777 , distance traveled: 77.46510474250654 , average speed: 0.2049341395304406 , explore ratio: 0.0499340670765195\n",
      "Episode 1656 , steps =  113 , total reward: -33.770188341035826 , steps_avg: 243.82619191309595 , reward_avg: -9.98111606716467 , distance traveled: -6.860842936299741 , average speed: -0.060715424215041953 , explore ratio: 0.0499340670765195\n",
      "Episode 1657 , steps =  66 , total reward: -3.137244847834118 , steps_avg: 243.7189384800965 , reward_avg: -9.976988279939501 , distance traveled: 7.62554082110524 , average speed: 0.11553849728947332 , explore ratio: 0.0499340670765195\n",
      "Episode 1658 , steps =  511 , total reward: 51.27127449275136 , steps_avg: 243.88004822182037 , reward_avg: -9.940069495869164 , distance traveled: 153.28878931850187 , average speed: 0.29997806128865334 , explore ratio: 0.0499340670765195\n",
      "Episode 1659 , steps =  51 , total reward: -0.7953939753783292 , steps_avg: 243.76385542168674 , reward_avg: -9.93456065519417 , distance traveled: 7.667083546221256 , average speed: 0.15033497149453443 , explore ratio: 0.0499340670765195\n",
      "Episode 1660 , steps =  229 , total reward: 0.08681852293943754 , steps_avg: 243.75496688741723 , reward_avg: -9.928527314328345 , distance traveled: 37.6092874244973 , average speed: 0.1642326961768441 , explore ratio: 0.0499340670765195\n",
      "Episode 1661 , steps =  258 , total reward: 30.597966749605444 , steps_avg: 243.76353790613717 , reward_avg: -9.904143142208047 , distance traveled: 85.75192515771835 , average speed: 0.33237180293689284 , explore ratio: 0.0499340670765195\n",
      "Episode 1662 , steps =  46 , total reward: -2.8337176014184955 , steps_avg: 243.6446181599519 , reward_avg: -9.899891533344075 , distance traveled: 5.5591823440790185 , average speed: 0.12085179008867432 , explore ratio: 0.0499340670765195\n",
      "Episode 1663 , steps =  51 , total reward: -24.208133717413382 , steps_avg: 243.52884615384616 , reward_avg: -9.908490236579693 , distance traveled: -6.193020015209913 , average speed: -0.12143176500411594 , explore ratio: 0.0499340670765195\n",
      "Episode 1664 , steps =  134 , total reward: 6.840640703453361 , steps_avg: 243.46306306306306 , reward_avg: -9.898430698477572 , distance traveled: 34.56723701661452 , average speed: 0.25796445534786955 , explore ratio: 0.0499340670765195\n",
      "Episode 1665 , steps =  57 , total reward: -10.515784144310906 , steps_avg: 243.35114045618246 , reward_avg: -9.898801258769188 , distance traveled: -1.516938842944801 , average speed: -0.026612962156926333 , explore ratio: 0.0499340670765195\n",
      "Episode 1666 , steps =  382 , total reward: 30.43093234084914 , steps_avg: 243.43431313737253 , reward_avg: -9.87460825720973 , distance traveled: 107.59381028171627 , average speed: 0.28165918921915256 , explore ratio: 0.0499340670765195\n",
      "Episode 1667 , steps =  264 , total reward: 29.11021756194647 , steps_avg: 243.44664268585132 , reward_avg: -9.85123605947642 , distance traveled: 85.18080345701422 , average speed: 0.3226545585492963 , explore ratio: 0.0499340670765195\n",
      "Episode 1668 , steps =  80 , total reward: 2.271490986250953 , steps_avg: 243.34871180347514 , reward_avg: -9.843972592103308 , distance traveled: 18.21885961373336 , average speed: 0.227735745171667 , explore ratio: 0.0499340670765195\n",
      "Episode 1669 , steps =  40 , total reward: -13.210947942056999 , steps_avg: 243.22694610778444 , reward_avg: -9.845988745007471 , distance traveled: -0.34020225875079635 , average speed: -0.008505056468769909 , explore ratio: 0.0499340670765195\n",
      "Episode 1670 , steps =  208 , total reward: -25.12977109276739 , steps_avg: 243.20586475164572 , reward_avg: -9.855135233545926 , distance traveled: 0.2603749593347303 , average speed: 0.0012518026891092803 , explore ratio: 0.0499340670765195\n",
      "Episode 1671 , steps =  51 , total reward: -4.7975190160311785 , steps_avg: 243.0909090909091 , reward_avg: -9.852110343463682 , distance traveled: 2.1934302860498436 , average speed: 0.04300843698136948 , explore ratio: 0.0499340670765195\n",
      "Episode 1672 , steps =  450 , total reward: 22.961272787619325 , steps_avg: 243.21458457860132 , reward_avg: -9.832496844879651 , distance traveled: 106.52667735627152 , average speed: 0.23672594968060337 , explore ratio: 0.0499340670765195\n",
      "Episode 1673 , steps =  224 , total reward: 23.17676039358727 , steps_avg: 243.2031063321386 , reward_avg: -9.812778053219875 , distance traveled: 76.07824482053522 , average speed: 0.3396350215202465 , explore ratio: 0.0499340670765195\n",
      "Episode 1674 , steps =  99 , total reward: -9.086474498332171 , steps_avg: 243.11701492537313 , reward_avg: -9.812344439157256 , distance traveled: 6.38579995505512 , average speed: 0.06450302984904162 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1675 , steps =  90 , total reward: -31.813793546250096 , steps_avg: 243.02565632458234 , reward_avg: -9.825471795426402 , distance traveled: -9.039867061078546 , average speed: -0.10044296734531717 , explore ratio: 0.0499340670765195\n",
      "Episode 1676 , steps =  97 , total reward: 6.50504656762878 , steps_avg: 242.93858079904592 , reward_avg: -9.815733859610626 , distance traveled: 27.24817181289196 , average speed: 0.2809089877617728 , explore ratio: 0.0499340670765195\n",
      "Episode 1677 , steps =  692 , total reward: 19.90307210151185 , steps_avg: 243.2061978545888 , reward_avg: -9.79802300981258 , distance traveled: 140.49640837529688 , average speed: 0.2030294918718163 , explore ratio: 0.0499340670765195\n",
      "Episode 1678 , steps =  90 , total reward: -5.958832798395312 , steps_avg: 243.11494937462774 , reward_avg: -9.795736416476418 , distance traveled: 8.762988010793924 , average speed: 0.09736653345326582 , explore ratio: 0.0499340670765195\n",
      "Episode 1679 , steps =  52 , total reward: -12.650094689021511 , steps_avg: 243.0011904761905 , reward_avg: -9.797435439257695 , distance traveled: 0.6153116366497126 , average speed: 0.011832916089417549 , explore ratio: 0.0499340670765195\n",
      "Episode 1680 , steps =  47 , total reward: -3.1562308226736864 , steps_avg: 242.88459250446164 , reward_avg: -9.793484692906366 , distance traveled: 4.437952014505863 , average speed: 0.09442451094693326 , explore ratio: 0.0499340670765195\n",
      "Episode 1681 , steps =  243 , total reward: -4.609852582226221 , steps_avg: 242.884661117717 , reward_avg: -9.790402866443417 , distance traveled: 36.447027971211355 , average speed: 0.1499877694288533 , explore ratio: 0.0499340670765195\n",
      "Episode 1682 , steps =  465 , total reward: -30.23863469540103 , steps_avg: 243.01663695781343 , reward_avg: -9.802552736811188 , distance traveled: 33.652937274430876 , average speed: 0.07237190811705564 , explore ratio: 0.0499340670765195\n",
      "Episode 1683 , steps =  46 , total reward: -26.510301864114297 , steps_avg: 242.89964370546318 , reward_avg: -9.812474203038802 , distance traveled: -6.19999682695605 , average speed: -0.13478253971643586 , explore ratio: 0.0499340670765195\n",
      "Episode 1684 , steps =  254 , total reward: -24.00995709611596 , steps_avg: 242.90623145400593 , reward_avg: -9.820900008910066 , distance traveled: 13.413611198561265 , average speed: 0.052809492907721516 , explore ratio: 0.0499340670765195\n",
      "Episode 1685 , steps =  58 , total reward: -5.512334135687598 , steps_avg: 242.79655990510082 , reward_avg: -9.818344513137097 , distance traveled: 3.513517071381212 , average speed: 0.060577880541055375 , explore ratio: 0.0499340670765195\n",
      "Episode 1686 , steps =  362 , total reward: 25.82468135480516 , steps_avg: 242.86721991701245 , reward_avg: -9.797216459866238 , distance traveled: 94.29751048419622 , average speed: 0.2604903604535807 , explore ratio: 0.0499340670765195\n",
      "Episode 1687 , steps =  491 , total reward: -33.79587834511694 , steps_avg: 243.01421800947867 , reward_avg: -9.811433676622903 , distance traveled: 32.10328036854508 , average speed: 0.06538346307239323 , explore ratio: 0.0499340670765195\n",
      "Episode 1688 , steps =  642 , total reward: -21.94955016340671 , steps_avg: 243.25044404973357 , reward_avg: -9.818620246478902 , distance traveled: 70.9603253244551 , average speed: 0.1105301017514877 , explore ratio: 0.0499340670765195\n",
      "Episode 1689 , steps =  62 , total reward: -4.318990062207603 , steps_avg: 243.1431952662722 , reward_avg: -9.815366027434955 , distance traveled: 7.6552551286295065 , average speed: 0.12347185691337914 , explore ratio: 0.0499340670765195\n",
      "Episode 1690 , steps =  1099 , total reward: -52.40356085586798 , steps_avg: 243.64931992903607 , reward_avg: -9.840551240225276 , distance traveled: 100.69096980504698 , average speed: 0.09162053667429206 , explore ratio: 0.0499340670765195\n",
      "Episode 1691 , steps =  42 , total reward: -11.875581575749443 , steps_avg: 243.53014184397162 , reward_avg: -9.841753976830196 , distance traveled: -5.362724812030792 , average speed: -0.12768392409597124 , explore ratio: 0.0499340670765195\n",
      "Episode 1692 , steps =  77 , total reward: -8.986119809479147 , steps_avg: 243.4317779090372 , reward_avg: -9.84124858157482 , distance traveled: 5.369349361639467 , average speed: 0.06973180989142165 , explore ratio: 0.0499340670765195\n",
      "Episode 1693 , steps =  225 , total reward: -10.706281836964129 , steps_avg: 243.42089728453365 , reward_avg: -9.841759226944 , distance traveled: 23.68971280178055 , average speed: 0.105287612452358 , explore ratio: 0.0499340670765195\n",
      "Episode 1694 , steps =  229 , total reward: -19.39337492271818 , steps_avg: 243.41238938053098 , reward_avg: -9.84739439844593 , distance traveled: 10.805088354488836 , average speed: 0.04718379194099928 , explore ratio: 0.0499340670765195\n",
      "Episode 1695 , steps =  207 , total reward: 23.22877883616585 , steps_avg: 243.39091981132074 , reward_avg: -9.827891937812316 , distance traveled: 69.6885170214507 , average speed: 0.33665950251908555 , explore ratio: 0.0499340670765195\n",
      "Episode 1696 , steps =  199 , total reward: 28.739279445414073 , steps_avg: 243.36476134354743 , reward_avg: -9.805165260509295 , distance traveled: 76.27609700968489 , average speed: 0.383296969897914 , explore ratio: 0.0499340670765195\n",
      "Episode 1697 , steps =  89 , total reward: -12.640086880328138 , steps_avg: 243.273851590106 , reward_avg: -9.806834825656418 , distance traveled: 0.6759751155227421 , average speed: 0.007595226017109462 , explore ratio: 0.0499340670765195\n",
      "Episode 1698 , steps =  336 , total reward: 45.027380870399256 , steps_avg: 243.3284284873455 , reward_avg: -9.774560419714069 , distance traveled: 118.19844391923398 , average speed: 0.3517810830929583 , explore ratio: 0.0499340670765195\n",
      "Episode 1699 , steps =  40 , total reward: -15.315863877891882 , steps_avg: 243.20882352941177 , reward_avg: -9.777820009983584 , distance traveled: -2.1837480998039243 , average speed: -0.05459370249509811 , explore ratio: 0.0499340670765195\n",
      "Episode 1700 , steps =  95 , total reward: -14.376569867009918 , steps_avg: 243.1216931216931 , reward_avg: -9.780523566630867 , distance traveled: 2.904144239025191 , average speed: 0.030569939358159902 , explore ratio: 0.0499340670765195\n",
      "Episode 1701 , steps =  170 , total reward: -40.64267850178291 , steps_avg: 243.07873090481786 , reward_avg: -9.798656442620967 , distance traveled: -28.03518011044712 , average speed: -0.1649128241791007 , explore ratio: 0.0499340670765195\n",
      "Episode 1702 , steps =  309 , total reward: -49.969045006799064 , steps_avg: 243.1174398120963 , reward_avg: -9.822244457045029 , distance traveled: -3.555288622397928 , average speed: -0.011505788421999766 , explore ratio: 0.0499340670765195\n",
      "Episode 1703 , steps =  378 , total reward: -29.980518454435057 , steps_avg: 243.19659624413146 , reward_avg: -9.834074430048192 , distance traveled: 36.64887743895875 , average speed: 0.09695470221946759 , explore ratio: 0.0499340670765195\n",
      "Episode 1704 , steps =  259 , total reward: -0.2178587750954108 , steps_avg: 243.2058651026393 , reward_avg: -9.828434420866403 , distance traveled: 41.94164586313069 , average speed: 0.1619368566144042 , explore ratio: 0.0499340670765195\n",
      "Episode 1705 , steps =  260 , total reward: 6.338182653461878 , steps_avg: 243.21570926143025 , reward_avg: -9.818958091983443 , distance traveled: 51.888942995779225 , average speed: 0.19957285767607394 , explore ratio: 0.0499340670765195\n",
      "Episode 1706 , steps =  421 , total reward: -45.44784325636712 , steps_avg: 243.31985940246045 , reward_avg: -9.839830315278338 , distance traveled: 24.10361291407607 , average speed: 0.05725323732559637 , explore ratio: 0.0499340670765195\n",
      "Episode 1707 , steps =  304 , total reward: -3.770707309036851 , steps_avg: 243.35538641686182 , reward_avg: -9.836276964572106 , distance traveled: 47.009537265552204 , average speed: 0.15463663574194805 , explore ratio: 0.0499340670765195\n",
      "Episode 1708 , steps =  96 , total reward: -6.01160129131564 , steps_avg: 243.26916325336455 , reward_avg: -9.834039003382372 , distance traveled: 8.854534767363221 , average speed: 0.09223473716003355 , explore ratio: 0.0499340670765195\n",
      "Episode 1709 , steps =  233 , total reward: -5.505377831906717 , steps_avg: 243.26315789473685 , reward_avg: -9.831507622580338 , distance traveled: 34.35869420528409 , average speed: 0.14746220688963127 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1710 , steps =  71 , total reward: -24.1435803174954 , steps_avg: 243.1624780829924 , reward_avg: -9.83987236407357 , distance traveled: -2.4205084419250484 , average speed: -0.034091668196127446 , explore ratio: 0.0499340670765195\n",
      "Episode 1711 , steps =  226 , total reward: 5.2789622034833865 , steps_avg: 243.15245327102804 , reward_avg: -9.831041269115884 , distance traveled: 45.084600407872365 , average speed: 0.19948938233571842 , explore ratio: 0.0499340670765195\n",
      "Episode 1712 , steps =  135 , total reward: -5.490695935388418 , steps_avg: 243.0893169877408 , reward_avg: -9.828507500678214 , distance traveled: 15.850610567964608 , average speed: 0.11741193013307118 , explore ratio: 0.0499340670765195\n",
      "Episode 1713 , steps =  65 , total reward: -12.084766085560744 , steps_avg: 242.98541423570595 , reward_avg: -9.829823870914435 , distance traveled: -4.456505149304867 , average speed: -0.06856161768161334 , explore ratio: 0.0499340670765195\n",
      "Episode 1714 , steps =  301 , total reward: -12.161425605715497 , steps_avg: 243.01924198250728 , reward_avg: -9.831183405453677 , distance traveled: 34.522061657044105 , average speed: 0.11469123474101031 , explore ratio: 0.0499340670765195\n",
      "Episode 1715 , steps =  229 , total reward: -6.274862381330401 , steps_avg: 243.01107226107226 , reward_avg: -9.82911095730442 , distance traveled: 29.93224064818583 , average speed: 0.13070847444622632 , explore ratio: 0.0499340670765195\n",
      "Episode 1716 , steps =  119 , total reward: 1.053916825156651 , steps_avg: 242.93884682585906 , reward_avg: -9.822772560226692 , distance traveled: 21.42339302301407 , average speed: 0.18002851279843757 , explore ratio: 0.0499340670765195\n",
      "Episode 1717 , steps =  100 , total reward: -4.212810125499968 , steps_avg: 242.85564610011642 , reward_avg: -9.819507157179704 , distance traveled: 12.625708236694342 , average speed: 0.1262570823669434 , explore ratio: 0.0499340670765195\n",
      "Episode 1718 , steps =  368 , total reward: 4.5905088064193755 , steps_avg: 242.9284467713787 , reward_avg: -9.811124367206695 , distance traveled: 69.79136872189117 , average speed: 0.18965045848339993 , explore ratio: 0.0499340670765195\n",
      "Episode 1719 , steps =  318 , total reward: -37.063223832160155 , steps_avg: 242.9720930232558 , reward_avg: -9.82696861108167 , distance traveled: 5.543114711539827 , average speed: 0.017431178338175556 , explore ratio: 0.0499340670765195\n",
      "Episode 1720 , steps =  81 , total reward: -4.455562509408221 , steps_avg: 242.87797791981407 , reward_avg: -9.823847515148099 , distance traveled: 11.252365567982196 , average speed: 0.13891809343187897 , explore ratio: 0.0499340670765195\n",
      "Episode 1721 , steps =  68 , total reward: -7.3933012276273296 , steps_avg: 242.77642276422765 , reward_avg: -9.822436048082174 , distance traveled: 9.659442058391868 , average speed: 0.14205061850576275 , explore ratio: 0.0499340670765195\n",
      "Episode 1722 , steps =  116 , total reward: -13.147927164380752 , steps_avg: 242.70284387695878 , reward_avg: -9.824366106768363 , distance traveled: 3.187721261903645 , average speed: 0.027480355706065905 , explore ratio: 0.0499340670765195\n",
      "Episode 1723 , steps =  42 , total reward: -21.507565626569715 , steps_avg: 242.58642691415312 , reward_avg: -9.831142904633676 , distance traveled: -4.5553309978544725 , average speed: -0.10846026185367792 , explore ratio: 0.0499340670765195\n",
      "Episode 1724 , steps =  123 , total reward: -11.413083847799038 , steps_avg: 242.51710144927537 , reward_avg: -9.832059971847105 , distance traveled: 6.461908784061669 , average speed: 0.0525358437728591 , explore ratio: 0.0499340670765195\n",
      "Episode 1725 , steps =  787 , total reward: 7.2052828389845285 , steps_avg: 242.83256083429896 , reward_avg: -9.822188973694828 , distance traveled: 139.9445884572623 , average speed: 0.177820315701731 , explore ratio: 0.0499340670765195\n",
      "Episode 1726 , steps =  54 , total reward: -13.213563283897944 , steps_avg: 242.72321945570354 , reward_avg: -9.824152710990834 , distance traveled: 1.1944213297963149 , average speed: 0.022118913514746572 , explore ratio: 0.0499340670765195\n",
      "Episode 1727 , steps =  121 , total reward: -37.16751070505132 , steps_avg: 242.65277777777777 , reward_avg: -9.839976413533691 , distance traveled: -28.18800003290176 , average speed: -0.23295867795786576 , explore ratio: 0.0499340670765195\n",
      "Episode 1728 , steps =  376 , total reward: -16.85966006316682 , steps_avg: 242.7299016772701 , reward_avg: -9.844036380942386 , distance traveled: 38.122641541454996 , average speed: 0.10139000409961435 , explore ratio: 0.0499340670765195\n",
      "Episode 1729 , steps =  87 , total reward: 2.983766400796048 , steps_avg: 242.6398843930636 , reward_avg: -9.836621466039647 , distance traveled: 22.715597895383823 , average speed: 0.2610988263837221 , explore ratio: 0.0499340670765195\n",
      "Episode 1730 , steps =  59 , total reward: -9.000691677544888 , steps_avg: 242.53379549393415 , reward_avg: -9.836138548773041 , distance traveled: 2.498527373664546 , average speed: 0.04234792158753468 , explore ratio: 0.0499340670765195\n",
      "Episode 1731 , steps =  435 , total reward: 6.61271155323519 , steps_avg: 242.64491916859123 , reward_avg: -9.826641522155255 , distance traveled: 85.32514878417958 , average speed: 0.19614976731995304 , explore ratio: 0.0499340670765195\n",
      "Episode 1732 , steps =  63 , total reward: 0.8562031189749613 , steps_avg: 242.54125793421812 , reward_avg: -9.820477157099784 , distance traveled: 13.28290516734123 , average speed: 0.21083976456097192 , explore ratio: 0.0499340670765195\n",
      "Episode 1733 , steps =  60 , total reward: -7.824394152620814 , steps_avg: 242.43598615916954 , reward_avg: -9.819326013498584 , distance traveled: 3.666416927799583 , average speed: 0.06110694879665971 , explore ratio: 0.0499340670765195\n",
      "Episode 1734 , steps =  120 , total reward: -12.961060520686841 , steps_avg: 242.36541786743516 , reward_avg: -9.821136811485436 , distance traveled: 10.328228337764742 , average speed: 0.08606856948137284 , explore ratio: 0.0499340670765195\n",
      "Episode 1735 , steps =  44 , total reward: -14.516628998557106 , steps_avg: 242.25115207373273 , reward_avg: -9.823841588090893 , distance traveled: -2.155340275615454 , average speed: -0.048985006263987586 , explore ratio: 0.0499340670765195\n",
      "Episode 1736 , steps =  57 , total reward: -4.923788802607607 , steps_avg: 242.14450201496834 , reward_avg: -9.821020602031316 , distance traveled: 3.708112437939271 , average speed: 0.06505460417437317 , explore ratio: 0.0499340670765195\n",
      "Episode 1737 , steps =  279 , total reward: -7.207907365854231 , steps_avg: 242.1657077100115 , reward_avg: -9.819517084634207 , distance traveled: 39.9345247265976 , average speed: 0.14313449722794838 , explore ratio: 0.0499340670765195\n",
      "Episode 1738 , steps =  62 , total reward: -7.720301444436735 , steps_avg: 242.06210465784935 , reward_avg: -9.818309945105629 , distance traveled: 5.7639954109489935 , average speed: 0.09296766791853216 , explore ratio: 0.0499340670765195\n",
      "Episode 1739 , steps =  238 , total reward: 34.57822474187168 , steps_avg: 242.05977011494252 , reward_avg: -9.792794695285528 , distance traveled: 88.6469089102373 , average speed: 0.3724660038245265 , explore ratio: 0.0499340670765195\n",
      "Episode 1740 , steps =  279 , total reward: 20.945924251714104 , steps_avg: 242.08098793796668 , reward_avg: -9.775138911858186 , distance traveled: 82.48264376197014 , average speed: 0.2956367159927245 , explore ratio: 0.0499340670765195\n",
      "Episode 1741 , steps =  125 , total reward: 1.290652453505119 , steps_avg: 242.0137772675086 , reward_avg: -9.768786563198391 , distance traveled: 25.878208942115304 , average speed: 0.20702567153692242 , explore ratio: 0.0499340670765195\n",
      "Episode 1742 , steps =  71 , total reward: -15.42218046997488 , steps_avg: 241.9156626506024 , reward_avg: -9.772030047941236 , distance traveled: -7.793365012183784 , average speed: -0.10976570439695471 , explore ratio: 0.0499340670765195\n",
      "Episode 1743 , steps =  722 , total reward: 5.581048263812026 , steps_avg: 242.19094036697248 , reward_avg: -9.763226677349634 , distance traveled: 126.72126056919808 , average speed: 0.1755142113146788 , explore ratio: 0.0499340670765195\n",
      "Episode 1744 , steps =  159 , total reward: -2.581288485013583 , steps_avg: 242.1432664756447 , reward_avg: -9.759110953457178 , distance traveled: 24.55887552425264 , average speed: 0.15445833663051975 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1745 , steps =  665 , total reward: 33.28224035321136 , steps_avg: 242.38545246277204 , reward_avg: -9.734459549501468 , distance traveled: 157.32418813958984 , average speed: 0.236577726525699 , explore ratio: 0.0499340670765195\n",
      "Episode 1746 , steps =  178 , total reward: -8.053023297132313 , steps_avg: 242.34859759587866 , reward_avg: -9.733497078836116 , distance traveled: 19.95062012895941 , average speed: 0.11208213555595174 , explore ratio: 0.0499340670765195\n",
      "Episode 1747 , steps =  37 , total reward: -13.973270683427645 , steps_avg: 242.23112128146454 , reward_avg: -9.73592257860991 , distance traveled: -0.6900912835076453 , average speed: -0.0186511157704769 , explore ratio: 0.0499340670765195\n",
      "Episode 1748 , steps =  241 , total reward: -16.979247627594805 , steps_avg: 242.23041738136078 , reward_avg: -9.740063988014704 , distance traveled: 16.2099397018645 , average speed: 0.06726116058864938 , explore ratio: 0.0499340670765195\n",
      "Episode 1749 , steps =  258 , total reward: -21.388655760034233 , steps_avg: 242.23942857142856 , reward_avg: -9.746720326170145 , distance traveled: 15.68441823922097 , average speed: 0.060792318756670426 , explore ratio: 0.0499340670765195\n",
      "Episode 1750 , steps =  282 , total reward: -14.659992349687231 , steps_avg: 242.2621359223301 , reward_avg: -9.7495263067661 , distance traveled: 25.902025197297316 , average speed: 0.09185115318190537 , explore ratio: 0.0499340670765195\n",
      "Episode 1751 , steps =  51 , total reward: -2.1640774337680395 , steps_avg: 242.15296803652967 , reward_avg: -9.745196712660507 , distance traveled: 7.957371559739116 , average speed: 0.15602689332821795 , explore ratio: 0.0499340670765195\n",
      "Episode 1752 , steps =  139 , total reward: 10.836230028589556 , steps_avg: 242.09412435824302 , reward_avg: -9.73345602427417 , distance traveled: 41.405566622614835 , average speed: 0.29788177426341605 , explore ratio: 0.0499340670765195\n",
      "Episode 1753 , steps =  200 , total reward: -19.309043946781458 , steps_avg: 242.07012542759406 , reward_avg: -9.738915310432954 , distance traveled: 11.218152524668255 , average speed: 0.05609076262334128 , explore ratio: 0.0499340670765195\n",
      "Episode 1754 , steps =  78 , total reward: -1.7700006700096056 , steps_avg: 241.97663817663818 , reward_avg: -9.734374618330147 , distance traveled: 12.792145445197821 , average speed: 0.16400186468202335 , explore ratio: 0.0499340670765195\n",
      "Episode 1755 , steps =  457 , total reward: 24.38890483913697 , steps_avg: 242.09908883826878 , reward_avg: -9.714942226839563 , distance traveled: 116.8426121637295 , average speed: 0.2556731119556444 , explore ratio: 0.0499340670765195\n",
      "Episode 1756 , steps =  37 , total reward: -11.120092616800841 , steps_avg: 241.9823562891292 , reward_avg: -9.715741970943128 , distance traveled: 1.8136884355545047 , average speed: 0.049018606366337966 , explore ratio: 0.0499340670765195\n",
      "Episode 1757 , steps =  242 , total reward: 38.03853935652159 , steps_avg: 241.98236632536972 , reward_avg: -9.68857798839053 , distance traveled: 94.92795031942427 , average speed: 0.3922642575182821 , explore ratio: 0.0499340670765195\n",
      "Episode 1758 , steps =  286 , total reward: -6.580637146061736 , steps_avg: 242.00739056281978 , reward_avg: -9.686811109003191 , distance traveled: 39.75483587846161 , average speed: 0.13900292265196368 , explore ratio: 0.0499340670765195\n",
      "Episode 1759 , steps =  617 , total reward: -14.761232865907825 , steps_avg: 242.22045454545454 , reward_avg: -9.68969430318325 , distance traveled: 79.62615439480169 , average speed: 0.12905373483760404 , explore ratio: 0.0499340670765195\n",
      "Episode 1760 , steps =  81 , total reward: -12.92412718008087 , steps_avg: 242.12890403180012 , reward_avg: -9.691531005555142 , distance traveled: 16.913787059783935 , average speed: 0.20881218592325845 , explore ratio: 0.0499340670765195\n",
      "Episode 1761 , steps =  53 , total reward: -2.92052486832937 , steps_avg: 242.02156640181613 , reward_avg: -9.68768820979054 , distance traveled: 6.262173781692982 , average speed: 0.118154222296094 , explore ratio: 0.0499340670765195\n",
      "Episode 1762 , steps =  59 , total reward: -3.388332792401318 , steps_avg: 241.91775382870108 , reward_avg: -9.684115121068254 , distance traveled: 11.074615479111669 , average speed: 0.1877053471035876 , explore ratio: 0.0499340670765195\n",
      "Episode 1763 , steps =  61 , total reward: -5.259470141118399 , steps_avg: 241.8151927437642 , reward_avg: -9.681606818925426 , distance traveled: 5.765041107516735 , average speed: 0.09450887061502844 , explore ratio: 0.0499340670765195\n",
      "Episode 1764 , steps =  42 , total reward: -15.151268346101046 , steps_avg: 241.70198300283286 , reward_avg: -9.684705777297763 , distance traveled: -3.5035040062665925 , average speed: -0.08341676205396649 , explore ratio: 0.0499340670765195\n",
      "Episode 1765 , steps =  302 , total reward: -25.02304615195444 , steps_avg: 241.7361268403171 , reward_avg: -9.693391134248303 , distance traveled: 15.367600421269895 , average speed: 0.05088609411016522 , explore ratio: 0.0499340670765195\n",
      "Episode 1766 , steps =  536 , total reward: -49.47737762700262 , steps_avg: 241.9026598754952 , reward_avg: -9.715906123774483 , distance traveled: 17.684917624489046 , average speed: 0.03299424929941986 , explore ratio: 0.0499340670765195\n",
      "Episode 1767 , steps =  123 , total reward: -33.48581268222133 , steps_avg: 241.835407239819 , reward_avg: -9.729350641058671 , distance traveled: -24.523876273222264 , average speed: -0.19938110791237612 , explore ratio: 0.0499340670765195\n",
      "Episode 1768 , steps =  52 , total reward: -11.526001901715999 , steps_avg: 241.72809496890898 , reward_avg: -9.730366272070913 , distance traveled: -5.1355989726539715 , average speed: -0.09876151870488406 , explore ratio: 0.0499340670765195\n",
      "Episode 1769 , steps =  120 , total reward: -1.3011037598177873 , steps_avg: 241.6593220338983 , reward_avg: -9.725603976866251 , distance traveled: 23.43115576833486 , average speed: 0.1952596314027905 , explore ratio: 0.0499340670765195\n",
      "Episode 1770 , steps =  371 , total reward: 23.48094787333677 , steps_avg: 241.7323546019198 , reward_avg: -9.706853806425707 , distance traveled: 95.56893816999626 , average speed: 0.25759821609163414 , explore ratio: 0.0499340670765195\n",
      "Episode 1771 , steps =  96 , total reward: -27.54908580915815 , steps_avg: 241.65011286681715 , reward_avg: -9.716922786111223 , distance traveled: -19.704286859147256 , average speed: -0.20525298811611725 , explore ratio: 0.0499340670765195\n",
      "Episode 1772 , steps =  771 , total reward: 31.441126415563986 , steps_avg: 241.94867456288776 , reward_avg: -9.693708996375365 , distance traveled: 168.29548172500924 , average speed: 0.21828207746434403 , explore ratio: 0.0499340670765195\n",
      "Episode 1773 , steps =  175 , total reward: -14.407113675450212 , steps_avg: 241.91093573844418 , reward_avg: -9.696365932496603 , distance traveled: 12.236506422087555 , average speed: 0.06992289384050031 , explore ratio: 0.0499340670765195\n",
      "Episode 1774 , steps =  276 , total reward: 29.729826095202355 , steps_avg: 241.9301408450704 , reward_avg: -9.674153993326067 , distance traveled: 86.22443778902294 , average speed: 0.3124073832935614 , explore ratio: 0.0499340670765195\n",
      "Episode 1775 , steps =  239 , total reward: 9.872356547106039 , steps_avg: 241.92849099099098 , reward_avg: -9.663148075228976 , distance traveled: 54.75376841618676 , average speed: 0.22909526533969354 , explore ratio: 0.0499340670765195\n",
      "Episode 1776 , steps =  672 , total reward: 2.7748999425277945 , steps_avg: 242.17051209904332 , reward_avg: -9.656148610953368 , distance traveled: 112.76554034720176 , average speed: 0.16780586361190739 , explore ratio: 0.0499340670765195\n",
      "Episode 1777 , steps =  137 , total reward: -21.48595651836694 , steps_avg: 242.11136107986502 , reward_avg: -9.662802046221879 , distance traveled: -5.084919651886449 , average speed: -0.03711620183858722 , explore ratio: 0.0499340670765195\n",
      "Episode 1778 , steps =  69 , total reward: -1.2340328615456855 , steps_avg: 242.01405283867342 , reward_avg: -9.658064120879173 , distance traveled: 13.693413714040073 , average speed: 0.19845527121797207 , explore ratio: 0.0499340670765195\n",
      "Episode 1779 , steps =  62 , total reward: -13.299052873144548 , steps_avg: 241.9129213483146 , reward_avg: -9.660109620178199 , distance traveled: -5.9104499897360805 , average speed: -0.09532983854413032 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1780 , steps =  81 , total reward: -14.930067250729858 , steps_avg: 241.82257158899495 , reward_avg: -9.66306860817963 , distance traveled: -2.3911415103077887 , average speed: -0.029520265559355417 , explore ratio: 0.0499340670765195\n",
      "Episode 1781 , steps =  490 , total reward: 44.15127849737181 , steps_avg: 241.9618406285073 , reward_avg: -9.632869760196717 , distance traveled: 142.11447280883783 , average speed: 0.290029536344567 , explore ratio: 0.0499340670765195\n",
      "Episode 1782 , steps =  627 , total reward: 70.65223633403326 , steps_avg: 242.17779024116658 , reward_avg: -9.587841658068713 , distance traveled: 201.20885564876704 , average speed: 0.3209072657875072 , explore ratio: 0.0499340670765195\n",
      "Episode 1783 , steps =  81 , total reward: -19.210687305177252 , steps_avg: 242.08744394618833 , reward_avg: -9.593235629844 , distance traveled: -1.8281574106961491 , average speed: -0.02256984457649567 , explore ratio: 0.0499340670765195\n",
      "Episode 1784 , steps =  123 , total reward: -13.234155313308044 , steps_avg: 242.02072829131652 , reward_avg: -9.595275360759105 , distance traveled: 10.58624205842614 , average speed: 0.08606700860509058 , explore ratio: 0.0499340670765195\n",
      "Episode 1785 , steps =  65 , total reward: -15.086147694364195 , steps_avg: 241.92161254199328 , reward_avg: -9.598349757362467 , distance traveled: -0.24211084507405786 , average speed: -0.0037247822319085824 , explore ratio: 0.0499340670765195\n",
      "Episode 1786 , steps =  837 , total reward: -39.1359565233953 , steps_avg: 242.25461667599328 , reward_avg: -9.614878916157112 , distance traveled: 82.52455521526068 , average speed: 0.09859564541847153 , explore ratio: 0.0499340670765195\n",
      "Episode 1787 , steps =  75 , total reward: -16.812684147913636 , steps_avg: 242.16107382550337 , reward_avg: -9.618904534295678 , distance traveled: -8.268050100328402 , average speed: -0.11024066800437869 , explore ratio: 0.0499340670765195\n",
      "Episode 1788 , steps =  140 , total reward: -10.716616557876899 , steps_avg: 242.10396869759643 , reward_avg: -9.619518124023786 , distance traveled: 12.290373108834029 , average speed: 0.08778837934881449 , explore ratio: 0.0499340670765195\n",
      "Episode 1789 , steps =  849 , total reward: -34.50062445506675 , steps_avg: 242.44301675977653 , reward_avg: -9.633418183426603 , distance traveled: 91.56245874996128 , average speed: 0.10784741902233366 , explore ratio: 0.0499340670765195\n",
      "Episode 1790 , steps =  586 , total reward: -13.26304239056788 , steps_avg: 242.63484087102177 , reward_avg: -9.635444774273694 , distance traveled: 78.62327254478822 , average speed: 0.13416940707301744 , explore ratio: 0.0499340670765195\n",
      "Episode 1791 , steps =  51 , total reward: -4.434774311387912 , steps_avg: 242.52790178571428 , reward_avg: -9.632542614417174 , distance traveled: 6.524544872045518 , average speed: 0.12793225239304937 , explore ratio: 0.0499340670765195\n",
      "Episode 1792 , steps =  125 , total reward: -3.1129743556554237 , steps_avg: 242.46235359732293 , reward_avg: -9.628906491573469 , distance traveled: 18.480703578572726 , average speed: 0.1478456286285818 , explore ratio: 0.0499340670765195\n",
      "Episode 1793 , steps =  563 , total reward: -85.54767754771467 , steps_avg: 242.64102564102564 , reward_avg: -9.671224647123157 , distance traveled: -28.102297791251907 , average speed: -0.049915271387658805 , explore ratio: 0.0499340670765195\n",
      "Episode 1794 , steps =  162 , total reward: 3.948708915245397 , steps_avg: 242.59610027855155 , reward_avg: -9.663636940403174 , distance traveled: 36.44184144459663 , average speed: 0.2249496385468928 , explore ratio: 0.0499340670765195\n",
      "Episode 1795 , steps =  557 , total reward: 67.29720025473027 , steps_avg: 242.77115812917594 , reward_avg: -9.62078569474887 , distance traveled: 199.26990565650195 , average speed: 0.35775566545152954 , explore ratio: 0.0499340670765195\n",
      "Episode 1796 , steps =  70 , total reward: -16.45412017247019 , steps_avg: 242.67501391207568 , reward_avg: -9.624588329405364 , distance traveled: -8.01762321181479 , average speed: -0.114537474454497 , explore ratio: 0.0499340670765195\n",
      "Episode 1797 , steps =  256 , total reward: -23.727911751668806 , steps_avg: 242.68242491657398 , reward_avg: -9.63243222452342 , distance traveled: 12.150948463494423 , average speed: 0.04746464243552509 , explore ratio: 0.0499340670765195\n",
      "Episode 1798 , steps =  315 , total reward: 50.52224450097402 , steps_avg: 242.72262367982214 , reward_avg: -9.59899438309735 , distance traveled: 127.11196185601881 , average speed: 0.4035300376381549 , explore ratio: 0.0499340670765195\n",
      "Episode 1799 , steps =  242 , total reward: 26.538983807073926 , steps_avg: 242.72222222222223 , reward_avg: -9.578917728547255 , distance traveled: 83.01973466622177 , average speed: 0.3430567548190982 , explore ratio: 0.0499340670765195\n",
      "Episode 1800 , steps =  196 , total reward: -19.613322402842286 , steps_avg: 242.6962798445308 , reward_avg: -9.584489302491894 , distance traveled: 14.001957918754778 , average speed: 0.07143856080997335 , explore ratio: 0.0499340670765195\n",
      "Episode 1801 , steps =  92 , total reward: -27.029489008631558 , steps_avg: 242.6126526082131 , reward_avg: -9.59417021242871 , distance traveled: -11.421095137596126 , average speed: -0.12414233845213181 , explore ratio: 0.0499340670765195\n",
      "Episode 1802 , steps =  57 , total reward: -4.870763573984308 , steps_avg: 242.50970604547976 , reward_avg: -9.591550463877159 , distance traveled: 6.127243159711359 , average speed: 0.10749549403002384 , explore ratio: 0.0499340670765195\n",
      "Episode 1803 , steps =  64 , total reward: -9.146333030693864 , steps_avg: 242.41075388026607 , reward_avg: -9.591303669291136 , distance traveled: 3.66502445127815 , average speed: 0.05726600705122109 , explore ratio: 0.0499340670765195\n",
      "Episode 1804 , steps =  269 , total reward: 26.845703664410816 , steps_avg: 242.42548476454294 , reward_avg: -9.571116961627036 , distance traveled: 85.0849043175981 , average speed: 0.3163007595449744 , explore ratio: 0.0499340670765195\n",
      "Episode 1805 , steps =  375 , total reward: -29.46810920672484 , steps_avg: 242.49889258028793 , reward_avg: -9.582134122338609 , distance traveled: 34.801172156548155 , average speed: 0.09280312575079508 , explore ratio: 0.0499340670765195\n",
      "Episode 1806 , steps =  423 , total reward: 77.12333186798364 , steps_avg: 242.59878251245158 , reward_avg: -9.534151019964328 , distance traveled: 178.28971108898523 , average speed: 0.4214886786973646 , explore ratio: 0.0499340670765195\n",
      "Episode 1807 , steps =  65 , total reward: -10.720248836238559 , steps_avg: 242.50055309734512 , reward_avg: -9.534807047517578 , distance traveled: -1.2103684629499913 , average speed: -0.018621053276153713 , explore ratio: 0.0499340670765195\n",
      "Episode 1808 , steps =  508 , total reward: 85.90077876613739 , steps_avg: 242.6473189607518 , reward_avg: -9.482051057570837 , distance traveled: 205.07711075786497 , average speed: 0.40369509991705704 , explore ratio: 0.0499340670765195\n",
      "Episode 1809 , steps =  158 , total reward: -17.169554517213825 , steps_avg: 242.60055248618784 , reward_avg: -9.486298297051302 , distance traveled: 5.177329748868941 , average speed: 0.03276790980296798 , explore ratio: 0.0499340670765195\n",
      "Episode 1810 , steps =  550 , total reward: 40.296688759159174 , steps_avg: 242.77029265599117 , reward_avg: -9.45880907173037 , distance traveled: 146.68005984233693 , average speed: 0.26669101789515803 , explore ratio: 0.0499340670765195\n",
      "Episode 1811 , steps =  351 , total reward: 11.839712554888768 , steps_avg: 242.83002207505518 , reward_avg: -9.4470549207223 , distance traveled: 74.72558641489596 , average speed: 0.21289340858944716 , explore ratio: 0.0499340670765195\n",
      "Episode 1812 , steps =  545 , total reward: 35.287780232218424 , steps_avg: 242.99669056811913 , reward_avg: -9.422380439115603 , distance traveled: 140.61678800940513 , average speed: 0.2580124550631287 , explore ratio: 0.0499340670765195\n",
      "Episode 1813 , steps =  226 , total reward: 36.00906211318001 , steps_avg: 242.98732083792723 , reward_avg: -9.39733554244951 , distance traveled: 90.18667967833578 , average speed: 0.39905610477139725 , explore ratio: 0.0499340670765195\n",
      "Episode 1814 , steps =  174 , total reward: -20.782503373214908 , steps_avg: 242.94931129476583 , reward_avg: -9.403608362190978 , distance traveled: 3.5290740638505604 , average speed: 0.020282034849715865 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1815 , steps =  395 , total reward: 35.07031427836654 , steps_avg: 243.03303964757708 , reward_avg: -9.379118316684062 , distance traveled: 117.45726591501386 , average speed: 0.2973601668734528 , explore ratio: 0.0499340670765195\n",
      "Episode 1816 , steps =  134 , total reward: -35.46230717246608 , steps_avg: 242.97303247110622 , reward_avg: -9.393473401359783 , distance traveled: -14.557715828726069 , average speed: -0.10863967036362739 , explore ratio: 0.0499340670765195\n",
      "Episode 1817 , steps =  221 , total reward: 39.5478208431774 , steps_avg: 242.96094609460945 , reward_avg: -9.3665529974849 , distance traveled: 96.45294122635272 , average speed: 0.436438648083044 , explore ratio: 0.0499340670765195\n",
      "Episode 1818 , steps =  60 , total reward: -14.498847495069105 , steps_avg: 242.86036283672348 , reward_avg: -9.369374489787036 , distance traveled: -0.6256060254760089 , average speed: -0.010426767091266814 , explore ratio: 0.0499340670765195\n",
      "Episode 1819 , steps =  287 , total reward: 38.57675202255808 , steps_avg: 242.8846153846154 , reward_avg: -9.3430304642308 , distance traveled: 104.89238913115118 , average speed: 0.3654787077740459 , explore ratio: 0.0499340670765195\n",
      "Episode 1820 , steps =  180 , total reward: -12.662656682720419 , steps_avg: 242.8500823723229 , reward_avg: -9.344853433049302 , distance traveled: 19.240073626809757 , average speed: 0.10688929792672087 , explore ratio: 0.0499340670765195\n",
      "Episode 1821 , steps =  223 , total reward: 13.843035229481114 , steps_avg: 242.83918770581778 , reward_avg: -9.332126820171952 , distance traveled: 59.6565175173059 , average speed: 0.2675180157726722 , explore ratio: 0.0499340670765195\n",
      "Episode 1822 , steps =  61 , total reward: -0.07761349994192401 , steps_avg: 242.7394404827208 , reward_avg: -9.327050290649062 , distance traveled: 10.965437697172163 , average speed: 0.17976127372413384 , explore ratio: 0.0499340670765195\n",
      "Episode 1823 , steps =  429 , total reward: 78.08057906892903 , steps_avg: 242.84155701754386 , reward_avg: -9.279129441219467 , distance traveled: 181.1523566289246 , average speed: 0.42226656556858877 , explore ratio: 0.0499340670765195\n",
      "Episode 1824 , steps =  187 , total reward: 17.381280138043056 , steps_avg: 242.81095890410958 , reward_avg: -9.264520997614392 , distance traveled: 59.111279441239326 , average speed: 0.3161030986162531 , explore ratio: 0.0499340670765195\n",
      "Episode 1825 , steps =  138 , total reward: -38.14771232370345 , steps_avg: 242.75355969331872 , reward_avg: -9.280338736566248 , distance traveled: -27.95016643166542 , average speed: -0.20253743791061898 , explore ratio: 0.0499340670765195\n",
      "Episode 1826 , steps =  268 , total reward: 13.245271109180505 , steps_avg: 242.76737821565408 , reward_avg: -9.268009448199665 , distance traveled: 68.497556373775 , average speed: 0.2555878969170709 , explore ratio: 0.0499340670765195\n",
      "Episode 1827 , steps =  298 , total reward: 32.88655897806328 , steps_avg: 242.79759299781182 , reward_avg: -9.244948962189675 , distance traveled: 96.5256018798798 , average speed: 0.32391141570429466 , explore ratio: 0.0499340670765195\n",
      "Episode 1828 , steps =  322 , total reward: -11.309421799017768 , steps_avg: 242.84089666484417 , reward_avg: -9.246077706222932 , distance traveled: 39.233717433298 , average speed: 0.12184384296055278 , explore ratio: 0.0499340670765195\n",
      "Episode 1829 , steps =  310 , total reward: 25.701724809085306 , steps_avg: 242.8775956284153 , reward_avg: -9.2269805463785 , distance traveled: 86.38812313377862 , average speed: 0.278671364947673 , explore ratio: 0.0499340670765195\n",
      "Episode 1830 , steps =  466 , total reward: 75.13499675803064 , steps_avg: 242.999453850355 , reward_avg: -9.18090628242197 , distance traveled: 182.18852406173954 , average speed: 0.3909624979865655 , explore ratio: 0.0499340670765195\n",
      "Episode 1831 , steps =  329 , total reward: 32.15273184158333 , steps_avg: 243.04639737991266 , reward_avg: -9.158344252878297 , distance traveled: 102.03925023173208 , average speed: 0.31014969675298504 , explore ratio: 0.0499340670765195\n",
      "Episode 1832 , steps =  179 , total reward: -1.4573037087501461 , steps_avg: 243.0114566284779 , reward_avg: -9.154142921430328 , distance traveled: 29.981393218841408 , average speed: 0.1674938168650358 , explore ratio: 0.0499340670765195\n",
      "Episode 1833 , steps =  217 , total reward: 22.475666315506512 , steps_avg: 242.99727371864776 , reward_avg: -9.136896569610844 , distance traveled: 71.79635515630247 , average speed: 0.33085877952213116 , explore ratio: 0.0499340670765195\n",
      "Episode 1834 , steps =  87 , total reward: -5.531053648463141 , steps_avg: 242.91226158038148 , reward_avg: -9.134931532596594 , distance traveled: 11.791424544453621 , average speed: 0.1355336154534899 , explore ratio: 0.0499340670765195\n",
      "Episode 1835 , steps =  94 , total reward: -4.623972553559899 , steps_avg: 242.83115468409585 , reward_avg: -9.132474583261608 , distance traveled: 9.013416816908867 , average speed: 0.09588741294583901 , explore ratio: 0.0499340670765195\n",
      "Episode 1836 , steps =  234 , total reward: 21.336242799561468 , steps_avg: 242.82634730538922 , reward_avg: -9.115888455127244 , distance traveled: 72.38751785079833 , average speed: 0.30934836688375356 , explore ratio: 0.0499340670765195\n",
      "Episode 1837 , steps =  165 , total reward: -2.0454023044680727 , steps_avg: 242.78400435255713 , reward_avg: -9.112041618266169 , distance traveled: 26.031468205503185 , average speed: 0.15776647397274657 , explore ratio: 0.0499340670765195\n",
      "Episode 1838 , steps =  45 , total reward: -3.4757148934900757 , steps_avg: 242.67645459488853 , reward_avg: -9.108976731520777 , distance traveled: 4.680780081152916 , average speed: 0.10401733513673146 , explore ratio: 0.0499340670765195\n",
      "Episode 1839 , steps =  105 , total reward: -2.6383940995919293 , steps_avg: 242.6016304347826 , reward_avg: -9.105460110525163 , distance traveled: 20.755868211016068 , average speed: 0.19767493534301017 , explore ratio: 0.0499340670765195\n",
      "Episode 1840 , steps =  69 , total reward: -0.9571591381964585 , steps_avg: 242.5073329712113 , reward_avg: -9.101034091528785 , distance traveled: 13.943673102557662 , average speed: 0.20208221887764727 , explore ratio: 0.0499340670765195\n",
      "Episode 1841 , steps =  40 , total reward: -14.929910931009804 , steps_avg: 242.3973941368078 , reward_avg: -9.104198519780406 , distance traveled: -0.40251123757101603 , average speed: -0.0100627809392754 , explore ratio: 0.0499340670765195\n",
      "Episode 1842 , steps =  103 , total reward: -6.373177361886331 , steps_avg: 242.32175800325555 , reward_avg: -9.10271668518578 , distance traveled: 13.692723765559492 , average speed: 0.1329390656850436 , explore ratio: 0.0499340670765195\n",
      "Episode 1843 , steps =  93 , total reward: 0.5155712790749903 , steps_avg: 242.2407809110629 , reward_avg: -9.09750069388195 , distance traveled: 19.100923821553586 , average speed: 0.20538627765111384 , explore ratio: 0.0499340670765195\n",
      "Episode 1844 , steps =  62 , total reward: -2.9214968158702064 , steps_avg: 242.14308943089432 , reward_avg: -9.094153266305792 , distance traveled: 9.835570462346077 , average speed: 0.1586382332636464 , explore ratio: 0.0499340670765195\n",
      "Episode 1845 , steps =  96 , total reward: -9.278719970017058 , steps_avg: 242.06392199349946 , reward_avg: -9.0942532482688 , distance traveled: 5.743802019993673 , average speed: 0.05983127104160076 , explore ratio: 0.0499340670765195\n",
      "Episode 1846 , steps =  76 , total reward: -7.2951772538864414 , steps_avg: 241.97401191120736 , reward_avg: -9.093279195212826 , distance traveled: 4.345198351498692 , average speed: 0.057173662519719635 , explore ratio: 0.0499340670765195\n",
      "Episode 1847 , steps =  186 , total reward: 15.494705290457842 , steps_avg: 241.94372294372295 , reward_avg: -9.079974008802832 , distance traveled: 54.83552454885095 , average speed: 0.2948146481121019 , explore ratio: 0.0499340670765195\n",
      "Episode 1848 , steps =  252 , total reward: 2.103257113394692 , steps_avg: 241.9491617090319 , reward_avg: -9.073925749677793 , distance traveled: 49.13669274668276 , average speed: 0.19498687597889985 , explore ratio: 0.0499340670765195\n",
      "Episode 1849 , steps =  67 , total reward: -29.510871506208556 , steps_avg: 241.8545945945946 , reward_avg: -9.084972747384025 , distance traveled: -16.78264170885086 , average speed: -0.2504871896843412 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1850 , steps =  287 , total reward: 29.860706204549018 , steps_avg: 241.8789843327931 , reward_avg: -9.063932402191192 , distance traveled: 93.3620492367447 , average speed: 0.3253033074451035 , explore ratio: 0.0499340670765195\n",
      "Episode 1851 , steps =  311 , total reward: 37.54601417219443 , steps_avg: 241.91630669546436 , reward_avg: -9.038765044429645 , distance traveled: 105.95951376132314 , average speed: 0.34070583202997795 , explore ratio: 0.0499340670765195\n",
      "Episode 1852 , steps =  127 , total reward: -43.021212342911696 , steps_avg: 241.8542903399892 , reward_avg: -9.05710419569704 , distance traveled: -27.88602923244238 , average speed: -0.21957503332631795 , explore ratio: 0.0499340670765195\n",
      "Episode 1853 , steps =  197 , total reward: 19.588368438498424 , steps_avg: 241.83009708737865 , reward_avg: -9.04165356320826 , distance traveled: 62.224552079234286 , average speed: 0.3158606704529659 , explore ratio: 0.0499340670765195\n",
      "Episode 1854 , steps =  48 , total reward: -6.0982726239295015 , steps_avg: 241.72560646900268 , reward_avg: -9.040066834939108 , distance traveled: 0.5860607719235122 , average speed: 0.012209599415073172 , explore ratio: 0.0499340670765195\n",
      "Episode 1855 , steps =  349 , total reward: 19.42962213855053 , steps_avg: 241.78340517241378 , reward_avg: -9.024727562862875 , distance traveled: 87.17299107179475 , average speed: 0.24977934404525717 , explore ratio: 0.0499340670765195\n",
      "Episode 1856 , steps =  98 , total reward: 7.873489143841581 , steps_avg: 241.7059773828756 , reward_avg: -9.015627823117745 , distance traveled: 29.869824254661808 , average speed: 0.3047941250475695 , explore ratio: 0.0499340670765195\n",
      "Episode 1857 , steps =  42 , total reward: -20.883110156350455 , steps_avg: 241.59849300322927 , reward_avg: -9.022015057958022 , distance traveled: -3.1269830511510377 , average speed: -0.07445197740835804 , explore ratio: 0.0499340670765195\n",
      "Episode 1858 , steps =  58 , total reward: -19.374460799527036 , steps_avg: 241.49973103819258 , reward_avg: -9.027583882993829 , distance traveled: -1.7359686837159096 , average speed: -0.029930494546826027 , explore ratio: 0.0499340670765195\n",
      "Episode 1859 , steps =  231 , total reward: 23.394900103669592 , steps_avg: 241.49408602150538 , reward_avg: -9.010152439990248 , distance traveled: 74.5453052287409 , average speed: 0.3227069490421684 , explore ratio: 0.0499340670765195\n",
      "Episode 1860 , steps =  52 , total reward: -6.5342086444168075 , steps_avg: 241.39226222461042 , reward_avg: -9.008822002700848 , distance traveled: 2.1518588807433847 , average speed: 0.0413819015527574 , explore ratio: 0.0499340670765195\n",
      "Episode 1861 , steps =  327 , total reward: 57.3377608588746 , steps_avg: 241.43823845327606 , reward_avg: -8.973190110723632 , distance traveled: 136.34231015101082 , average speed: 0.4169489607064551 , explore ratio: 0.0499340670765195\n",
      "Episode 1862 , steps =  345 , total reward: -32.99425252242913 , steps_avg: 241.49382716049382 , reward_avg: -8.986083864031041 , distance traveled: 22.86994398370385 , average speed: 0.06628969270638796 , explore ratio: 0.0499340670765195\n",
      "Episode 1863 , steps =  334 , total reward: 25.22796191957292 , steps_avg: 241.54345493562232 , reward_avg: -8.96772868925443 , distance traveled: 91.83600826889274 , average speed: 0.2749581085894992 , explore ratio: 0.0499340670765195\n",
      "Episode 1864 , steps =  247 , total reward: 3.9109558790524606 , steps_avg: 241.54638069705095 , reward_avg: -8.960823228359896 , distance traveled: 45.55605889052152 , average speed: 0.1844374853867268 , explore ratio: 0.0499340670765195\n",
      "Episode 1865 , steps =  328 , total reward: 19.359352546209436 , steps_avg: 241.59271168274384 , reward_avg: -8.945646285286708 , distance traveled: 83.18377302892507 , average speed: 0.25360906411257644 , explore ratio: 0.0499340670765195\n",
      "Episode 1866 , steps =  114 , total reward: -40.4372975199657 , steps_avg: 241.52437064809857 , reward_avg: -8.962513800677538 , distance traveled: -21.865787511616947 , average speed: -0.19180515361067496 , explore ratio: 0.0499340670765195\n",
      "Episode 1867 , steps =  236 , total reward: 24.864943739739505 , steps_avg: 241.52141327623127 , reward_avg: -8.944404883364681 , distance traveled: 73.86201874963933 , average speed: 0.3129746557188107 , explore ratio: 0.0499340670765195\n",
      "Episode 1868 , steps =  186 , total reward: 6.613741397716711 , steps_avg: 241.4917067950776 , reward_avg: -8.936080567537457 , distance traveled: 38.09933772120858 , average speed: 0.2048351490387558 , explore ratio: 0.0499340670765195\n",
      "Episode 1869 , steps =  136 , total reward: -12.761808419154343 , steps_avg: 241.43529411764706 , reward_avg: -8.938126411308374 , distance traveled: 9.088699303306639 , average speed: 0.06682867134784293 , explore ratio: 0.0499340670765195\n",
      "Episode 1870 , steps =  56 , total reward: -1.03177395450386 , steps_avg: 241.33618385889898 , reward_avg: -8.933900675094156 , distance traveled: 8.355672680139541 , average speed: 0.14920844071677752 , explore ratio: 0.0499340670765195\n",
      "Episode 1871 , steps =  53 , total reward: -0.39918488985921174 , steps_avg: 241.23557692307693 , reward_avg: -8.929341532046488 , distance traveled: 8.804828168749808 , average speed: 0.16612883337263787 , explore ratio: 0.0499340670765195\n",
      "Episode 1872 , steps =  272 , total reward: 2.807327728802939 , steps_avg: 241.25200213561132 , reward_avg: -8.923075291117044 , distance traveled: 52.68175506100061 , average speed: 0.19368292301838458 , explore ratio: 0.0499340670765195\n",
      "Episode 1873 , steps =  91 , total reward: -12.73582091842282 , steps_avg: 241.1718249733191 , reward_avg: -8.925109840544636 , distance traveled: 6.204542464613915 , average speed: 0.06818178532542764 , explore ratio: 0.0499340670765195\n",
      "Episode 1874 , steps =  291 , total reward: 40.79690537889975 , steps_avg: 241.1984 , reward_avg: -8.898591432427597 , distance traveled: 105.03394350841644 , average speed: 0.36094138662686065 , explore ratio: 0.0499340670765195\n",
      "Episode 1875 , steps =  182 , total reward: -21.451488214938575 , steps_avg: 241.16684434968016 , reward_avg: -8.905282742013158 , distance traveled: 3.1868207393819468 , average speed: 0.017510004062538168 , explore ratio: 0.0499340670765195\n",
      "Episode 1876 , steps =  603 , total reward: 22.65461491685613 , steps_avg: 241.35961640916355 , reward_avg: -8.8884687315396 , distance traveled: 124.86116006589724 , average speed: 0.2070666004409573 , explore ratio: 0.0499340670765195\n",
      "Episode 1877 , steps =  765 , total reward: 54.66694673993601 , steps_avg: 241.6384451544196 , reward_avg: -8.854626657273638 , distance traveled: 200.24314858285692 , average speed: 0.26175574978151234 , explore ratio: 0.0499340670765195\n",
      "Episode 1878 , steps =  46 , total reward: -3.311125722528744 , steps_avg: 241.53432676955828 , reward_avg: -8.851676417287079 , distance traveled: 4.884255296587944 , average speed: 0.10617946296930313 , explore ratio: 0.0499340670765195\n",
      "Episode 1879 , steps =  133 , total reward: -19.470736995721847 , steps_avg: 241.47659574468085 , reward_avg: -8.85732485376497 , distance traveled: 0.8514278138056395 , average speed: 0.006401712885756688 , explore ratio: 0.0499340670765195\n",
      "Episode 1880 , steps =  345 , total reward: -11.729533372735634 , steps_avg: 241.53163211057947 , reward_avg: -8.858851812041934 , distance traveled: 47.48334745639934 , average speed: 0.13763289117796912 , explore ratio: 0.0499340670765195\n",
      "Episode 1881 , steps =  229 , total reward: 16.351072655805687 , steps_avg: 241.5249734325186 , reward_avg: -8.845456528052642 , distance traveled: 61.6905044453591 , average speed: 0.2693908491063716 , explore ratio: 0.0499340670765195\n",
      "Episode 1882 , steps =  99 , total reward: 7.437138417525832 , steps_avg: 241.44928305894848 , reward_avg: -8.836809371947714 , distance traveled: 29.87907591819763 , average speed: 0.3018088476585619 , explore ratio: 0.0499340670765195\n",
      "Episode 1883 , steps =  199 , total reward: 22.397145332173732 , steps_avg: 241.42675159235668 , reward_avg: -8.820230839726845 , distance traveled: 67.82298385217787 , average speed: 0.34081901433255213 , explore ratio: 0.0499340670765195\n",
      "Episode 1884 , steps =  213 , total reward: 6.860521682745449 , steps_avg: 241.41167108753316 , reward_avg: -8.811912138123411 , distance traveled: 47.40621275609359 , average speed: 0.2225643791365896 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1885 , steps =  45 , total reward: -2.624432691600719 , steps_avg: 241.30752916224813 , reward_avg: -8.808631396105104 , distance traveled: 3.6806376814842223 , average speed: 0.08179194847742716 , explore ratio: 0.0499340670765195\n",
      "Episode 1886 , steps =  63 , total reward: -3.242991587374359 , steps_avg: 241.21303656597775 , reward_avg: -8.805681931447591 , distance traveled: 7.915111911892891 , average speed: 0.12563669701417288 , explore ratio: 0.0499340670765195\n",
      "Episode 1887 , steps =  250 , total reward: 35.41757066656827 , steps_avg: 241.2176906779661 , reward_avg: -8.782258598503725 , distance traveled: 90.24389754720035 , average speed: 0.3609755901888014 , explore ratio: 0.0499340670765195\n",
      "Episode 1888 , steps =  369 , total reward: 30.485137715704074 , steps_avg: 241.28533615669667 , reward_avg: -8.76147119971378 , distance traveled: 103.25674445137383 , average speed: 0.27982857574898057 , explore ratio: 0.0499340670765195\n",
      "Episode 1889 , steps =  142 , total reward: -4.3496186357264826 , steps_avg: 241.23280423280423 , reward_avg: -8.75913688618786 , distance traveled: 18.956199141573165 , average speed: 0.1334943601519237 , explore ratio: 0.0499340670765195\n",
      "Episode 1890 , steps =  91 , total reward: -8.832009414507086 , steps_avg: 241.15335801163405 , reward_avg: -8.759175422691468 , distance traveled: 7.28134526906535 , average speed: 0.08001478317654231 , explore ratio: 0.0499340670765195\n",
      "Episode 1891 , steps =  536 , total reward: 7.4085790993075875 , steps_avg: 241.30919661733614 , reward_avg: -8.750630097891257 , distance traveled: 102.44124412709849 , average speed: 0.19112172411772105 , explore ratio: 0.0499340670765195\n",
      "Episode 1892 , steps =  326 , total reward: -6.854431881108039 , steps_avg: 241.35393555203382 , reward_avg: -8.749628408394805 , distance traveled: 54.64860020061021 , average speed: 0.1676337429466571 , explore ratio: 0.0499340670765195\n",
      "Episode 1893 , steps =  236 , total reward: 27.083476317750225 , steps_avg: 241.35110876451952 , reward_avg: -8.730709134516164 , distance traveled: 79.96370907140894 , average speed: 0.33882927572630905 , explore ratio: 0.0499340670765195\n",
      "Episode 1894 , steps =  279 , total reward: 38.293048514849076 , steps_avg: 241.37097625329815 , reward_avg: -8.705894486680089 , distance traveled: 100.6987236984819 , average speed: 0.36092732508416453 , explore ratio: 0.0499340670765195\n",
      "Episode 1895 , steps =  226 , total reward: -12.205537758275263 , steps_avg: 241.36286919831224 , reward_avg: -8.707740290093376 , distance traveled: 27.4847129634954 , average speed: 0.12161377417475841 , explore ratio: 0.0499340670765195\n",
      "Episode 1896 , steps =  173 , total reward: -7.990938234283295 , steps_avg: 241.32683183974697 , reward_avg: -8.707362429231063 , distance traveled: 18.994862524489875 , average speed: 0.10979689320514378 , explore ratio: 0.0499340670765195\n",
      "Episode 1897 , steps =  146 , total reward: 16.187622494569034 , steps_avg: 241.27660695468916 , reward_avg: -8.6942459988181 , distance traveled: 50.30761729806661 , average speed: 0.34457272121963434 , explore ratio: 0.0499340670765195\n",
      "Episode 1898 , steps =  291 , total reward: 21.3424317918643 , steps_avg: 241.30279094260138 , reward_avg: -8.678428896242702 , distance traveled: 79.6793553256988 , average speed: 0.2738122176140852 , explore ratio: 0.0499340670765195\n",
      "Episode 1899 , steps =  84 , total reward: -3.8781774468614483 , steps_avg: 241.22 , reward_avg: -8.675902448111449 , distance traveled: 10.578933541942387 , average speed: 0.12593968502312367 , explore ratio: 0.0499340670765195\n",
      "Episode 1900 , steps =  328 , total reward: 13.894042822069311 , steps_avg: 241.2656496580747 , reward_avg: -8.664029778321769 , distance traveled: 77.87990657161926 , average speed: 0.23743873954761968 , explore ratio: 0.0499340670765195\n",
      "Episode 1901 , steps =  169 , total reward: -9.359858781197431 , steps_avg: 241.22765509989486 , reward_avg: -8.664395619017286 , distance traveled: 17.143086419384932 , average speed: 0.1014383811797925 , explore ratio: 0.0499340670765195\n",
      "Episode 1902 , steps =  232 , total reward: 11.383578073957297 , steps_avg: 241.22280609563848 , reward_avg: -8.6538606880173 , distance traveled: 58.036397252082814 , average speed: 0.2501568847072535 , explore ratio: 0.0499340670765195\n",
      "Episode 1903 , steps =  177 , total reward: 31.827016582092245 , steps_avg: 241.1890756302521 , reward_avg: -8.632599723064512 , distance traveled: 77.69159832179547 , average speed: 0.43893558373895747 , explore ratio: 0.0499340670765195\n",
      "Episode 1904 , steps =  495 , total reward: 44.79360822098629 , steps_avg: 241.3223097112861 , reward_avg: -8.604554469550575 , distance traveled: 142.80253189712772 , average speed: 0.28848996342854083 , explore ratio: 0.0499340670765195\n",
      "Episode 1905 , steps =  214 , total reward: 10.58630260786786 , steps_avg: 241.30797481636935 , reward_avg: -8.5944858142109 , distance traveled: 52.54977151840926 , average speed: 0.24555967999256662 , explore ratio: 0.0499340670765195\n",
      "Episode 1906 , steps =  61 , total reward: -12.002275078052657 , steps_avg: 241.21342422653382 , reward_avg: -8.596272803861577 , distance traveled: 1.9120144139975308 , average speed: 0.031344498590123455 , explore ratio: 0.0499340670765195\n",
      "Episode 1907 , steps =  157 , total reward: 9.802190218143156 , steps_avg: 241.16928721174006 , reward_avg: -8.58663000353558 , distance traveled: 42.49784846261142 , average speed: 0.2706869328828753 , explore ratio: 0.0499340670765195\n",
      "Episode 1908 , steps =  48 , total reward: -28.05939904138507 , steps_avg: 241.06809848088005 , reward_avg: -8.596830511151007 , distance traveled: -6.438914278736338 , average speed: -0.1341440474736737 , explore ratio: 0.0499340670765195\n",
      "Episode 1909 , steps =  254 , total reward: -6.213415270129861 , steps_avg: 241.07486910994766 , reward_avg: -8.595582649768273 , distance traveled: 36.30507523648032 , average speed: 0.14293336707275717 , explore ratio: 0.0499340670765195\n",
      "Episode 1910 , steps =  404 , total reward: 73.51807432245886 , steps_avg: 241.160125588697 , reward_avg: -8.552613703158002 , distance traveled: 171.5919415810425 , average speed: 0.4247325286659468 , explore ratio: 0.0499340670765195\n",
      "Episode 1911 , steps =  223 , total reward: 34.782187231921164 , steps_avg: 241.15062761506277 , reward_avg: -8.529949058317479 , distance traveled: 87.44783092760481 , average speed: 0.3921427395856718 , explore ratio: 0.0499340670765195\n",
      "Episode 1912 , steps =  61 , total reward: -6.708378947518149 , steps_avg: 241.05645582854154 , reward_avg: -8.528996852300335 , distance traveled: 3.364592321701347 , average speed: 0.055157251175431916 , explore ratio: 0.0499340670765195\n",
      "Episode 1913 , steps =  48 , total reward: -17.615329440124952 , steps_avg: 240.95559038662486 , reward_avg: -8.53374415250296 , distance traveled: -8.610679496750237 , average speed: -0.1793891561822966 , explore ratio: 0.0499340670765195\n",
      "Episode 1914 , steps =  64 , total reward: -12.872987566297256 , steps_avg: 240.8631853785901 , reward_avg: -8.536010075956638 , distance traveled: -3.4125040367245685 , average speed: -0.05332037557382138 , explore ratio: 0.0499340670765195\n",
      "Episode 1915 , steps =  66 , total reward: -15.135028464267654 , steps_avg: 240.77192066805844 , reward_avg: -8.539454240042396 , distance traveled: -6.306348199099301 , average speed: -0.09555073028938335 , explore ratio: 0.0499340670765195\n",
      "Episode 1916 , steps =  63 , total reward: 0.19235413030348303 , steps_avg: 240.679186228482 , reward_avg: -8.534899306098554 , distance traveled: 12.461399261355396 , average speed: 0.19779998827548248 , explore ratio: 0.0499340670765195\n",
      "Episode 1917 , steps =  59 , total reward: -7.745254159863427 , steps_avg: 240.5844629822732 , reward_avg: -8.534487603728254 , distance traveled: 4.315200689435004 , average speed: 0.07313899473618651 , explore ratio: 0.0499340670765195\n",
      "Episode 1918 , steps =  112 , total reward: -8.789945095755163 , steps_avg: 240.51745700885877 , reward_avg: -8.534620723838742 , distance traveled: 9.145521993561418 , average speed: 0.08165644637108409 , explore ratio: 0.0499340670765195\n",
      "Episode 1919 , steps =  226 , total reward: -8.803415788487863 , steps_avg: 240.50989583333333 , reward_avg: -8.534760721268245 , distance traveled: 25.199459114642814 , average speed: 0.11150203148072041 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1920 , steps =  197 , total reward: 3.133449451296883 , steps_avg: 240.487246225924 , reward_avg: -8.528686692026932 , distance traveled: 38.040817797720365 , average speed: 0.1931005979579714 , explore ratio: 0.0499340670765195\n",
      "Episode 1921 , steps =  53 , total reward: -2.031035345495367 , steps_avg: 240.38969823100936 , reward_avg: -8.525306020150484 , distance traveled: 7.27129724867642 , average speed: 0.13719428771087583 , explore ratio: 0.0499340670765195\n",
      "Episode 1922 , steps =  66 , total reward: 0.7432353780437266 , steps_avg: 240.29901196047842 , reward_avg: -8.520486185830052 , distance traveled: 14.382759506106376 , average speed: 0.21792059857736934 , explore ratio: 0.0499340670765195\n",
      "Episode 1923 , steps =  134 , total reward: 5.890765085398519 , steps_avg: 240.243762993763 , reward_avg: -8.512995930491574 , distance traveled: 31.41071576908697 , average speed: 0.23440832663497738 , explore ratio: 0.0499340670765195\n",
      "Episode 1924 , steps =  188 , total reward: -21.439531952531308 , steps_avg: 240.21662337662337 , reward_avg: -8.519711014139387 , distance traveled: 9.583669578116385 , average speed: 0.0509769658410446 , explore ratio: 0.0499340670765195\n",
      "Episode 1925 , steps =  228 , total reward: 27.124784242177977 , steps_avg: 240.21028037383178 , reward_avg: -8.501204007256565 , distance traveled: 81.22901186585426 , average speed: 0.35626759590286955 , explore ratio: 0.0499340670765195\n",
      "Episode 1926 , steps =  60 , total reward: -7.4807274834625455 , steps_avg: 240.11676180591593 , reward_avg: -8.50067443978184 , distance traveled: 3.1892146664857854 , average speed: 0.05315357777476309 , explore ratio: 0.0499340670765195\n",
      "Episode 1927 , steps =  74 , total reward: -6.633887216795245 , steps_avg: 240.03060165975103 , reward_avg: -8.499706189147512 , distance traveled: 8.145926250815393 , average speed: 0.11008008447047828 , explore ratio: 0.0499340670765195\n",
      "Episode 1928 , steps =  210 , total reward: -13.09942299835696 , steps_avg: 240.01503369621565 , reward_avg: -8.502090697602258 , distance traveled: 20.010142328795048 , average speed: 0.09528639204188118 , explore ratio: 0.0499340670765195\n",
      "Episode 1929 , steps =  155 , total reward: 0.3344119969724261 , steps_avg: 239.97098445595856 , reward_avg: -8.497512198796779 , distance traveled: 29.632099955538287 , average speed: 0.19117483842282765 , explore ratio: 0.0499340670765195\n",
      "Episode 1930 , steps =  74 , total reward: -17.5156853272381 , steps_avg: 239.8850336613154 , reward_avg: -8.50218240756345 , distance traveled: -10.176925886250103 , average speed: -0.13752602548986625 , explore ratio: 0.0499340670765195\n",
      "Episode 1931 , steps =  96 , total reward: -12.164912006136037 , steps_avg: 239.81055900621118 , reward_avg: -8.504078230337038 , distance traveled: 2.908023856021465 , average speed: 0.030291915166890258 , explore ratio: 0.0499340670765195\n",
      "Episode 1932 , steps =  87 , total reward: -11.491179896608001 , steps_avg: 239.73150543197102 , reward_avg: -8.505623549357354 , distance traveled: 9.130409211711957 , average speed: 0.10494723231852823 , explore ratio: 0.0499340670765195\n",
      "Episode 1933 , steps =  227 , total reward: 0.7694873375265351 , steps_avg: 239.72492244053774 , reward_avg: -8.50082773193911 , distance traveled: 39.40910698257387 , average speed: 0.17360840080429016 , explore ratio: 0.0499340670765195\n",
      "Episode 1934 , steps =  131 , total reward: 7.666347189441936 , steps_avg: 239.6687338501292 , reward_avg: -8.492472602780774 , distance traveled: 33.77865202561486 , average speed: 0.25785230553904476 , explore ratio: 0.0499340670765195\n",
      "Episode 1935 , steps =  391 , total reward: 71.63312463175056 , steps_avg: 239.74690082644628 , reward_avg: -8.451085414126576 , distance traveled: 165.59924255669122 , average speed: 0.42352747456954276 , explore ratio: 0.0499340670765195\n",
      "Episode 1936 , steps =  286 , total reward: 59.804773382695195 , steps_avg: 239.77077955601445 , reward_avg: -8.41584749012202 , distance traveled: 136.4588942745701 , average speed: 0.4771290009600353 , explore ratio: 0.0499340670765195\n",
      "Episode 1937 , steps =  222 , total reward: 21.721139206737853 , steps_avg: 239.76160990712074 , reward_avg: -8.400296929390928 , distance traveled: 69.367445280198 , average speed: 0.31246596973062163 , explore ratio: 0.0499340670765195\n",
      "Episode 1938 , steps =  221 , total reward: 47.56647678516045 , steps_avg: 239.751933986591 , reward_avg: -8.371433198749076 , distance traveled: 109.48130384087558 , average speed: 0.4953905151170841 , explore ratio: 0.0499340670765195\n",
      "Episode 1939 , steps =  242 , total reward: 30.45663616448074 , steps_avg: 239.75309278350517 , reward_avg: -8.351418730005143 , distance traveled: 84.65329149608617 , average speed: 0.34980698965324863 , explore ratio: 0.0499340670765195\n",
      "Episode 1940 , steps =  220 , total reward: -16.235214421342455 , steps_avg: 239.74291602266874 , reward_avg: -8.35548044854782 , distance traveled: 18.901030385121693 , average speed: 0.08591377447782587 , explore ratio: 0.0499340670765195\n",
      "Episode 1941 , steps =  89 , total reward: -7.184299606356776 , steps_avg: 239.66529351184346 , reward_avg: -8.354877368814456 , distance traveled: 11.867293897792699 , average speed: 0.13334038087407526 , explore ratio: 0.0499340670765195\n",
      "Episode 1942 , steps =  130 , total reward: -11.602446874522924 , steps_avg: 239.60885229027278 , reward_avg: -8.356548789043849 , distance traveled: 6.726714669093489 , average speed: 0.05174395899302684 , explore ratio: 0.0499340670765195\n",
      "Episode 1943 , steps =  195 , total reward: -7.0211908926256195 , steps_avg: 239.58590534979425 , reward_avg: -8.355861876545692 , distance traveled: 30.88990067034958 , average speed: 0.15840974702743374 , explore ratio: 0.0499340670765195\n",
      "Episode 1944 , steps =  346 , total reward: 58.93243582635971 , steps_avg: 239.64061696658098 , reward_avg: -8.321266350734428 , distance traveled: 142.22502425383783 , average speed: 0.4110549833925949 , explore ratio: 0.0499340670765195\n",
      "Episode 1945 , steps =  52 , total reward: -0.5359989142970476 , steps_avg: 239.5441932168551 , reward_avg: -8.317265699431019 , distance traveled: 7.518296942710878 , average speed: 0.14458263351367073 , explore ratio: 0.0499340670765195\n",
      "Episode 1946 , steps =  46 , total reward: -2.61897021913094 , steps_avg: 239.4447868515665 , reward_avg: -8.314338993996863 , distance traveled: 4.927783778607845 , average speed: 0.10712573431756184 , explore ratio: 0.0499340670765195\n",
      "Episode 1947 , steps =  267 , total reward: 14.610502690148863 , steps_avg: 239.45893223819303 , reward_avg: -8.302570594775021 , distance traveled: 64.25825614070055 , average speed: 0.24066762599513317 , explore ratio: 0.0499340670765195\n",
      "Episode 1948 , steps =  76 , total reward: -21.80473990700642 , steps_avg: 239.37506413545407 , reward_avg: -8.309498336854157 , distance traveled: -13.490431422293186 , average speed: -0.17750567660912087 , explore ratio: 0.0499340670765195\n",
      "Episode 1949 , steps =  96 , total reward: -11.578834892015909 , steps_avg: 239.30153846153846 , reward_avg: -8.311174919702957 , distance traveled: 6.630651030521841 , average speed: 0.06906928156793585 , explore ratio: 0.0499340670765195\n",
      "Episode 1950 , steps =  124 , total reward: 9.203130914011336 , steps_avg: 239.24243977447463 , reward_avg: -8.302197828040367 , distance traveled: 35.46564608677291 , average speed: 0.2860132748933299 , explore ratio: 0.0499340670765195\n",
      "Episode 1951 , steps =  267 , total reward: 41.932215324327196 , steps_avg: 239.25665983606558 , reward_avg: -8.276462985236899 , distance traveled: 106.29036040797835 , average speed: 0.398091237483065 , explore ratio: 0.0499340670765195\n",
      "Episode 1952 , steps =  166 , total reward: 6.013862938333291 , steps_avg: 239.21915002560164 , reward_avg: -8.269145870068659 , distance traveled: 41.427333219945425 , average speed: 0.24956224831292426 , explore ratio: 0.0499340670765195\n",
      "Episode 1953 , steps =  131 , total reward: 5.342610825590783 , steps_avg: 239.16376663254863 , reward_avg: -8.262179771452661 , distance traveled: 31.14554925408213 , average speed: 0.23775228438230633 , explore ratio: 0.0499340670765195\n",
      "Episode 1954 , steps =  138 , total reward: -2.836260328277957 , steps_avg: 239.11202046035805 , reward_avg: -8.259404365087867 , distance traveled: 24.00627848088741 , average speed: 0.17395853971657543 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1955 , steps =  490 , total reward: 117.87591187626802 , steps_avg: 239.24028629856852 , reward_avg: -8.194918007091264 , distance traveled: 245.35444203324604 , average speed: 0.5007233510882573 , explore ratio: 0.0499340670765195\n",
      "Episode 1956 , steps =  528 , total reward: 50.1816409420118 , steps_avg: 239.38783852835974 , reward_avg: -8.16508839086791 , distance traveled: 150.29263066132572 , average speed: 0.2846451338282684 , explore ratio: 0.0499340670765195\n",
      "Episode 1957 , steps =  55 , total reward: -17.10600961766827 , steps_avg: 239.29366700715016 , reward_avg: -8.169654744916327 , distance traveled: -5.4095258277654645 , average speed: -0.09835501505028117 , explore ratio: 0.0499340670765195\n",
      "Episode 1958 , steps =  381 , total reward: 55.60413395351908 , steps_avg: 239.36600306278714 , reward_avg: -8.13710048830661 , distance traveled: 141.9530535283686 , average speed: 0.3725801929878441 , explore ratio: 0.0499340670765195\n",
      "Episode 1959 , steps =  272 , total reward: 27.558272417060973 , steps_avg: 239.3826530612245 , reward_avg: -8.118888563354892 , distance traveled: 88.55150751376522 , average speed: 0.32555701291825445 , explore ratio: 0.0499340670765195\n",
      "Episode 1960 , steps =  55 , total reward: -0.9215985676242643 , steps_avg: 239.2886282508924 , reward_avg: -8.115218349180628 , distance traveled: 8.377656172513964 , average speed: 0.1523210213184357 , explore ratio: 0.0499340670765195\n",
      "Episode 1961 , steps =  198 , total reward: 11.266532086968404 , steps_avg: 239.26758409785933 , reward_avg: -8.105339781170358 , distance traveled: 52.40085013970732 , average speed: 0.2646507582813501 , explore ratio: 0.0499340670765195\n",
      "Episode 1962 , steps =  140 , total reward: 8.282633032314463 , steps_avg: 239.21701477330618 , reward_avg: -8.0969913487641 , distance traveled: 40.11941162914039 , average speed: 0.28656722592243133 , explore ratio: 0.0499340670765195\n",
      "Episode 1963 , steps =  61 , total reward: 1.909006459817288 , steps_avg: 239.12627291242362 , reward_avg: -8.091896645195575 , distance traveled: 13.537566960453985 , average speed: 0.22192732722055714 , explore ratio: 0.0499340670765195\n",
      "Episode 1964 , steps =  268 , total reward: 32.26377286106277 , steps_avg: 239.1409669211196 , reward_avg: -8.071359408805623 , distance traveled: 91.58685476694261 , average speed: 0.3417419953990396 , explore ratio: 0.0499340670765195\n",
      "Episode 1965 , steps =  59 , total reward: -0.6990714193712918 , steps_avg: 239.0493387589013 , reward_avg: -8.067609516644161 , distance traveled: 10.811445339918137 , average speed: 0.18324483626979893 , explore ratio: 0.0499340670765195\n",
      "Episode 1966 , steps =  162 , total reward: -6.489930439600116 , steps_avg: 239.01016776817488 , reward_avg: -8.066807442888672 , distance traveled: 18.160741717759517 , average speed: 0.11210334393678714 , explore ratio: 0.0499340670765195\n",
      "Episode 1967 , steps =  431 , total reward: 33.2136608798324 , steps_avg: 239.10772357723576 , reward_avg: -8.045831595163715 , distance traveled: 117.30144060183318 , average speed: 0.2721611150854598 , explore ratio: 0.0499340670765195\n",
      "Episode 1968 , steps =  75 , total reward: -23.346369832900052 , steps_avg: 239.0243778567801 , reward_avg: -8.053602310368253 , distance traveled: -5.537979769036173 , average speed: -0.07383973025381564 , explore ratio: 0.0499340670765195\n",
      "Episode 1969 , steps =  63 , total reward: -7.123187577079368 , steps_avg: 238.93502538071067 , reward_avg: -8.053130018625467 , distance traveled: 3.0686688349954787 , average speed: 0.048709029126912363 , explore ratio: 0.0499340670765195\n",
      "Episode 1970 , steps =  245 , total reward: 35.11144882622477 , steps_avg: 238.93810248604768 , reward_avg: -8.031230181565675 , distance traveled: 91.25340396076443 , average speed: 0.37246287330924255 , explore ratio: 0.0499340670765195\n",
      "Episode 1971 , steps =  440 , total reward: 51.284529911195676 , steps_avg: 239.04006085192697 , reward_avg: -8.001151195717418 , distance traveled: 147.50164577677853 , average speed: 0.33523101312904213 , explore ratio: 0.0499340670765195\n",
      "Episode 1972 , steps =  477 , total reward: 97.25112585584141 , steps_avg: 239.16066903193106 , reward_avg: -7.947804881955858 , distance traveled: 215.1082445669175 , average speed: 0.45096068043378934 , explore ratio: 0.0499340670765195\n",
      "Episode 1973 , steps =  79 , total reward: -26.191834056826295 , steps_avg: 239.07953394123606 , reward_avg: -7.9570470446584265 , distance traveled: -10.040105885602532 , average speed: -0.1270899479190194 , explore ratio: 0.0499340670765195\n",
      "Episode 1974 , steps =  353 , total reward: 66.86381889843922 , steps_avg: 239.13721518987342 , reward_avg: -7.919163061902428 , distance traveled: 151.50682218242446 , average speed: 0.4291977965507775 , explore ratio: 0.0499340670765195\n",
      "Episode 1975 , steps =  38 , total reward: -11.948311317222194 , steps_avg: 239.03542510121457 , reward_avg: -7.921202104541759 , distance traveled: 0.9602279238402844 , average speed: 0.0252691558905338 , explore ratio: 0.0499340670765195\n",
      "Episode 1976 , steps =  146 , total reward: 5.986750659873077 , steps_avg: 238.98836621143147 , reward_avg: -7.914167227068611 , distance traveled: 33.93758482262492 , average speed: 0.23244921111386932 , explore ratio: 0.0499340670765195\n",
      "Episode 1977 , steps =  259 , total reward: 38.4507653825586 , steps_avg: 238.9984833164813 , reward_avg: -7.890726917356969 , distance traveled: 98.69892301825806 , average speed: 0.3810769228504172 , explore ratio: 0.0499340670765195\n",
      "Episode 1978 , steps =  261 , total reward: 36.888492030810426 , steps_avg: 239.00960080848913 , reward_avg: -7.868099722335156 , distance traveled: 101.3281465704739 , average speed: 0.3882304466301682 , explore ratio: 0.0499340670765195\n",
      "Episode 1979 , steps =  60 , total reward: -15.307021614819147 , steps_avg: 238.91919191919192 , reward_avg: -7.8718567535939865 , distance traveled: -3.7686870724707853 , average speed: -0.06281145120784642 , explore ratio: 0.0499340670765195\n",
      "Episode 1980 , steps =  339 , total reward: 28.0332594658322 , steps_avg: 238.96971226653204 , reward_avg: -7.85373201042416 , distance traveled: 98.82845708370213 , average speed: 0.2915293719283249 , explore ratio: 0.0499340670765195\n",
      "Episode 1981 , steps =  444 , total reward: 53.29499622253797 , steps_avg: 239.0731584258325 , reward_avg: -7.822879978016006 , distance traveled: 145.43043466955422 , average speed: 0.3275460240305275 , explore ratio: 0.0499340670765195\n",
      "Episode 1982 , steps =  71 , total reward: -23.08834667019051 , steps_avg: 238.98840141200202 , reward_avg: -7.830578145788157 , distance traveled: -3.8805412609130143 , average speed: -0.05465551071708471 , explore ratio: 0.0499340670765195\n",
      "Episode 1983 , steps =  339 , total reward: -32.038748661743824 , steps_avg: 239.03881048387098 , reward_avg: -7.842779844636924 , distance traveled: 23.69449365366252 , average speed: 0.06989526151522867 , explore ratio: 0.0499340670765195\n",
      "Episode 1984 , steps =  67 , total reward: 2.082842555167772 , steps_avg: 238.9521410579345 , reward_avg: -7.837779531085385 , distance traveled: 15.322942651212214 , average speed: 0.22870063658525694 , explore ratio: 0.0499340670765195\n",
      "Episode 1985 , steps =  57 , total reward: -3.8021433819265438 , steps_avg: 238.86052366565963 , reward_avg: -7.835747488714207 , distance traveled: 4.780984141901135 , average speed: 0.08387691477019536 , explore ratio: 0.0499340670765195\n",
      "Episode 1986 , steps =  491 , total reward: 45.80880394158742 , steps_avg: 238.98741821841972 , reward_avg: -7.808749727551499 , distance traveled: 147.2670935693057 , average speed: 0.2999329807928833 , explore ratio: 0.0499340670765195\n",
      "Episode 1987 , steps =  79 , total reward: -7.572975715326148 , steps_avg: 238.9069416498994 , reward_avg: -7.8086311289538 , distance traveled: 8.031466716974974 , average speed: 0.10166413565791106 , explore ratio: 0.0499340670765195\n",
      "Episode 1988 , steps =  465 , total reward: 50.94377893427677 , steps_avg: 239.02061337355454 , reward_avg: -7.779092461249812 , distance traveled: 149.79597729697122 , average speed: 0.32214188666015314 , explore ratio: 0.0499340670765195\n",
      "Episode 1989 , steps =  264 , total reward: 8.867820089013604 , steps_avg: 239.03316582914573 , reward_avg: -7.770727178561238 , distance traveled: 55.859721908275965 , average speed: 0.21158985571316655 , explore ratio: 0.0499340670765195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 1990 , steps =  113 , total reward: -6.4107060944171055 , steps_avg: 238.9698643897539 , reward_avg: -7.7700440941392666 , distance traveled: 11.378336602672936 , average speed: 0.10069324427144191 , explore ratio: 0.0499340670765195\n",
      "Episode 1991 , steps =  74 , total reward: -12.958936853140592 , steps_avg: 238.8870481927711 , reward_avg: -7.772648959982139 , distance traveled: 1.88001223934607 , average speed: 0.02540557080197392 , explore ratio: 0.0499340670765195\n",
      "Episode 1992 , steps =  58 , total reward: -6.627047762877618 , steps_avg: 238.79628700451582 , reward_avg: -7.77207414754004 , distance traveled: 2.394632254689932 , average speed: 0.04128676301189538 , explore ratio: 0.0499340670765195\n",
      "Episode 1993 , steps =  269 , total reward: 5.524752541884132 , steps_avg: 238.81143430290874 , reward_avg: -7.765405728939526 , distance traveled: 58.956675782650706 , average speed: 0.21916979844851564 , explore ratio: 0.0499340670765195\n",
      "Episode 1994 , steps =  64 , total reward: -12.52143848925084 , steps_avg: 238.72380952380954 , reward_avg: -7.767789705260483 , distance traveled: -3.939677642136812 , average speed: -0.061557463158387685 , explore ratio: 0.0499340670765195\n",
      "Episode 1995 , steps =  121 , total reward: 4.7661865857541565 , steps_avg: 238.66482965931863 , reward_avg: -7.761510158020497 , distance traveled: 27.819125157693122 , average speed: 0.22991012527019108 , explore ratio: 0.0499340670765195\n",
      "Episode 1996 , steps =  69 , total reward: 1.0202674622442567 , steps_avg: 238.57986980470707 , reward_avg: -7.7571126729828075 , distance traveled: 13.944116002321245 , average speed: 0.20208863771480065 , explore ratio: 0.0499340670765195\n",
      "Episode 1997 , steps =  65 , total reward: -14.920136961669973 , steps_avg: 238.49299299299298 , reward_avg: -7.760697770224393 , distance traveled: -5.357900545522571 , average speed: -0.08242923916188571 , explore ratio: 0.0499340670765195\n",
      "Episode 1998 , steps =  289 , total reward: 33.5976890319566 , steps_avg: 238.51825912956477 , reward_avg: -7.740008232054218 , distance traveled: 96.3138390630483 , average speed: 0.3332658791108938 , explore ratio: 0.0499340670765195\n",
      "Episode 1999 , steps =  367 , total reward: 42.89447768037254 , steps_avg: 238.5825 , reward_avg: -7.714690989098004 , distance traveled: 120.52150940157479 , average speed: 0.32839648338303756 , explore ratio: 0.0499340670765195\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BipedalWalker-v2').unwrapped\n",
    "env.reset()\n",
    "model = DQN()\n",
    "\n",
    "if use_gpu:\n",
    "    model.cuda()\n",
    "\n",
    "transition_buffer = TransitionBuffer()\n",
    "\n",
    "reward_his = np.zeros(NUM_EPISODES)\n",
    "steps_his = np.zeros(NUM_EPISODES)\n",
    "distance_his = np.zeros(NUM_EPISODES)\n",
    "velocity_his = np.zeros(NUM_EPISODES)\n",
    "\n",
    "min_max_states = np.zeros((NUM_FEATURES, 2))\n",
    "\n",
    "explore_ratio = START_EXPLORE_RATIO\n",
    "explore_decay_ratio = get_decay_ratio()\n",
    "\n",
    "for episode in range(NUM_EPISODES):\n",
    "    env.reset()\n",
    "    action_vec = env.action_space.sample()\n",
    "\n",
    "    current_state = FloatTensor(np.zeros(NUM_FEATURES))\n",
    "\n",
    "    for i in count():\n",
    "        env.render(mode='rgb_array')\n",
    "\n",
    "        if i < FALL_TIME:\n",
    "               action_ind = 8\n",
    "\n",
    "        else:\n",
    "            randomization = bool(np.mod(episode, 50))\n",
    "            action_ind = get_action(model, Variable(current_state, volatile=True), explore_ratio, randomization)\n",
    "            action_vec = get_action_vec(int(action_ind.cpu().numpy()))\n",
    "\n",
    "        obs, reward, done, info = env.step(action_vec)\n",
    "\n",
    "        distance_his[episode] += obs[2]\n",
    "\n",
    "        if done is False:\n",
    "            next_state = FloatTensor(obs[:NUM_FEATURES])\n",
    "            reward_his[episode] += reward\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        if i >= FALL_TIME:\n",
    "            transition_buffer.push([current_state, action_ind, FloatTensor([reward]), next_state])\n",
    "\n",
    "        current_state = next_state\n",
    "        \n",
    "        #update model\n",
    "        model.update(transition_buffer)\n",
    "\n",
    "        if done is True:\n",
    "            steps_his[episode] = i\n",
    "            velocity_his[episode] = distance_his[episode]/i\n",
    "            print(\"Episode\", episode, \", steps = \", i,\n",
    "                    \", total reward:\", reward_his[episode],\n",
    "                    \", steps_avg:\", np.mean(steps_his[:episode+1]),\n",
    "                    \", reward_avg:\", np.mean(reward_his[:episode+1]),\n",
    "                    \", distance traveled:\", distance_his[episode],\n",
    "                    \", average speed:\", velocity_his[episode],\n",
    "                    \", explore ratio:\", explore_ratio)\n",
    "            break\n",
    "\n",
    "    if explore_ratio > END_EXPLORE_RATIO:\n",
    "           explore_ratio = explore_ratio*explore_decay_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visiualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEKCAYAAADuEgmxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJztnXecFeX1/z9nG0tHYAUEZEFBBEXRFcGCGKRJFGPsxpDEEvOVqDEmwR92TazRGDWJ2GMvsaBgoyh2WDpIh0WWurSlLuyy5/fHnbk7d+7M3Okzd/e8X6997b1zn3mec+fOPOd5znOec4iZIQiCIAh2yIlaAEEQBCF7EKUhCIIg2EaUhiAIgmAbURqCIAiCbURpCIIgCLYRpSEIgiDYRpSGIAiCYBtRGoIgCIJtRGkIgiAItsmLWgC/adu2LRcXF0cthiAIQlYxa9asLcxclKlcvVMaxcXFKC0tjVoMQRCErIKI1tgpJ+YpQRAEwTaiNARBEATbiNIQBEEQbCNKQxAEQbCNKA1BEATBNpEqDSIaTkRLiWgFEY01+PxXRFRBRHOVv6uikFMQBEFIEJnLLRHlAngSwBAA5QBmEtEEZv5BV/QNZh4TuoCCIAhCGlHONPoBWMHMq5j5AIDXAYyKUB5BEIRYU7m3Gh/OXx+pDFEqjY4A1mrelyvH9PyciOYT0dtE1NmoIiK6hohKiai0oqIiCFkFQRAig5nBzPj963Mw5tU5WLttb2SyRKk0yOAY695/AKCYmfsAmAzgRaOKmHk8M5cwc0lRUcZd8IIgCFlDbS2j6y2T8LdJi7Fue0JZVFUfjEyeKJVGOQDtzKETgJR5FzNvZeb9ytunAZwYkmyCIAix4CAnxtLPf10WrSAKUSqNmQC6E1FXIioAcAmACdoCRNRB8/ZcAItDlE8QBCE26M0wURGZ9xQz1xDRGACfAMgF8BwzLyKiuwGUMvMEANcT0bkAagBsA/CrqOQVBEGIGiIjq364RBrllpknAZikO3a75vUtAG4JWy5BEIS4UMtxmWMkkB3hgiAIMea/3yQilh+sjYfyEKUhCIIQY+avq0w7FqX6EKUhCIIQY1hjnqLksWhkAURpCIIgxJp4GKXqEKUhCPWcNVv34A9vzMWBmtqoRRHcEDOtIUpDEOo5f/nffLw7Zx1Ky7aF3jYz4+Xv1mDP/prQ264vaL2nYuBxK0pDEOo7pFjCoxiwTl++Bbe+txD3TtQHrxbsYrZ+sXTjLpRvDz8GVaT7NARBCB51dBrF4um+A4kZxtbdB8JvvJ7AJup+2D+mAwDK7h8Zpjgy0xCE+k5SaQQ81/h6xRbsO6APpOfvLKdsy54GZ+oy2p4R9G9phSgNQajnkGFAaX8p27IHlz/zPW55Z35q2z7PcgY9/Dl+9fwMfyqLIcycFvY8ZhvCRWkIQn0nDPPUrqrE6H9Fxe7UtgNoa2bZ9gBq9Z/NO6vw0rdljs55/usynP7gNCxar93QFy+tIUpDEBoIQXY9mc0l/rbe49aPsLGyytc6/ebql2bhtvcXOVqsnrE64eH249a6c7TKPoxZYyZEaQhCA4EjsHOoUVn9bvpATS2mLd3sb6U+s31PYvHfa8yoeM0zRGkIQlazcF0lvlhmneI42XGHIZCOnOQivOCEN0vXolZRNkbKXsKICILgip8+/hVGP2e9MJw0aETQ0ajrKUGE947bArEKM+OxycuxaWfCfHbZ0987rmPa0gq8UboWQKr3VBw298k+DUGo54TlcmvYNoIxT8WZBesq8ejkZcn363bsSyuzbNMu1Bxk9DqsRcpxrVLYujuR6VryaQiCECqfL02Yr+z2Pc98uQpvzypPOz5l8SZMmLfe8ty0hdoGaJ6ys4Yx9NHpOPufX1qWqYlJ/gw9kSoNIhpOREuJaAURjbUodwERMRGVhCmfIIRJbS1jV1V1YPXbVRr3TlyMm9+al3b8yhdLcf1rcxy1WRfKO/wOcFdVdSSJi7y0qJ1pHEyuadQdW7JxV9qxsIlMaRBRLoAnAYwA0AvApUTUy6BccwDXA3BuGBSELOK+jxbj2Ds/DWzHcxT9TFQ5rQ/WMo6981OMe3dBJO3rcaM01ZlGlLu/jYhyptEPwApmXsXMBwC8DmCUQbl7ADwIIN5O2YLgkffmJkw/gSmNAIenMTO7o6Y2EQb+f7PTzWxBMm/tDpz/r2/Sjru5Pqr3VG3MItpHqTQ6AlireV+uHEtCRH0BdGbmD8MUTBCCoKr6IHbbUAiZ1g2yiagyzUW1Ce75r1cbHnezmC0zjXSMftXk1SGiHACPAvhjxoqIriGiUiIqraiw9lkXhKgY9NDnOOaOT0w/Vx+IeycuDqT9ILseMyuU1nNrxebdWKrY5PXs3l+Tcb9JJir3VUcezDDH5EK4ufZGaxp19TXMgIXlADpr3ncCoB1iNQdwDIDPiagMQH8AE4wWw5l5PDOXMHNJUVFRgCILgns27ozWwhqFCSlHsyP8rEe+SIbz1nPzm/Mw+rkZacH6tGQyrx1316c49YGp7oV1wGOTl6P/36akHTdbw3nuK+MZiBXVBxN2qXjNM6JVGjMBdCeirkRUAOASABPUD5m5kpnbMnMxMxcD+A7AucxcGo24Qn1lxeZdKB47ESs2G4+C6w/Ou5/aWvY0ele70EzmmZVKoMO9aaHVzTEabe/YW236mZ88OnmZ4SAgx2TGdd9HS7B5V+ZBg9asxmkvjHEaFNErkSkNZq4BMAbAJwAWA3iTmRcR0d1EdG5UcgkNjwnzNgAAPpy/wfe6r39tDq541p7jX9CORm5mGg98vAS97/gko+KYvcYk8qyPEXbd1OHmnI8XbsScH91F0jUzT7mVBTBWgNq6bnt/kbuKXRLpjnBmngRgku7Y7SZlB4Uhk5BdnHr/VDTKy8HUmwdFLYohcVrUdtNnvTNnHYDMHl13fmCcztXpgrRfitOLkrr25VkA3GXEy7EYhruVKW57/GRHuJDVrNuxD6u27IlaDN9ZunFX0uXSL8IaqRvW40N7bkQJu7+1nGm4lCaKjZFWiNIQhBgy7B/T8dT0Vb7WGYbHjb7PTL7P0HQcAvFlYsvu/bjpzbkGKW3rsFIabjG6dF49zbwgSkOot0xasAH3TQrGfTUMFqzb4Wt9UQxYk2066Es/XrjRMMiffsQ97t2Fmdv1kQc/XoJ3Zq/D+3PXmZYxWwi3LZPB+UYTzoc+WWqjsmAQpSHUW/7vldm+j9aDJOgNaZ76UY+iZTp92aa6NLHXvjwLo574KuXz2lrG7x3GvVJZuK4S170623McqmTEXqsyluYpl8TMPCWh0QUhJg9l8N5Tzr7nFiU0t6c2HXaVavktuw+kHN++9wA+WrjRVbvXvjwL5dv3YezwnujcuokjebSoi9xWl9HqNzS6/uqspeYgY+rSzZho4MEXj7uzDlEagiAYcsaD09C4wJ8uIqo1C2ZGVXViDaIwP9djbYkvYbXn5PmvyyxkST92w+tzLVuctmRz7HKhi3lKEBoITidUew4cRFzGuVZS7DQIJ6/9rurCda7VgoMN6kKihMevX5iJzbu8z/j8RJSGIMSUH7fttRXg0C5+eU852vgWcA/75fIK9LnzU3y9Yotp81U1/oSJrUubGw9FGhWiNIQGj5PQFUGiHwcvXLcTl4z/1sf6CbW1jGe+XOUpNMjP/vUN5q2159mldq/frdrmur2XvluDH01iUj36WSKt6ozVqfVru3W/EjEl42i5PN+promrF7KsaQgNnmdcBJMLi4Xrdvpa34cLNuDeiYuxaWcVxo2sy3lWW8u4+8MfMPqUYsPz9J5dGyqrcFxno3KpOO0o9eX3HTiI295biPxc4y509o8J5aVVDD+s34lpSzcb1G0uTM3BWuTlWo+hVfOU202XDAYz48vlxrOibEGUhiA0EBiMTZUJ+7i+31u2eRde+KYML3xT5rGN9DYdna8rrp5ffdC6noOaE7W5t+0orbdK1+JPb8/Hl38+09K7yutMo5aB12euxS3vxCOboFvEPCUIClEl7km2H4KLkWqKa1Lg1ZPIHo5nGi67ZDujf6MSW3bvxweKm+uKit326nEdQ4qxcvPuzAVdMnftDsvQ8n4hSkOINVXVB3HAp4XMbKV47ESsqkjvbB6bvNxxXS99t8ZRea92eKPTt+7ebxrI0W2H7GbdYuG6SpTcOxnTlZAcmVS2V++p6csqsK86uPWz8578Gqc/OC2w+lVEaQixpudtH2O4SeIepzAz7pywCAvXVfpSn9O2vTBlcbqN/tHJyxzVsXzT7uSGPVWcRz9bhuKxEz3JZoXR9/7tS7Nw/WtzsMnHpFQHXVxfoyyClru91R3hLn/Luz74ITCloSZsCgNRGkLscRrF9tmvVuOi/6R7He3YW40XvinD5c/Yy2+hZeG6SiVRU3DmBSvcWK4q91VjQXmdgtTO2LbuOYC12/bisSnOZyte2aBsVjOaQbo2/diYaZTcOxkfeAhVr27zMJJx34GDyU2EVux3MGt2cileVmaQHVs1dnCWO2QhXKh33POhSW4HD0sGqjllyuJNOPLQZo7PD9q1v3jsRCy6axiaNqp7pH/53IwU19iqmrpO7bUZP+K1GT9mrHfrnkQ4D7fXzs7X1srodk3D7kzj96/NwRlHFaFFYX7aZ0RkOYtIek8ZlDn69o9RkBfdGPwuJZ9J/25tAm9LZhqCEDIfL/Q/QyAA/G92ecp7/V6Kl7/LrCT8YMvu/fhG3Wxnoy9frZlJpnlP2dQhTtY0ql2ukVEG7ym/197cDDTCCNcSqdIgouFEtJSIVhDRWIPPryWiBUQ0l4i+IqJeRvUIgh282qS1VO6txin3TUkx/9jl2pdne27fCC9fa/ue9FAcbrnoqW9xmWICNJo5kIWZR4/dr+REaViFE7Fe01DK6AqV3DvZdtv1gciUBhHlAngSwAgAvQBcaqAUXmXmY5n5eAAPAngkZDGF+oSPsYO+XbUV6yur8PhUe2sCcQ88cenT3/lW16oK85kDYL0DP4zd1mZlMw7Sk/dPagV+RAM2xvnVCMNpPMqZRj8AK5h5FTMfAPA6gFHaAsys3Q7bFPF/9oR6TpA3oJVpwc4eDnUGtb/mICYtCMYEpmnNXimDYtv2HEg/qLBXF94kiFSnrPuf2p75ecnNfSH1QnENcRWl0ugIYK3mfblyLAUiuo6IViIx07g+JNmE+ozDh7HMwHvr2pdnuakqjfs+WozisRN97Rwf+ngp/u+VYExgGdEpN6tvZWS6+sObc3Vl7GEWm8oIdSH725VbbZ8DaM1TMe3NQyJKpWE0dEr7NZj5SWY+AsBfANxqWBHRNURUSkSlFRXR5c4V6vhx614Uj53o+MEMEjebsz5dtBGDHv4cH5skANpYWYXisRPTAubpMetonvpilfK5tRxOzA5GqVK9kt6+PYnsdLBa5bFpZ6qpx27//H2G669FVRp6xwEia+8t9f75YJ77WVz5dvu/jSyEp1MOQBvyrBMAKyfq1wGcZ/QBM49n5hJmLikqKvJRRMEt361KKAv9gxklbh7CHzYkLKRmI9kFykbBV753ttO6eOxEVGjyJGzcWYXKveaL0XY6gziOfy1nGnYEDuJLsfHsMROqI8XSTembAu1iNzpwnIlSacwE0J2IuhJRAYBLAEzQFiCi7pq3IwGEvxNJcIU6YnOT9+ajBRtSOlS/MRv9vvhtGQDgvTnr8N6cdYZl3A7kjFpcu71OEZ1y/1Ts8pg746OFGzH5h02e6giTqJRcLQODHv7c8DPrNY1g5DHDr/wnfhPZ5j5mriGiMQA+AZAL4DlmXkREdwMoZeYJAMYQ0VkAqgFsBzA6KnnrKwdqagPZlKQ+fE6DAJ7/r68x+8cd6Nm+OT6+caDPQll/vG3PARyoqcWNbyTs6uf17Zgmv5+P8c///Y3tsnau4ozV2zBj9TYM793evVC2sRPYjz0v5gbRcVqla7Ukqpy1Dggj6Gak+zSYeRIz92DmI5j5r8qx2xWFAWa+gZl7M/PxzHwmMy+KUt76xrJNu9Dj1o8Mk9l7RX0s1eeseOxEjJ++MqXM9GUVeLN0bcoxNT/Cmq3uonVa2dDVDsjp4qwWK88fpzjtu8KML6THfddtfuY5j3+V+ewABtvj3jUOTT7nR2vTUdgzjbgiO8IbMOrGtMmL/TdpqKM57eDsb5OWJF+XbdmDXz43A39+e77l+U75ZFHm72JVdaZmx09fhb53f+pQKu+d39SlFeg+7iNbwRaXb3Zvc7ePSQ+q+6JW39tOKtsgDDTTlho7yzzymXUAyLBD58fVSUuURgNGPxvwte7kDW9cuZlNWcWt0rCaCdip0k672y0WrINCDd9tJz/3ygrni7x+od2Yzey90w/bvdWqOaPnJG7ut/Xde0qIGPWGD2IE5UQhrazYjbdnpXpZ1ejCQpz2wFRbUUStAtfZctYJqA+YV57dXjN2r8sC3UzIVqiQGPW7li63RuUDlD1GlyUFURoNGC8zjR+37k0Z1TNzatjwpELKPBob9uh03PzWvFTZdKeUb9+Hnrd9bFnP7v01uO29hRllt+oYJga0k/pCg1Dt2U3iGlZVH8Rmk7wYDO8L2XHqOHMMFjXiJF9YSGj0hkzSw8k5Ax+ahsb5uVh8z3B89sMmPDZlGRau24lXrz4ZpxzRNkUhZRqN6WcVbhn/xUrLz1XlZSWPfo3FrkJtqGukv31pFr5YZr6h1stIfOG6SrRrUei+Ahes3Gxs2ltQXok1W9M/c+2JZQPZ3CfEDnUU6PZGU7OQXf3fUixcl9gEp4a5Vm/4nBi5KdaHUWFU3yF9xkD4ycOfWyqMxHnueXtWeeh7Fc55wtij65wnvsKbpekbVVdFuH4UFaI0GjC1yZmGfx37uHcX4oWvV2vWS/zt6G58fQ5mlhmHjLAT1A8+y9OQyZRR0c4iceW+atMR9QvflMX+xxrmUypi/6jn+zSEaEluwPP5Pnt7drnGPGWdDc0p781dj18/P9Pws0zfIymGTXHWbtsbO7NTnBaN7ZDptz/uLmv35X5/m+KnOFlFXHeEi9JowGQyTzEznp6+Clt278fmXVU4/cGpKVnWzNhYuR8+LVMYYuzFwsk8yWZ8u8pZ8MRpSzc7Kq9n1hr7QfRiT3oo0YynjH1nQTIGmVB/EKUhAADemV2etuN4wbpK/HXSYtz05jxMnL8Ba7ftw4vflGWsa8vu/XXmKUrtXlZW7EblPo/7HAy0xpTFm7Flt/kejdVb9uD61+YAsD+Cc5INzogXv3EWxNAOd0xYhJ1V4e8T+fun1hvfjHh7Vjlem7E2c0HBmJguhIv3VANGtRx8tHAjXpuxFmVb9+KmIT2Sn6tKZHdVdbKftustcu/ExQDS10sG//0Lb0LDeKax54D17uJdLjpaqwxzdrBKK+qFxet34uRubQKp24w3SvWdf9wMd0JYiNLwiVPum4L+3drgkYuPj1oU26izgR3KDmertJV2F5nTz/PfDm8kixP5tPJ8s3KLabmHPlnqKZhjUKM+Rvx2InthfQD5P+oDVhtVoyTjE0FErcMQJNtZX1mFd0zCaceVdCdKG+foTpqdIaxFwnvK35s/hxI7xO/+4Afb52hnPFppLnv6e8vzDtS4DxIYVKyiS8Z/l9HVNWgO+Bg88e8ZYj41VN6fa5VeyJi45Aj/nojeIqKzye1wU4gldr2nZmuif+rNUx9myGJmtIvWjPk2Q20QEcq378NzX6+uO2a7lfAIMipqpkX/oPnz2/MyFxJCx05AS6/YURo9AIwHcAWAFUT0NyLqkeGcBs8bM3/MOAp3ytQlm3D/R0syF7SJ3sShVR7FYydi3Lt1ITm+XJ4w4+jnDHZmEXZn2epCdSaM+uKPFxmnY02eE4FWCWpNA/BvF71bqqqjC9MumJMSyicgMioNTvAZM18K4CokEiHNIKIviGhA4BJmKX/53wKc/y/7SXbs8JsXSvGfDKEynJDcS2Hy+ZKNdSG2a22E4DCi5qD/nZuRAnCSEySI9QAiwrJNu7Bk486UY0Gxx2OWP6F+EsZgws6aRhsiuoGISgHcDOD3ANoC+COAVwOWT3DA9j0H8OS0Fai1eePo+04rG/zUJeqeBWc35XertuKO9+3lzrJfs7POWL+DPKjHauij0zH8H18CSOQLWe4hl3QmdkQQnl2IP7FQGgC+BdACwHnMPJKZ32HmGmYuBfCfYMUTnHDr+wvx0CdL8c1Kexuq0hbCbfTFtQ6tEj9s2Gngrmkij04gs0Vop1afi54KP8LsoIc/R+kaf82TWmSmETzZ6KHmdW+RHewojVuZ+R5mTkbrIqILAYCZH/DSOBENJ6KlRLSCiMYafH4TEf1ARPOJaAoRdfHSXn2nStlXYCfvBGCwpoFER/1eRF5g+vWRy57+zrDc5l3mrsFG5OfkpChEZuDxKctx3pNfO5YxLkS9piE0XOwojbTOHMAtXhsmolwATwIYAaAXgEuJqJeu2BwAJczcB8DbAB702m59oPpgLcb+bz7W79iH7XsO4MP567F9zwFMUUxIM8u24db3FjjeOUxEeHzqctz4xlzTMkHGw9EP7PwaqefnUprp7e+fLcPctf4lRno3ZEUbZEhuIYFcYmNMN/cR0QgAZwPoSET/1HzUAoAfc+N+AFYw8yqlvdcBjAKQdL5n5mma8t8B+IUP7caa3ftr8PjU5bhpSA80yss1LDN9WQVen7kWM1ZvS0Yavfe8Y5KfPzV9FQCgaUEebjn7aNO26lxu63bgbTJJqKMS5AA3qIc0LzcnVO8pO/G5vCIzjeBZtWUPWjXJR9tmjaIWJVZYzTTWAygFUAVgluZvAoBhPrTdEYDW2F2uHDPjSgAfGX1ARNcQUSkRlVZURLvpySuPT12Op75YhTdmmq8DqJ2rNjS1kY1bVR6m9RjMGjJtSMvG0Vd+brj+tmdmyH/uBwcD8EoTUjnrkS9Qcu/kqMWIHaYzDWaeB2AeEb3CzEGsuhkGKzUsSPQLACUAzjD6nJnHI7GXBCUlJVn9NKmLv1Y7kY2y4pmFHFiycSd6tm9h+NmmnYm1AXXxzM5oXK9o/FQiQS085oc80wiDXbIQLkSElXnqTWa+CMAcIkoPjJxYZ/BCOYDOmvedkJjd6OU4C8A4AGcws7MV0Iiw6/JqhJ3QE6o9uyA3B/sV5WI28lyyYZep0nj2q9Up7wlkq3P926TFmQu5IKhYOwTgq+XmMaYEwYrnv16duVADwipg4Q3K/58G1PZMAN2JqCuAdQAuAXCZtgAR9QXwFIDhzOwtuUGIeOn8VHdSZmDN1j048+HP8ekfBqK4TdNkGbX6fI3SMLNxOwnjsXzzruTObzPKt+/DO7ODWfRVZz5+s76yKhl1VxCccpeDGGcNASvzlLrFNgfABmauAgAiagygndeGmbmGiMYA+ARALoDnmHkREd0NoJSZJwB4CEAzAG8pu2t/ZOZzvbYdNF58pdWRfi0zPpy/AbUMvDN7HXq0a64plahfa6s386bJ0yiNdUo00Y6tGhuWnWXDW2lvhhDkgiDUb+yERn8LwCma9weVYyd5bZyZJwGYpDt2u+b1WV7biAIv7pBq6AlGnZmLCNhfU7f3wqh6s5mGNv7RqfdPBQCU3T/SsGyLwvyMOSQWrttp+bkgCPUbO/s08pg5mRJNeV0QnEjZj9VMY2dVNS57+rvkqF+P2sUzA+/OTZiBcohSFIVavbYVszbzHJinmjQydvEVBEFQsaM0KogoaRIiolEAZFXRAn33vauqGn98cx52VlXjg3nr8c3KrXhi6grjk9U1DTBWVSRcahfowh0bucqaBQbMy7WfRKjAQVmVF2ykfxUEof5gxzx1LYBXiOhJ5f1aJMKkNyh+WL8T78wux7iRRzuOXvrcV2X43+xyHNaqEO1bFlqWzVHNUxod8PnSipSZhPqZtsxzJh4elfuqUVq2DU0KUn9qI/fWfBdKQxCEhkVGpcHMKwH0J6JmAIiZgwvdGWMufupb7Npfg2e+Wo2HLzwOF5zYybSs2ZKGHVVjVkbr1aRWb2dfg1GOiunLKvDYlOVpx514WgmC0DCxExq9JRE9AuBzANOI6O9E1DJwyeKGpj994Rtzv+2q6oNp9qmkOUm3NqGydff+tNATVgpB/cztcvt1r8w29pTKxu3egiCEih17xHMAdgG4SPnbCeD5IIWKO1Yb8Hre9nHasWSMJ20dmjenPjA1GXqCKPUcI4zMU04w2028q0rcaQVBsMbOmsYRzPxzzfu7iMg8DGoDQO3YN1ZWYfOuKvTp1Crl87RQGxnqU1NnVlUfrFvTsChfl0XP35nBqhAC7QmCkN3YmWnsI6LT1DdEdCoAY3/RBoK6ED7woWk494n0nAy36TPVsb3YTg98vCQ5G7Ha66F+JIFOBUEIGztK43cAniSiMiJaA+AJJDyq6hV7D9TgqS9WYqHGvXXi/A0oHjsRm3XhwtWO3Syo4Afz6kJoMTP+qbjXEgjb9yS3vGDttr0pOS+e/7oMb89K5Lqyysym6grJqSAIQtjY8Z6aC+A4ImqhvK+XW4L3HTiI+z5agrvO7Y1jOrbEis27cN2rswEAS3W5np143J72QF1KkJ1V1ckggQTg9Aen4Yiipinl11cmFNTTX5ovtquKR1SGIAhhYxXl9iaT4wAAZn4kIJkiQV1LUEfvZz0y3bTsxkrrREVatDu/tbMHtcNfWeF8HeGvSpRZq/DpgiAIQWA102hu8Vm9Q92jYCfY4IbKKrzgIlyyWJMEQch2rKLc3hWmIFGjBvazu05wp4twyVqvKpklCIKQjdjZ3NeDiKYQ0ULlfR8iujV40cIlN2meCq4NrT6qqraOJisIghBH7HhPPQ3gFgDVAMDM85FImFSvUBe3veTCcIKqNOpbGlJBEOo3dpRGE2aeoTtW77YOJ81TASoNbc2TFycSERbmSThyQRCyBztKYwsRHQGlzyOiCwBssD4l+1DNU3//bFlgbRgtlxTmS2RZQRCyBzs91nVI5OnuSUTrANwInzb3EdFwIlpKRCuIaKzB5wOJaDYR1SjKKjCsIrxaxZoCgDKb4TeM8mDIgrggCNmEndhTa5j5LCJqCiDHr9DoRJQL4EkAQwCUA5hJRBOYWeuW9COAXwG42Y8Q/128AAAgAElEQVQ23cJgS7UxSAk2mIn91ekKYk+G9KqCIAhxws5MYzURjQfQH8BuH9vuB2AFM69SUsi+DmCUtgAzlykL7/ViOD5xQb2z6gmC0MCwozSOAjAZCTPVaiJ6QhvA0AMdkcgCqFKuHIsdBHKcrU8QBKE+klFpMPM+Zn6Tmc8H0BdACwBf+NC2US/synWJiK4holIiKq2oqPAoVjqla7ahcl915oKCIAgeePjC46IWISO2XHeI6Awi+heA2QAKkUjG5JVyAJ017zsBWG9S1hJmHs/MJcxcUlRU5INoqfxjcnpqVEEQBLuccHirzIWyhIwL4US0GsBcAG8C+BMz+5WpZyaA7kTUFcA6JDYMXuZT3YIgCLGh12EtMPvHHVGL4Qt2ZhrHMfPPmPk1HxUGmLkGwBgAnwBYDOBNZl5ERHcT0bkAQEQnEVE5gAsBPEVEi8xrFOozV57WNWoRBEGAvXwageXPYOZJACbpjt2ueT0TCbNVqIQVSkSwj7ghCA0Bi+1isUG2Ixtwx4SFUYsg6LDafCkI9YHRA7rgp30Oi1qMjNjZ3NfgeKu0PGoRBB3i8SzUd+4adUzUItjCzkK4UQa/SgCzlFSw9Y79EtojdmQK5SIIQjjYMU+VIBFrqqPydw2AQQCeJqI/ByeaINQhMw2gfYvCqEUQBFtKow2AE5j5j8z8RySUSBGAgUjEhRKykK5tm0YtgiNkSQP4ydGHuj63VZN8HyURGjJ2lMbhAA5o3lcD6MLM+wDsD0QqIXCybeTe0M1TnVs3xl3n9nZ9fsO+eoKf2FkIfxXAd0T0vvL+HACvKVFvnSfKFmJBbpZpjYY+02jfohD5udnv7FjUvBEqdslYM5uxE3vqHgBXA9iBxAL4tcx8NzPvYebLgxZQCIacLFMaasDIToc0jliS7KFz63hdq+d/dRKm/PGMqMUQPJJRaRDRYwAaMfNjzPwPZi4NQS4hYLJMZyTlbVHo3jZ/XKeWsetIg6BLmyYAgCb58fKob9+y0NPv5wdtmhZE2r5TRg/oAgAY3PNQtG3WKGJpEtiZ784GcKuSXe8hIioJWigheLJtpuEHDSW8fZOCeCkLO/z2jG5Ri+CIw1s3CaWdYzslAh0SAY3y4mGetGOeepGZz0YiadIyAA8QkYR9zXJy4nH/2cYPJZfbQBZG2CgZfQyIqViucHo7enfkoNj8rk66jiMB9ARQDGBJINIIoZFtMw0/pM1mnZEt3mNxv638ks9pNewuVVAssbOmoc4s7gawCMCJzHxO4JJFQEOKpJptpho/Yk9l23cOgicu6xto/a2bZNeaQbYQp1vXVo5wAAOYeTgzP8fM9SMovAHHda4/iVIykRujm9AO6kPjZbyWzTMNNxh1NKcc0Tb5+qYhPUKUxhvDe7f3qaZobgKvM0WCt3vfT+ysafwHwEEi6kdEA9W/EGQTAiT7zFPe5c227+yVTCbw6wd3973NoC6x3rzTv1vrYBqyidNZq1vzlLqOEadb14556ioA05FIlnSX8v/OYMUS/CZON50b/JDfSGncc152RBat72TLmo1K2NISyJYjQRjPuR3z1A0ATgKwhpnPBNAXQEWgUkVEfj22X+h3gMdlqmsXP34aoweqRWH2uadmK14Wg4f2SjVPxcSRyDbZphStsKM0qpi5CgCIqBEzLwFwlB+NE9FwIlqq7AEZa/B5IyJ6Q/n8eyIq9qNdM4b0ahdk9ZGiH2WH7b7XoaW3CK1+maf09TSUxXE3ezfispkMAFo29mdToG8/d0i3jfqUxuk2taM0yomoFYD3AHymxKBa77VhIsoF8CSAEQB6AbiUiHrpil0JYDszHwngUQAPeG3Xirx6ENvHDP1Nl2UDNV8emtwcShvtxuhZTHJGjyJ08yEKsfaavXLVyfjTsKPQ2sGO6ONtOoacckQbp6I5Rn+/ur1/s0xn1LVH9mZqYchlZyH8Z8y8g5nvBHAbgGcBnOdD2/0ArGDmVcx8AMDrAEbpyowC8KLy+m0Ag6mhDA19Jn2mEZEgLvHjZzcyccXxbsohYOrNg3zdjFjctimuO/NIR+c0Kch10VIwFzQuG9uC4rcDrXfEx8m85WjOysxf+Nh2RwBrNe/LAZxsVoaZa4ioEon8Hlt8lKNBoO9/sukRbNk4Hyd2OcRzPWRgnoqjR5XX38aP/vVfl5+Arbv3Y8K8zEaFMC5hrV9TjRhSdv/IqEVwRJT2GKNbTX8r2CkDIrqGiEqJqLSiol6u0XsmbXNcFo3cHrvkeOT7sLHEaOBej30fPP3EZx/bwXbZcBRvvO7X0A0eZO/3DEOuKJVGOYDOmvedkL5WkixDRHkAWgLYpq+ImcczcwkzlxQVFQUkbnaTZp6KSI4oiTr2lN01gqj12Kd/cL8NK7B9Grob1q0nVlRhRFzDIbdngyiVxkwA3YmoKxEVALgEwARdmQkARiuvLwAwleu7cTMgsnii4Ru9D2tpcDS8x/H6wc7WFLzitoPs2Cp+4eMb4O2aAhHF5hpEpjSYuQbAGCQ2Cy4G8CYzLyKiu4noXKXYswDaENEKADcBSHPLjTNxevjSZxpxuQXDYcKYU/G7M45IOx6mlcGpok4ZH4Uop+MIrjZP8DJQ8WuQ49eCspv7ZqrHBFS2zFOeWrBHpD6mzDyJmXsw8xHM/Ffl2O3MPEF5XcXMFzLzkczcj5lXRSlvNqNf0/h/I452Vc+Se4bj0Obx8d+3S59OrQyDHsZp2q9i1DdccEInB+eHOyAI4xrWxmxq3DjfuWdZt6Jmjs9Rf8s43af1d2OCkEKersM85ci2JiWtKczPxZ+H9/RDpFiQDR7cS+4ZjotO6py5oE+oo/E4ddNpzlMRC/fvX5wYant2b9O4hBER6gFxdC11g99LWnG8KnqZ/P7p/nHx8RjpwDsqE1r53Iqa6Tv6Fe7lmI5G61rOOSwk0zOnLITHQ42L0mggZFumvrCI45pG0F3DeX074snLT/CtvjAGJGf0SPWKdHuNHrvkeO/CRECcZsTSlQRInBy99AELGxLP//qk5Gv9ZQjzsvQ93F2+lrB3AztPZRosI/t08K3TbNpIAlR6RZRGA8GPzHcqUagfLx2n9ky9HvejQz6/b8eMZW4Z0RNtbAYA9CpRlGMVP5XwPy81zzJod0BWX8ZKhOjXcVREaTQQsn2mEZhHkA+XxY5kHy3c6Lr+uP90cZevXhCjayxKo4EQ9W7osHjt6v6Wn0fVwa3esie0tmIyIHWE0c9i9VN5+Y4Txpzq4exwSYZGh2zuiy2PXHRc1CIEQrYrjRaFiXwKR7VvbllugMMw3XpXZDfYMZXoyzhp127Ju0f1tl2nn/yif5fkaytzn2vzisF5A7vXLYz/6pRi01ONpMl0D2UzYZiwRGnoONYnl7y4oVUaA7oFn//Abzq3boLXru6P+8/v4/hcq0VUu54/jfLMHxU3z6mfa0xRU1IcTL5uq5/mBk1+80FHmcebM/rt4xRm3C5xMgGK0tDh54/TyMWu0aBQO8dXrjoZr11jbcLJRFQ38IAj2qCxixwPVjMBu0pj6s2DUt5feKL9HdrG7Xo63RDfEgzFqIMyIyeH0EzxhDqhyyEY1jv4rJtnWiinoNDu04iLN6YojQAp9Kg0rjWIleSWejSw9RW7ZrvDWhamuMzePKwu47GbkNXNGtWlL/3lgC4pn3nPpxFdGJEoFA4B6HRIk8DbibLLtntdw5BRlIYOP5+3wnxvl/fw1v49CNm8puHVR9/aPGW/Du2sxOt98uZv62Z75xx3WMa27bC/ptaTTG4JWlGYec5plaPZ71FQT1I4Z1oIv+2niUzZYXzf+nFFfcRPTX1cJ3ebuYJA7fDiMMN93ML/PmycrC2YFbVzSfWj/25FzdD7sBYA0s1K6vF/XX4Cju/cypZiO6xlIYp8CiTp1OYf1BpBpnv18DaJPOq5OWSap/zd607BTUN6GH7mhxOEXYJUrHNuG4KLShLm0jC+kiiNgCi7fyQ6tCyMWowkcZppDD760KhFSOJk/4pZ52jLe0r5/9KV/fDFnwal1qup9v3rTsUfzkp0csOP6YD3rjvV1kzj7lHHeJqR/ePi49NC+dsdYNiNPeU0lI2arfHYjsaDr5eu7IfxV5yIJgV5OKtXO3z55zPTyvRs3wLXaxbN9fJa0bwwz3KR3QleB2tWMh/StMBb5Q4RpaEjDiNxFS8b2n5zaldco0lWr950UebRUPWW15GpvhPwgpO4Sdqi2uto54qqp57evQhdlBGyEcd1boU8lyYGtQ1VeTgJJ35e34549/9OwT8v7YsCE0+x3w1yv8b2xyE90KtDYgb1J816kBF9OrUEETC0V3s8dcWJ+K3mPtbStlkjDO3dPvledcvOZBbOyyG0KMzDPecdY1mubbNGeOHX/SzLBE0yNDrFp28SpaHDz05V7WSauPD40XJEUaKTcWKvvP2cXvh/Z9flzIiDm6Ffge28eC7pJXAy+vXbxFDXCfhbsVobM1DS5RDbaWYPbVGIcy3WV/RS/mV4T5TdP9LSHVnl94O7J5XZdWceaak4Jow5DavvG4mcHMKw3u1tmxAPKhe0UZ7180ZEmH/nMFza73Bb9fqB93uHUma0+jhmYQY0FKWhIwhtPqSXtTvgzHFnoblBIDWtLHNvH4JZt53lt2ihoiqNKF069T+vo5mGWeducM/oFZvVbeXH9SCqq0f9X8uMt393Ct67zp8d0GbfQdth6TuvubcPwbzbh2as249rUHMw4QjQplm45ho76PsVdd3K6Xkq+vtWXZ/pEcLGRVEaMaCoeSNTk4BKqyYFaF6Yb1km7iRNZDGZZgPOlIZ2VpLpO3S24flWFyLCH1SlFienh1ZNCtCyif37to0H+/yhLQpxy4ie+O9v/DEpZfpdnvllifu6nUYSzlC+MD8Xr151Mp7/1UnWBX0gkjjBRNQawBsAigGUAbiImbcblPsYQH8AXzHzT8OQLYgHzc79EYPn2zZuR4XJzszjt/USult/qpPlA+1Mo2lB3aPj/fsEM/XyK0VqQV4ObhjcHXv215iWeXZ0CfYcOIgHPloCAHj16pMd39Q/3D3MswnztyZ7m54dXYKWjb0NuvSX82ibswXA/TOjHVhkupxus3E6JaqZxlgAU5i5O4ApynsjHgJwRWhSBYSdTsHIAyd5wzi442aMG4wZ4wZbtGO7Kt9RTdMHa/0T4uKS9DSoc24bkvLeqjW3C+Ha0bPRNbU1UFBOdOvYNrhnqhdanXlKXQh3V6+ei0s647ozj7SW5eh2KeshnQ9pYtmJGV32JgV5njfEmjH46HbOw51EvwyYvEfitEs/KqUxCsCLyusXAZxnVIiZpwDYFZZQgM8L4Qjfhn9o80Ic2jzd1TcON90d5/RGQW4OGht0DKd3r+tg/vOL1KxyetG1SvRqA88aJy6ITpRGCwfmQSd3kVsnBbOZhKqE/JppCMZofzW/0tGat0UpN5VX5xovRKU02jHzBgBQ/nty3Ceia4iolIhKKyoqPAnm53OmToeLbCTfMWzWQpiRfdzleI6yG7nopM5Y9tcRhi6lWk+WTMmKtA/rkYc2y9iutrx+v4oTpfHXnxm7aAbpg++oHl19ft3LZvLFYSASJJm+nvb7TxhzmsO67V08o9/wytO64pGLoktbG5jSIKLJRLTQ4G+U320x83hmLmHmkqKi8IOKmXHBiZ1w//nH2ooh5fQB/+clfbH47uEuJQuGfgFFOzWjfQt7mye1l/bZ0Sfht2fUzU6ceNq0amK/rD3zlO3qjM/Xt6nbByMzDfvMvzOzh5cVQStQbf1jzjzSt93/bghMaTDzWcx8jMHf+wA2EVEHAFD+bw5KDqfonzOr6JnHdLReCMvJIVzS7/CMnlGJdu094GpHmZtDKRFfx47omdxJHBXXDjLehOWE4ZrNWmY4fUC117a4bVPcMqJu/0perven3a1Js+MhiR3Ybu34ZmsWUZqnsnX24cT0qKKdLRjNHPQ77N2QXNOAdo3Tc7WeiMo8NQHAaOX1aADvRyRHRk7scojh8c/+MBCvXt0/4SWiYNbh2QnhYfR8Gz3y7153Cp4dXefq99AFfXBGjyJce8YRuOEs/3ZKW2E2tfbiBaQ9szDD5iwVu521Vakg0uAablwzEOLRi4/Hk5edgK5tzXeIW6EfaLRQzKEdWjZWPndVraDj4QvrErM9fmlfvHXtAADpnfdVp3VNeT/x+tNME0Q5jVqbshcm4hX6qJTG/QCGENFyAEOU9yCiEiJ6Ri1ERF8CeAvAYCIqJ6JhQQtm1BHNujV9U133ds3RojA/xUTynytONKzTz36pQ8vGGHx03eznwpLOeNGlX/q3t/wE//mFscxWmHXWRl/TjWyZZnDqQ2O3U7SaxeXl5mC2ztvKKdrqH/x5H2NPI4OL07Jxvuu1KSMGdGuDf17aF+NGJmZSPjqpAfD3Po6647OD2lGrJkxGIiLxSSZm2Ft/2gt/Gd4z+b5VkwLXAwIVw1s34ksXyT4NZt4KIM0vlJlLAVyleX96mHIl2kx9TyDLhdlmBju59dgZzYY1KNR2oB1aNsb6HfsCba+7jYVqPZlmLM7NU9aft/YY8E27mG4mm1VoC9829xHh3OMOw5bd+wF4z6sRl6Q/ccXod/vdoCPwwMdLku/NrqGbSxuX3yMSpRFnenZwtg3/UN1i7B3n9MLeAwdTjtnx0DG6IVSz1iEOdtTqee5XJSjbshefLzP2KivIdW5PD8I8pcYXMlpjMDPvWT1CP9w9DNe9MhvTllb4PuJWmTFuMKoPMuav3YGPF20EYH4N3ChPIwrzc1BVnQiXYZZvRZUgyoXwIJv+3+8G+FbXPecdgyNMZgNprt6+tWofo3WMqNc0RGnoaJSXi7m3D8Hxd3/m6vxfn9o17ZidgGtGz1jXtk1x17m9MeLYzIvDZvykZ8KUpSoNfTvHdGyBe0b1xn0fLUlTdk7xci8P7nkorjqta1ok1ZF9OqCkOHVdyU47TQrykKvE/Qiq81T3w3Rs1RhnHlWEaUsrDGW7fnB3XH6yeXA8J51Afm5Cacy7fSj+9fkKwzLqIMWOsmzbrBGOdjhQUjES222H5sRcdWIX/7z0rujfJXMhhbTLaSLyxOtPwyGKp53ZIML2mkZyIZxSdocDCaeYjTur7FXkIxJ7yoBWTQrSFrWs8MPV1Gw2MvqUYsPNen5BRLhiQLFpEhstmbzA2hqY8dSNfMd2bJlyfNrNgzD5poHJ93m5Obj1p73STIFPXnaCqWknky4IM9aVuifHKGruTUN6oJ1N9+BMjB5QDAAoLEhtSHv7qIMUO8qy9Naz8NKVJ2cs15BQN5fWuTAbY6boeh/WEoe1Up0R/L/5VEX0+Z8GYdFdgS/zpiEzDQeMHtAFL367Ju34q1efnAzL7JaCvBxgv6cqPPGPS/pi0bpKXPPSLFTuqzYsM+l66yWmXgaxeA5pWoB3/+8UHKWLvulpgTD5rFpf87pH2r8Hd/6dQw2VkDqqdxMFwIlZ749De+CmIT0sZ6/NGuWhQ8tCjB3R07SM33LpyeTZFoaJxU0StKLmjdC1rT+mRCusuotL+3XGazPWppQzul5BhVzJhCgNm5TdPxIADJVGXm6O5wtpmJPAx0HKL04+HNOXVSQT4ehp1igPJ3drY/owjznzSMvd1z11SuHaM47AwB6J0CB9Dzd2W3aL6nzw0z7WubWtor3aHaF9cuNAzCvfkXxv5s+vtz0HNbshoowdbm4O4dtbzOOP2UU/StaPrI3kiItX1Cc3DnS8AW7eHUORn0tYu82ec4gdxedG8d53fp+k0hh+THv8ddJiXFjSCa9+/2OiTsc1+osojZhgZwOgF4b2bp9UfE7o06klfjmg2DI5D5BuXvM6yrWiSUEe5t0xNKPnmmoqMrLtN7Xh9QYAR7VvnjZLMiIuni1BEmXWR6fY+c30qCZGu99Te8eb6Qaz+8KuLuncuknyudVm8YsSURoR8eWfz0yMWpUbYFjv9hg/fVW0QhlASIRDSTlmcNOGnYPcTphrt+E0fn5CJ/xvdrmjc9QW4pBoKg441aFxul6sMzU6OccMfU1exhhRz+ZEaWTAr9HVgxf0wbEdW2LEY18CSE/S85fhPfGzvh2Tn0eF25hJdlNyhkldXnRn3Hf+sTi6Q3Nbe3BUoghhHda4PxkI0cbdEafO3yuZvosT01P2zNEyI0ojJC4yyPugJTeH0gLwZdON5kMIpxR+O7Abftiw01MdlFzTcHYlC/JycNXpzuJouRmdNmSy8Sqlr/FoXjv8Qm6Ua1wsoKI0TIhixBSHUZqd0VMY5qlbzj46c6EMqCKF8bCpbahtntnzUDz86TLf8nPHESsFafeSt2lagK17DtgK7venYUelOVwEQVpUCFubc60/9/PpiLqfkH0aMUJ/4zUPOLGLEb//SSJu0pgMmdr02MmJHTZh7oyu1Zmneh/WEmX3j8TxnVsF3nZQqHsNurTxFj/JivNP6Ij//qYfLj7JeiYOANedeWRK3LWw8LqYDaQrUVdhRJyfEgiiNGJIYX4OnrriRPTpFH6H8+tTu6Ls/pEYfLT9vFj/vvwE/PW8YwOUyppuRYlOTR9lmCxcbvWc0cNbHhY3qXnjztDe7fHqVScnI7Xqv5obDyUVbV0DexTF6rq1a5Fw1T33eGuPQS3miari8738QsxTJkRhP1SbLMzPxTAbeSWCxMnNPuJY/yK1uuGd352C9Tuq0jYXOlkIf/E3/VA8dqJrGerWNOoX2jzf+mdioIGipWTZuIyLndOmWSMsuWd4cu+UaSgQ7fZRk6/rxywlbojScIGTECNO0CZcEezTqkmBYVa9cDPYRdtJhrkA37wwD49f2teXuuKqW+zstnbiWenLrxOTayVKIwP6h9HNBjktb1zTH5t2WccLqY9T2ihIrs2HuhBef3+79kpYjltHHo1BR9k3XxpR37zMMv3sftyCRx7aDD9s2Bn5PSZKw4TLTj4cb88u9zVJDgCc3M08MGBMBhKhcs95xwTmEVMX7TX4K9uhVaJDbWFj06FfXHla11A3hF7W73C0bdbIMgVych0pLKEiRHtb+X2LDejWJi30/ctXnYyF6yoDjx6RCVEaJnQraoa5t3tLNu+WuI/B/BzpOAlN7ZRhx7TDG6VrcfzhwTsU3DqyF/p3a4N+Xf0L252Jdi0KMeioIny+1DhXit/k5BCGH+PPWtsxStRjs3TK2YATPeH0iXntmv5px1o3LTBcRwqbSFQWEbUmos+IaLnyP+3OIaLjiehbIlpERPOJ6OIoZBXSGda7Pc72kOMjLH7Ssx1W33c2era3Th/rB4X5uRkDKAZBXNcEMjHgiDaYMW5w5E4UXtAucodhnooLUc1zxgKYwszdAUxR3uvZC+CXzNwbwHAA/yCi7HV6t0GcOgAr75eCvBzcG6GLrROyaX3oqHbBb1wLGjUmmJ0Ux0HmiQkbt8/uT3p6WxuKgqjMU6MADFJevwjgcwB/0RZg5mWa1+uJaDOAIgA7UE9RN/Nd2s88y1tYbN97AAAMvZIA47SsADDv9qEg2f3jmA/GnIbOrTPvio47T11xIibO34BiL/lSYoaZ+vNqnpp161loFsEGXq9EJXE7Zt4AAMy8gYgs1S0R9QNQAGBlGMJFRWF+Lpb/dQTyYhD8r3+3NjjtyLa445xehp/nG6WoA9DSQz7zhsyxnVpmLpQFtGtRiN8E5JIeN5oU1LnlupnQ6rNUZguBKQ0imgzAyPA9zmE9HQC8BGA0M9ealLkGwDUAcPjh0Y/SvZCfG49hepOCPLx8lXkaULOZhiA0FJoU5KFxfi72VR80LaNujszmtRs9gSkNZj7L7DMi2kREHZRZRgcAm03KtQAwEcCtzPydRVvjAYwHgJKSkhitDNRf4jAbEjTIzxEJ7113Kl78tsw04GKPds097+2KG1ENaycAGK28Hg3gfX0BIioA8C6A/zLzWyHKJtggmxaYBcEPjBa7j2rfHH/72bGxzCcTFFEpjfsBDCGi5QCGKO9BRCVE9IxS5iIAAwH8iojmKn/HRyOuYEZxm/hFt21I9GiXyNvepqmxw4Ig+E0kC+HMvBXAYIPjpQCuUl6/DODlkEUTHPDh709Lhs8WouHPw3ti8NHtIomI3NDwc3J9aPPsXAQHZEe44AF1V68QHfm5OehvEZpG8A8/91H9/cLsNZrEw1VHEGKA15waQv0kiOW7bHZNl5mGICg8O7oE1QfF+U4QrBClIQgKebk5yMucRkFoYKjhXeykpG0IiNIQBEGw4NAWhfVur4UXZE1DEARBsI0oDUEQBME2ojQEQRAE28iahiAIQkh8MOY0zF27PWoxPCFKQxAEISSO7dQy68Pgi3lKEARBsI0oDUEQBME2ojQEQRAE24jSEARBEGwjSkMQBEGwjSgNQRAEwTaiNARBEATbiNIQBEEQbEPsZzqqGEBEFQDWeKiiLYAtPonjJyKXM0QuZ4hczqiPcnVh5oyZyOqd0vAKEZUyc0nUcugRuZwhcjlD5HJGQ5ZLzFOCIAiCbURpCIIgCLYRpZHO+KgFMEHkcobI5QyRyxkNVi5Z0xAEQRBsIzMNQRAEwTaiNBSIaDgRLSWiFUQ0NuS2OxPRNCJaTESLiOgG5fidRLSOiOYqf2drzrlFkXUpEQ0LULYyIlqgtF+qHGtNRJ8R0XLl/yHKcSKifypyzSeiEwKS6SjNNZlLRDuJ6MYorhcRPUdEm4looeaY4+tDRKOV8suJaHRAcj1EREuUtt8lolbK8WIi2qe5bv/RnHOi8vuvUGSngGRz/Nv5/cyayPWGRqYyIpqrHA/lmln0DdHdY8zc4P8A5AJYCaAbgAIA8wD0CrH9DgBOUF43B7AMQC8AdwK42aB8L0XGRgC6KrLnBiRbGYC2umMPAhirvB4L4AHl9dkAPgJAAPoD+D6k324jgC5RXC8AAwGcAGCh2+sDoDWAVcr/Q5TXhwQg13kDoMAAAAZSSURBVFAAecrrBzRyFWvL6eqZAWCAIvNHAEYEdM0c/XZBPLNGcuk+/zuA28O8ZhZ9Q2T3mMw0EvQDsIKZVzHzAQCvAxgVVuPMvIGZZyuvdwFYDKCjxSmjALzOzPuZeTWAFUh8h7AYBeBF5fWLAM7THP8vJ/gOQCsi6hCwLIMBrGRmqw2dgV0vZp4OYJtBe06uzzAAnzHzNmbeDuAzAMP9louZP2XmGuXtdwA6WdWhyNaCmb/lRM/zX8138VU2C8x+O9+fWSu5lNnCRQBes6rD72tm0TdEdo+J0kjQEcBazftyWHfagUFExQD6AvheOTRGmWY+p05BEa68DOBTIppFRNcox9ox8wYgcVMDODQCuVQuQeqDHPX1Apxfnyiu22+QGJGqdCWiOUT0BRGdrhzrqMgSllxOfruwr9npADYx83LNsVCvma5viOweE6WRwMjmGLpbGRE1A/A/ADcy804A/wZwBIDjAWxAYnoMhCvvqcx8AoARAK4jooEWZUO9jkRUAOBcAG8ph+JwvawwkyPs6zYOQA2AV5RDGwAczsx9AdwE4FUiahGyXE5/u7B/00uROjgJ9ZoZ9A2mRU3a900uURoJygF01rzvBGB9mAIQUT4SN8UrzPwOADDzJmY+yMy1AJ5GnUklNHmZeb3yfzOAdxUZNqlmJ+X/5rDlUhgBYDYzb1JkjPx6KTi9PqHJpyyA/hTA5Yr5BIrpZ6vyehYSawU9FLm0Jqwg7zOnv12Y1ywPwPkA3tDIG9o1M+obEOE9JkojwUwA3YmoqzJ6vQTAhLAaV+ylzwJYzMyPaI5r1wN+BkD16pgA4BIiakREXQF0R2LxzW+5mhJRc/U1EgupC5X2Ve+L0QDe18j1S8WDoz+ASnUKHRApo7+or5cGp9fnEwBDiegQxSwzVDnmK0Q0HMBfAJzLzHs1x4uIKFd53Q2J67NKkW0XEfVX7tFfar6L37I5/e3CfGbPArCEmZNmp7CumVnfgCjvMber+vXtDwmvg2VIjBjGhdz2aUhMFecDmKv8nQ3gJQALlOMTAHTQnDNOkXUpfPBoMZGrGxJeKfMALFKvC4A2AKYAWK78b60cJwBPKnItAFAS4DVrAmArgJaaY6FfLySU1gYA1UiM5q50c32QWGNYofz9OiC5ViBh11bvsf8oZX+u/L7zAMwGcI6mnhIkOvCVAJ6AsiE4ANkc/3Z+P7NGcinHXwBwra5sKNcM5n1DZPeY7AgXBEEQbCPmKUEQBME2ojQEQRAE24jSEARBEGwjSkMQBEGwjSgNQRAEwTaiNATBJUR0NxGd5UM9ux2Wn0RKhFrd8TuJ6Gav8giCFXlRCyAI2Qoz3x5Ru2dnLiUIwSAzDUFQIKJfENEMSuRHeEqz43c3Ef2diGYT0RQiKlKOv0BEFyiv7yeiH5SAew8rx7oo5ecr/w9Xjnclom+JaCYR3aOT4U/K8flEdJeJnGVE1FZ5PY4SOSUmAzgqsIsjCAqiNAQBABEdDeBiJAI0Hg/gIIDLlY+bIhHj6gQAXwC4Q3duayRCX/Rm5j4A7lU+egKJMNV9kAgO+E/l+GMA/s3MJyGRC0StZygS4Sj6IRG470SrAJFEdCIS4TP6IhEb6SR3314Q7CNKQxASDAZwIoCZlMjONhiJMCoAUIu6YHUvIxHaQctOAFUAniGi8wGocZ0GAHhVef2S5rxTURcz6yVNPUOVvzlIhKboiYQSMeN0AO8y815ORD4NLV6a0HCRNQ1BSEAAXmTmW2yUTYm9w8w1RNQPCUVzCYAxAH6S4Tyj+D0E4D5mfsqeyKb1CEJgyExDEBJMAXABER0KJHMwd1E+ywFwgfL6MgBfaU9Uch20ZOZJAG5EwrQEAN8goUSAhKlLPe9r3XGVTwD8RqkPRNRRlceE6QB+RkSNlWjE59j9soLgFplpCAIAZv6BiG5FIkthDhKRTq8DsAbAHgC9iWgWgEok1j60NAfwPhEVIjFb+INy/HoAzxHRnwBUAPi1cvwGJJL23IBEngRVhk+VtZVvExGxsRvAL1CXK0Ev82wiegOJyKdrAHzp4RIIgi0kyq0gZICIdjNzs6jlEIQ4IOYpQRAEwTYy0xAEQRBsIzMNQRAEwTaiNARBEATbiNIQBEEQbCNKQxAEQbCNKA1BEATBNqI0BEEQBNv8f4ZAYgZuI2aTAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"BipedalWalker DQN\")\n",
    "plt.ylabel(\"distance traveled\")\n",
    "plt.xlabel(\"episode id\")\n",
    "plt.plot(np.arange(0, NUM_EPISODES, 1), distance_his)\n",
    "plt.show()\n",
    "\n",
    "plt.ylabel(\"avg velocity\")\n",
    "plt.xlabel(\"episode id\")\n",
    "plt.plot(np.arange(0, NUM_EPISODES, 1), velocity_his)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
